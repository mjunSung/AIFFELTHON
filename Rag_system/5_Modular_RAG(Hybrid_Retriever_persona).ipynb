{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import pickle\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from IPython.display import clear_output\n",
    "from typing import List, Dict, Any, Optional\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.chains import RetrievalQA, LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.embeddings import ClovaXEmbeddings\n",
    "from langchain_community.chat_models import ChatClovaX\n",
    "from pymilvus import connections, utility\n",
    "from langchain_community.vectorstores.milvus import Milvus\n",
    "from langchain.schema import BaseRetriever, Document\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from langchain_elasticsearch import ElasticsearchRetriever\n",
    "from elasticsearch import Elasticsearch, helpers\n",
    "from langchain_elasticsearch import ElasticsearchStore\n",
    "from langchain.retrievers import EnsembleRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 로깅 설정\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ISBNMergingRetriever\n",
    "\n",
    "\n",
    "\n",
    "class ISBNMergingRetriever(BaseRetriever):\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    검색된 Document 리스트를 ISBN 기준으로 그룹화하고,\n",
    "\n",
    "\n",
    "    같은 ISBN을 가진 문서들의 page_content를 병합하며,\n",
    "\n",
    "\n",
    "    그룹 내에서 가장 정보가 많은 메타데이터를 대표로 사용합니다.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    base_retriever: BaseRetriever\n",
    "\n",
    "\n",
    "    def _extract_isbn(self, doc: Document) -> Optional[str]:\n",
    "\n",
    "\n",
    "        try:\n",
    "\n",
    "\n",
    "            for key in [\"ISBN\", \"isbn\"]:\n",
    "\n",
    "\n",
    "                if key in doc.metadata:\n",
    "\n",
    "\n",
    "                    isbn_val = doc.metadata[key]\n",
    "\n",
    "\n",
    "                    return str(isbn_val).replace(\".0\", \"\").strip() if isbn_val else None\n",
    "\n",
    "\n",
    "            inner_meta = doc.metadata.get(\"metadata\", {})\n",
    "\n",
    "\n",
    "            if isinstance(inner_meta, dict):\n",
    "\n",
    "\n",
    "                for key in [\"ISBN\", \"isbn\"]:\n",
    "\n",
    "\n",
    "                    if key in inner_meta:\n",
    "\n",
    "\n",
    "                        isbn_val = inner_meta[key]\n",
    "\n",
    "\n",
    "                        return (\n",
    "                            str(isbn_val).replace(\".0\", \"\").strip()\n",
    "                            if isbn_val\n",
    "                            else None\n",
    "                        )\n",
    "\n",
    "\n",
    "                inner_inner_meta = inner_meta.get(\"metadata\", {})\n",
    "\n",
    "\n",
    "                if isinstance(inner_inner_meta, dict):\n",
    "\n",
    "\n",
    "                    for key in [\"ISBN\", \"isbn\"]:\n",
    "\n",
    "\n",
    "                        if key in inner_inner_meta:\n",
    "\n",
    "\n",
    "                            isbn_val = inner_inner_meta[key]\n",
    "\n",
    "\n",
    "                            return (\n",
    "                                str(isbn_val).replace(\".0\", \"\").strip()\n",
    "                                if isbn_val\n",
    "                                else None\n",
    "                            )\n",
    "\n",
    "\n",
    "            source_meta = doc.metadata.get(\"_source\", {}).get(\"metadata\", {})\n",
    "\n",
    "\n",
    "            if isinstance(source_meta, dict):\n",
    "\n",
    "\n",
    "                for key in [\"ISBN\", \"isbn\"]:\n",
    "\n",
    "\n",
    "                    if key in source_meta:\n",
    "\n",
    "\n",
    "                        isbn_val = source_meta[key]\n",
    "\n",
    "\n",
    "                        return (\n",
    "                            str(isbn_val).replace(\".0\", \"\").strip()\n",
    "                            if isbn_val\n",
    "                            else None\n",
    "                        )\n",
    "\n",
    "\n",
    "        except Exception as e:\n",
    "\n",
    "\n",
    "            logger.warning(f\"[ISBN 추출 오류] Metadata: {doc.metadata}, Error: {e}\")\n",
    "\n",
    "\n",
    "        logger.debug(f\"ISBN 추출 실패 - Metadata: {doc.metadata}\")\n",
    "\n",
    "\n",
    "        return None\n",
    "\n",
    "\n",
    "    def _get_best_metadata(self, doc_list: List[Document]) -> Dict[str, Any]:\n",
    "\n",
    "\n",
    "        best_meta = {}\n",
    "\n",
    "\n",
    "        max_score = -1\n",
    "\n",
    "\n",
    "        required_keys = {\"title\", \"author\", \"ISBN\"}\n",
    "\n",
    "\n",
    "        for doc in doc_list:\n",
    "\n",
    "\n",
    "            current_meta = doc.metadata\n",
    "\n",
    "\n",
    "            score = 0\n",
    "\n",
    "\n",
    "            keys_lower = {k.lower() for k in current_meta.keys()}\n",
    "\n",
    "\n",
    "            required_keys_lower = {rk.lower() for rk in required_keys}\n",
    "\n",
    "\n",
    "            score += sum(\n",
    "                1\n",
    "                for req_key in required_keys_lower\n",
    "                if req_key in keys_lower\n",
    "                and current_meta.get(\n",
    "                    next((k for k in current_meta if k.lower() == req_key), None)\n",
    "                )\n",
    "            )\n",
    "\n",
    "\n",
    "            score += len(current_meta) * 0.1\n",
    "\n",
    "\n",
    "            if score > max_score:\n",
    "\n",
    "\n",
    "                max_score = score\n",
    "\n",
    "\n",
    "                best_meta = current_meta\n",
    "\n",
    "\n",
    "        if best_meta:\n",
    "\n",
    "\n",
    "            logger.debug(\n",
    "                f\"선택된 최적 메타데이터 (Score: {max_score:.2f}): {best_meta}\"\n",
    "            )\n",
    "\n",
    "\n",
    "        else:\n",
    "\n",
    "\n",
    "            logger.warning(\n",
    "                \"ISBN 그룹 내에서 유효한 메타데이터를 찾지 못함. 첫 번째 문서 메타데이터 사용 시도.\"\n",
    "            )\n",
    "\n",
    "\n",
    "            if doc_list:\n",
    "\n",
    "\n",
    "                best_meta = doc_list[0].metadata\n",
    "\n",
    "\n",
    "        return dict(best_meta)\n",
    "\n",
    "\n",
    "    def _merge_documents_by_isbn(\n",
    "        self, docs: List[Document], is_async=False\n",
    "    ) -> List[Document]:\n",
    "\n",
    "\n",
    "        grouped = defaultdict(list)\n",
    "\n",
    "\n",
    "        merged_docs = []\n",
    "        logger.info(\n",
    "\n",
    "            f\"[{'Async' if is_async else 'Sync'}] 병합 전 입력 문서 수: {len(docs)}\"\n",
    "        )\n",
    "\n",
    "\n",
    "        for idx, doc in enumerate(docs):\n",
    "\n",
    "\n",
    "            isbn = self._extract_isbn(doc)\n",
    "\n",
    "\n",
    "            if isbn:\n",
    "\n",
    "\n",
    "                grouped[isbn].append(doc)\n",
    "\n",
    "\n",
    "            else:\n",
    "\n",
    "\n",
    "                logger.warning(\n",
    "                    f\"[{'Async' if is_async else 'Sync'}] Doc {idx} ISBN 추출 실패 - Metadata: {doc.metadata}\"\n",
    "                )\n",
    "\n",
    "\n",
    "        for isbn, doc_list in grouped.items():\n",
    "\n",
    "\n",
    "            merged_meta = self._get_best_metadata(doc_list)\n",
    "\n",
    "\n",
    "            combined_text = \"\\n\\n---\\n\\n\".join(\n",
    "                d.page_content for d in doc_list if d.page_content\n",
    "            ).strip()\n",
    "\n",
    "\n",
    "            if combined_text:\n",
    "\n",
    "\n",
    "                logger.debug(f\"ISBN {isbn} 병합: 최종 사용될 메타데이터: {merged_meta}\")\n",
    "\n",
    "\n",
    "                merged_docs.append(\n",
    "                    Document(page_content=combined_text, metadata=merged_meta)\n",
    "                )\n",
    "\n",
    "\n",
    "            else:\n",
    "\n",
    "\n",
    "                logger.warning(\n",
    "                    f\"[{'Async' if is_async else 'Sync'}] ISBN {isbn} 병합 후 내용 없음. 제외됨. 사용된 메타데이터: {merged_meta}\"\n",
    "                )\n",
    "\n",
    "        logger.info(\n",
    "\n",
    "            f\"[{'Async' if is_async else 'Sync'}] ISBN 병합 그룹 수: {len(grouped)}\"\n",
    "        )\n",
    "        logger.info(\n",
    "\n",
    "            f\"[{'Async' if is_async else 'Sync'}] 병합 후 최종 문서 수: {len(merged_docs)}\"\n",
    "        )\n",
    "\n",
    "\n",
    "        return merged_docs\n",
    "\n",
    "\n",
    "    def _get_relevant_documents(self, query: str) -> List[Document]:\n",
    "\n",
    "\n",
    "        try:\n",
    "\n",
    "\n",
    "            docs = self.base_retriever.get_relevant_documents(query)\n",
    "\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(\n",
    "\n",
    "                f\"기본 리트리버 동기 검색 오류: '{query}' → {e}\", exc_info=True\n",
    "            )\n",
    "\n",
    "\n",
    "            docs = []\n",
    "\n",
    "\n",
    "        logger.info(f\"Sync 검색 결과 총 문서 수: {len(docs)}\")\n",
    "\n",
    "\n",
    "        return self._merge_documents_by_isbn(docs, is_async=False)\n",
    "\n",
    "\n",
    "    async def _aget_relevant_documents(self, query: str) -> List[Document]:\n",
    "\n",
    "\n",
    "        try:\n",
    "\n",
    "\n",
    "            docs = await self.base_retriever.aget_relevant_documents(query)\n",
    "\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(\n",
    "\n",
    "                f\"기본 리트리버 비동기 검색 오류: '{query}' → {e}\", exc_info=True\n",
    "            )\n",
    "\n",
    "\n",
    "            docs = []\n",
    "\n",
    "\n",
    "        logger.info(f\"Async 검색 결과 총 문서 수: {len(docs)}\")\n",
    "\n",
    "\n",
    "        return self._merge_documents_by_isbn(docs, is_async=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Util Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_similar_question(new_emb, prev_embeds, threshold=0.65):\n",
    "    if not prev_embeds:\n",
    "        return False\n",
    "    sim_scores = cosine_similarity([new_emb], prev_embeds)[0]\n",
    "    max_score = np.max(sim_scores)\n",
    "    logger.info(\n",
    "        f\"[질문 유사도 판단] Max Similarity = {max_score:.3f} (Threshold = {threshold})\"\n",
    "    )\n",
    "    return max_score > threshold\n",
    "\n",
    "\n",
    "def extract_field(text, field_name):\n",
    "    pattern = rf\"^\\s*{re.escape(field_name)}\\s*[:：]\\s*(.*?)\\s*$\"\n",
    "    lines = text.splitlines()\n",
    "    for line in lines:\n",
    "        match = re.search(pattern, line, re.IGNORECASE)\n",
    "        if match:\n",
    "            return match.group(1).strip()\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 환경설정 & 임베딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-08 10:14:23,521 - INFO - ClovaX 임베딩 및 Chat 모델 초기화 완료\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv(\"NCP_CLOVASTUDIO_API_KEY\")\n",
    "api_url = os.getenv(\"NCP_CLOVASTUDIO_API_URL\", \"https://clovastudio.stream.ntruss.com/\")\n",
    "milvus_host = os.getenv(\"MILVUS_HOST\", \"localhost\")\n",
    "milvus_port = os.getenv(\"MILVUS_PORT\", \"19530\")\n",
    "es_url = os.getenv(\"ELASTICSEARCH_URL\", \"http://localhost:9200\")\n",
    "es_index_name = \"book_bm25_index_v2\"\n",
    "\n",
    "if not api_key:\n",
    "    raise ValueError(\"NCP_CLOVASTUDIO_API_KEY 환경 변수가 설정되지 않았습니다.\")\n",
    "if not api_url:\n",
    "    raise ValueError(\"NCP_CLOVASTUDIO_API_URL 환경 변수가 설정되지 않았습니다.\")\n",
    "if not es_url:\n",
    "    raise ValueError(\"ELASTICSEARCH_URL 환경 변수가 설정되지 않았습니다.\")\n",
    "\n",
    "os.environ[\"NCP_CLOVASTUDIO_API_KEY\"] = api_key\n",
    "os.environ[\"NCP_CLOVASTUDIO_API_URL\"] = api_url\n",
    "\n",
    "try:\n",
    "    ncp_embeddings = ClovaXEmbeddings(model=\"bge-m3\")\n",
    "    llm_clova = ChatClovaX(model=\"HCX-003\", max_tokens=2048)\n",
    "    logger.info(\"ClovaX 임베딩 및 Chat 모델 초기화 완료\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"ClovaX 모델 초기화 실패: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-08 10:14:46,786 - INFO - 임베딩 데이터 로드 완료: 116218개\n",
      "2025-04-08 10:14:50,950 - INFO - 총 116218개의 Document 객체 생성 완료.\n"
     ]
    }
   ],
   "source": [
    "embedding_file = r\"\"\n",
    "if os.path.exists(embedding_file):\n",
    "    try:\n",
    "        with open(embedding_file, \"rb\") as f:\n",
    "            saved_data = pickle.load(f)\n",
    "        all_text_embedding_pairs = [\n",
    "            (v[\"text\"], v[\"embedding\"])\n",
    "            for v in saved_data.values()\n",
    "            if \"text\" in v and \"embedding\" in v\n",
    "        ]\n",
    "        all_metadata_list = [\n",
    "            v[\"metadata\"] for v in saved_data.values() if \"metadata\" in v\n",
    "        ]\n",
    "        if len(all_text_embedding_pairs) != len(all_metadata_list):\n",
    "            logger.warning(\n",
    "                f\"로드된 텍스트/임베딩 쌍({len(all_text_embedding_pairs)})과 메타데이터({len(all_metadata_list)}) 개수 불일치.\"\n",
    "            )\n",
    "            min_len = min(len(all_text_embedding_pairs), len(all_metadata_list))\n",
    "            all_text_embedding_pairs = all_text_embedding_pairs[:min_len]\n",
    "            all_metadata_list = all_metadata_list[:min_len]\n",
    "            logger.info(f\"데이터를 {min_len}개로 조정하여 계속 진행.\")\n",
    "        logger.info(f\"임베딩 데이터 로드 완료: {len(all_text_embedding_pairs)}개\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"임베딩 파일 로드 실패: {e}\", exc_info=True)\n",
    "        raise\n",
    "else:\n",
    "    raise FileNotFoundError(f\"임베딩 파일을 찾을 수 없음: {embedding_file}\")\n",
    "\n",
    "metadata_mapping = {\n",
    "    \"ISBN\": \"ISBN\",\n",
    "    \"페이지\": \"page\",\n",
    "    \"가격\": \"price\",\n",
    "    \"제목\": \"title\",\n",
    "    \"부제\": \"subtitle\",\n",
    "    \"저자\": \"author\",\n",
    "    \"분류\": \"category\",\n",
    "    \"저자소개\": \"author_intro\",\n",
    "    \"책소개\": \"book_intro\",\n",
    "    \"목차\": \"table_of_contents\",\n",
    "    \"출판사리뷰\": \"publisher_review\",\n",
    "    \"추천사\": \"recommendation\",\n",
    "    \"발행자\": \"publisher\",\n",
    "    \"표지\": \"book_cover\",\n",
    "}\n",
    "\n",
    "\n",
    "def clean_metadata(meta: dict) -> dict:\n",
    "    cleaned = {}\n",
    "    target_keys = list(metadata_mapping.values())\n",
    "    original_to_target = {\n",
    "        k_orig: k_target for k_orig, k_target in metadata_mapping.items()\n",
    "    }\n",
    "    for target_key in target_keys:\n",
    "        original_key = next(\n",
    "            (k for k, v in original_to_target.items() if v == target_key), None\n",
    "        )\n",
    "        value = (\n",
    "            meta.get(original_key)\n",
    "            if original_key and original_key in meta\n",
    "            else meta.get(target_key)\n",
    "        )\n",
    "        if pd.isna(value):\n",
    "            cleaned[target_key] = 0 if target_key in [\"page\", \"price\"] else \"\"\n",
    "        elif target_key == \"ISBN\":\n",
    "            try:\n",
    "                str_value = str(value).strip()\n",
    "                cleaned[target_key] = (\n",
    "                    str_value[:-2] if str_value.endswith(\".0\") else str_value\n",
    "                )\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"ISBN 값 '{value}' 처리 중 오류 발생: {e}\")\n",
    "                cleaned[target_key] = str(value).strip()\n",
    "        elif target_key == \"subtitle\":\n",
    "            cleaned[target_key] = str(value)\n",
    "        elif target_key in [\"page\", \"price\"]:\n",
    "            try:\n",
    "                cleaned[target_key] = int(float(value))\n",
    "            except (ValueError, TypeError):\n",
    "                logger.warning(\n",
    "                    f\"'{target_key}' 값 '{value}' 정수 변환 실패. 0으로 설정.\"\n",
    "                )\n",
    "                cleaned[target_key] = 0\n",
    "        else:\n",
    "            cleaned[target_key] = str(value)\n",
    "    return cleaned\n",
    "\n",
    "\n",
    "documents = []\n",
    "for i, (pair, meta) in enumerate(zip(all_text_embedding_pairs, all_metadata_list)):\n",
    "    try:\n",
    "        cleaned_meta = clean_metadata(meta)\n",
    "        documents.append(Document(page_content=pair[0], metadata=cleaned_meta))\n",
    "    except Exception as e:\n",
    "        logger.error(\n",
    "            f\"{i}번째 데이터 처리 중 오류 발생: {e}. 메타데이터: {meta}\", exc_info=True\n",
    "        )\n",
    "logger.info(f\"총 {len(documents)}개의 Document 객체 생성 완료.\")\n",
    "\n",
    "texts = [doc.page_content for doc in documents]\n",
    "embeds = [pair[1] for pair in all_text_embedding_pairs[: len(documents)]]\n",
    "metadatas = [doc.metadata for doc in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-08 10:15:22,684 - INFO - Milvus 유틸리티 함수용 임시 연결 설정 완료 (alias: utility_check_conn).\n",
      "2025-04-08 10:15:22,690 - WARNING - 기존 Milvus 컬렉션 'book_rag_db_v_no_sq'을 삭제.\n",
      "2025-04-08 10:15:22,833 - INFO - Milvus 유틸리티 함수용 임시 연결 해제 완료 (alias: utility_check_conn).\n",
      "C:\\Users\\computer\\AppData\\Local\\Temp\\ipykernel_30692\\2085374808.py:29: LangChainDeprecationWarning: The class `Milvus` was deprecated in LangChain 0.2.0 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-milvus package and should be used instead. To use it run `pip install -U :class:`~langchain-milvus` and import as `from :class:`~langchain_milvus import MilvusVectorStore``.\n",
      "  vectorstore = Milvus(\n",
      "2025-04-08 10:15:22,888 - INFO - Langchain Milvus 인스턴스 초기화 및 연결 설정 완료 (컬렉션: 'book_rag_db_v_no_sq').\n",
      "2025-04-08 10:15:22,910 - INFO - 사전 계산된 임베딩 사용: 116218개\n",
      "2025-04-08 10:17:00,445 - INFO - Milvus에 116218개의 텍스트와 임베딩 추가 완료.\n",
      "2025-04-08 10:17:00,571 - INFO - ClovaXEmbeddings.embed_documents 메소드 원상 복구 완료.\n"
     ]
    }
   ],
   "source": [
    "# Milvus Vector DB\n",
    "collection_name = \"book_rag_db_v_no_sq\"\n",
    "temp_conn_alias = \"utility_check_conn\"\n",
    "try:\n",
    "    connections.connect(alias=temp_conn_alias, host=milvus_host, port=milvus_port)\n",
    "    logger.info(\n",
    "        f\"Milvus 유틸리티 함수용 임시 연결 설정 완료 (alias: {temp_conn_alias}).\"\n",
    "    )\n",
    "    if utility.has_collection(collection_name, using=temp_conn_alias):\n",
    "        logger.warning(f\"기존 Milvus 컬렉션 '{collection_name}'을 삭제.\")\n",
    "        utility.drop_collection(collection_name, using=temp_conn_alias)\n",
    "    else:\n",
    "        logger.info(\n",
    "            f\"Milvus 컬렉션 '{collection_name}'이(가) 존재하지 않음. 새로 생성.\"\n",
    "        )\n",
    "except Exception as e:\n",
    "    logger.error(f\"Milvus 유틸리티 함수 실행 중 오류 발생: {e}\", exc_info=True)\n",
    "finally:\n",
    "    try:\n",
    "        if connections.get_connection_addr(temp_conn_alias):\n",
    "            connections.disconnect(temp_conn_alias)\n",
    "            logger.info(\n",
    "                f\"Milvus 유틸리티 함수용 임시 연결 해제 완료 (alias: {temp_conn_alias}).\"\n",
    "            )\n",
    "    except Exception as disconnect_e:\n",
    "        logger.warning(f\"Milvus 임시 연결 해제 중 오류 (무시 가능): {disconnect_e}\")\n",
    "\n",
    "try:\n",
    "    vectorstore = Milvus(\n",
    "        embedding_function=ncp_embeddings,\n",
    "        collection_name=collection_name,\n",
    "        connection_args={\"host\": milvus_host, \"port\": milvus_port},\n",
    "        auto_id=True,\n",
    "    )\n",
    "    logger.info(\n",
    "        f\"Langchain Milvus 인스턴스 초기화 및 연결 설정 완료 (컬렉션: '{collection_name}').\"\n",
    "    )\n",
    "    original_embed_documents = ClovaXEmbeddings.embed_documents\n",
    "\n",
    "    def precomputed_embed_documents(cls, input_texts: List[str]) -> List[List[float]]:\n",
    "        if len(input_texts) == len(texts) and all(\n",
    "            t1 == t2 for t1, t2 in zip(input_texts, texts)\n",
    "        ):\n",
    "            logger.info(f\"사전 계산된 임베딩 사용: {len(embeds)}개\")\n",
    "            return embeds\n",
    "        else:\n",
    "            logger.warning(\n",
    "                \"입력 텍스트가 사전 계산된 데이터와 불일치. ClovaX API를 통해 임베딩 수행.\"\n",
    "            )\n",
    "            return original_embed_documents.__func__(cls, input_texts)\n",
    "\n",
    "    ClovaXEmbeddings.embed_documents = classmethod(precomputed_embed_documents)\n",
    "    vectorstore.add_texts(texts=texts, metadatas=metadatas)\n",
    "    logger.info(f\"Milvus에 {len(texts)}개의 텍스트와 임베딩 추가 완료.\")\n",
    "    ClovaXEmbeddings.embed_documents = original_embed_documents\n",
    "    logger.info(\"ClovaXEmbeddings.embed_documents 메소드 원상 복구 완료.\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Milvus 데이터 추가 중 오류 발생: {e}\", exc_info=True)\n",
    "    if (\n",
    "        \"original_embed_documents\" in locals()\n",
    "        and hasattr(ClovaXEmbeddings, \"embed_documents\")\n",
    "        and ClovaXEmbeddings.embed_documents != original_embed_documents\n",
    "    ):\n",
    "        ClovaXEmbeddings.embed_documents = original_embed_documents\n",
    "        logger.info(\n",
    "            \"오류 발생 후 ClovaXEmbeddings.embed_documents 메소드 원상 복구 시도 완료.\"\n",
    "        )\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-08 10:17:10,105 - INFO - Elasticsearch 연결 시도 중: http://localhost:9200...\n",
      "2025-04-08 10:17:36,934 - INFO - HEAD http://localhost:9200/ [status:200 duration:26.223s]\n",
      "2025-04-08 10:17:36,942 - INFO - Elasticsearch 연결 성공\n",
      "2025-04-08 10:17:37,612 - INFO - HEAD http://localhost:9200/book_bm25_index_v2 [status:200 duration:0.648s]\n",
      "2025-04-08 10:17:37,613 - WARNING - 기존 Elasticsearch 인덱스 'book_bm25_index_v2' 삭제 중...\n",
      "C:\\Users\\computer\\AppData\\Local\\Temp\\ipykernel_30692\\3537059587.py:10: DeprecationWarning: Passing transport options in the API method is deprecated. Use 'Elasticsearch.options()' instead.\n",
      "  es_client.indices.delete(index=es_index_name, ignore=[400, 404])\n",
      "2025-04-08 10:17:44,152 - INFO - DELETE http://localhost:9200/book_bm25_index_v2 [status:200 duration:2.357s]\n",
      "2025-04-08 10:17:44,155 - INFO - 기존 Elasticsearch 인덱스 'book_bm25_index_v2' 삭제 완료.\n",
      "2025-04-08 10:17:44,161 - INFO - Langchain ElasticsearchStore 인스턴스 초기화 완료 (인덱스: 'book_bm25_index_v2', BM25 검색 전용).\n",
      "2025-04-08 10:17:44,162 - INFO - Elasticsearch에 문서 인덱싱 시작 (총 116218개)...\n",
      "2025-04-08 10:18:07,772 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:2.345s]\n",
      "2025-04-08 10:18:08,231 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.416s]\n",
      "2025-04-08 10:18:08,669 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.413s]\n",
      "2025-04-08 10:18:09,073 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.376s]\n",
      "2025-04-08 10:18:09,521 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.427s]\n",
      "2025-04-08 10:18:10,120 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.477s]\n",
      "2025-04-08 10:18:10,566 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.416s]\n",
      "2025-04-08 10:18:13,032 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:2.396s]\n",
      "2025-04-08 10:18:13,667 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.600s]\n",
      "2025-04-08 10:18:14,220 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.518s]\n",
      "2025-04-08 10:18:15,164 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.904s]\n",
      "2025-04-08 10:18:15,484 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.278s]\n",
      "2025-04-08 10:18:15,892 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.370s]\n",
      "2025-04-08 10:18:16,632 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.712s]\n",
      "2025-04-08 10:18:17,046 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.384s]\n",
      "2025-04-08 10:18:17,330 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.227s]\n",
      "2025-04-08 10:18:17,634 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.236s]\n",
      "2025-04-08 10:18:17,940 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.243s]\n",
      "2025-04-08 10:18:18,345 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.315s]\n",
      "2025-04-08 10:18:18,654 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.257s]\n",
      "2025-04-08 10:18:18,995 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.260s]\n",
      "2025-04-08 10:18:19,362 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.282s]\n",
      "2025-04-08 10:18:19,659 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.236s]\n",
      "2025-04-08 10:18:19,952 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.241s]\n",
      "2025-04-08 10:18:20,315 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.305s]\n",
      "2025-04-08 10:18:20,589 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.205s]\n",
      "2025-04-08 10:18:20,917 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.259s]\n",
      "2025-04-08 10:18:21,258 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.267s]\n",
      "2025-04-08 10:18:21,615 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.295s]\n",
      "2025-04-08 10:18:21,951 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.278s]\n",
      "2025-04-08 10:18:22,366 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.361s]\n",
      "2025-04-08 10:18:22,679 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.254s]\n",
      "2025-04-08 10:18:23,009 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.276s]\n",
      "2025-04-08 10:18:23,367 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.304s]\n",
      "2025-04-08 10:18:23,742 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.314s]\n",
      "2025-04-08 10:18:24,096 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.296s]\n",
      "2025-04-08 10:18:24,419 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.272s]\n",
      "2025-04-08 10:18:24,821 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.314s]\n",
      "2025-04-08 10:18:25,219 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.243s]\n",
      "2025-04-08 10:18:26,018 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.697s]\n",
      "2025-04-08 10:18:26,773 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.657s]\n",
      "2025-04-08 10:18:27,408 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.583s]\n",
      "2025-04-08 10:18:28,228 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.715s]\n",
      "2025-04-08 10:18:29,314 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:1.010s]\n",
      "2025-04-08 10:18:30,336 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.830s]\n",
      "2025-04-08 10:18:31,225 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.783s]\n",
      "2025-04-08 10:18:32,125 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.788s]\n",
      "2025-04-08 10:18:33,007 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.759s]\n",
      "2025-04-08 10:18:33,675 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.592s]\n",
      "2025-04-08 10:18:34,628 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.857s]\n",
      "2025-04-08 10:18:35,449 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.757s]\n",
      "2025-04-08 10:18:36,192 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.651s]\n",
      "2025-04-08 10:18:36,870 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.598s]\n",
      "2025-04-08 10:18:37,486 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.505s]\n",
      "2025-04-08 10:18:41,632 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:4.039s]\n",
      "2025-04-08 10:18:42,075 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.392s]\n",
      "2025-04-08 10:18:42,679 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.515s]\n",
      "2025-04-08 10:18:46,301 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:3.464s]\n",
      "2025-04-08 10:18:47,078 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.655s]\n",
      "2025-04-08 10:18:49,232 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:1.882s]\n",
      "2025-04-08 10:18:50,352 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:1.033s]\n",
      "2025-04-08 10:18:52,743 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:2.319s]\n",
      "2025-04-08 10:18:53,759 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.949s]\n",
      "2025-04-08 10:18:54,747 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.637s]\n",
      "2025-04-08 10:18:55,087 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.284s]\n",
      "2025-04-08 10:18:55,447 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.308s]\n",
      "2025-04-08 10:18:55,808 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.321s]\n",
      "2025-04-08 10:18:56,174 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.322s]\n",
      "2025-04-08 10:18:56,495 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.283s]\n",
      "2025-04-08 10:18:56,895 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.353s]\n",
      "2025-04-08 10:18:57,230 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.290s]\n",
      "2025-04-08 10:18:57,514 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.253s]\n",
      "2025-04-08 10:18:57,895 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.340s]\n",
      "2025-04-08 10:18:58,281 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.321s]\n",
      "2025-04-08 10:18:58,837 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.509s]\n",
      "2025-04-08 10:18:59,603 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.608s]\n",
      "2025-04-08 10:18:59,849 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.195s]\n",
      "2025-04-08 10:19:00,090 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.210s]\n",
      "2025-04-08 10:19:00,329 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.209s]\n",
      "2025-04-08 10:19:00,621 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.263s]\n",
      "2025-04-08 10:19:00,931 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.248s]\n",
      "2025-04-08 10:19:01,167 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.182s]\n",
      "2025-04-08 10:19:01,469 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.248s]\n",
      "2025-04-08 10:19:01,732 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.185s]\n",
      "2025-04-08 10:19:02,025 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.247s]\n",
      "2025-04-08 10:19:02,347 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.262s]\n",
      "2025-04-08 10:19:02,661 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.257s]\n",
      "2025-04-08 10:19:02,957 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.246s]\n",
      "2025-04-08 10:19:03,287 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.278s]\n",
      "2025-04-08 10:19:03,682 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.307s]\n",
      "2025-04-08 10:19:04,052 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.314s]\n",
      "2025-04-08 10:19:04,434 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.318s]\n",
      "2025-04-08 10:19:04,787 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.289s]\n",
      "2025-04-08 10:19:05,081 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.234s]\n",
      "2025-04-08 10:19:05,452 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.309s]\n",
      "2025-04-08 10:19:05,961 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.438s]\n",
      "2025-04-08 10:19:06,421 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.404s]\n",
      "2025-04-08 10:19:06,840 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.327s]\n",
      "2025-04-08 10:19:07,217 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.282s]\n",
      "2025-04-08 10:19:07,690 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.408s]\n",
      "2025-04-08 10:19:08,069 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.305s]\n",
      "2025-04-08 10:19:08,455 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.332s]\n",
      "2025-04-08 10:19:08,743 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.227s]\n",
      "2025-04-08 10:19:09,062 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.255s]\n",
      "2025-04-08 10:19:09,340 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.211s]\n",
      "2025-04-08 10:19:09,696 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.281s]\n",
      "2025-04-08 10:19:09,967 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.216s]\n",
      "2025-04-08 10:19:10,552 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.513s]\n",
      "2025-04-08 10:19:11,241 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.623s]\n",
      "2025-04-08 10:19:11,920 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.607s]\n",
      "2025-04-08 10:19:12,358 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.359s]\n",
      "2025-04-08 10:19:13,159 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.736s]\n",
      "2025-04-08 10:19:14,181 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.963s]\n",
      "2025-04-08 10:19:15,772 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:1.453s]\n",
      "2025-04-08 10:19:16,078 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.238s]\n",
      "2025-04-08 10:19:16,526 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.359s]\n",
      "2025-04-08 10:19:16,864 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.263s]\n",
      "2025-04-08 10:19:17,168 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.233s]\n",
      "2025-04-08 10:19:17,552 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.309s]\n",
      "2025-04-08 10:19:17,998 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.358s]\n",
      "2025-04-08 10:19:18,407 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.321s]\n",
      "2025-04-08 10:19:18,793 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.317s]\n",
      "2025-04-08 10:19:19,198 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.344s]\n",
      "2025-04-08 10:19:19,632 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.364s]\n",
      "2025-04-08 10:19:19,991 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.276s]\n",
      "2025-04-08 10:19:20,309 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.227s]\n",
      "2025-04-08 10:19:20,635 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.262s]\n",
      "2025-04-08 10:19:21,083 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.357s]\n",
      "2025-04-08 10:19:21,397 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.248s]\n",
      "2025-04-08 10:19:21,750 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.269s]\n",
      "2025-04-08 10:19:22,153 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.315s]\n",
      "2025-04-08 10:19:22,580 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.313s]\n",
      "2025-04-08 10:19:22,959 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.277s]\n",
      "2025-04-08 10:19:23,304 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.223s]\n",
      "2025-04-08 10:19:23,705 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.294s]\n",
      "2025-04-08 10:19:24,150 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.361s]\n",
      "2025-04-08 10:19:24,676 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.437s]\n",
      "2025-04-08 10:19:25,094 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.287s]\n",
      "2025-04-08 10:19:25,507 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.318s]\n",
      "2025-04-08 10:19:25,883 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.298s]\n",
      "2025-04-08 10:19:26,333 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.300s]\n",
      "2025-04-08 10:19:26,759 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.311s]\n",
      "2025-04-08 10:19:27,146 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.327s]\n",
      "2025-04-08 10:19:27,592 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.321s]\n",
      "2025-04-08 10:19:28,432 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.720s]\n",
      "2025-04-08 10:19:28,838 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.315s]\n",
      "2025-04-08 10:19:29,610 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.676s]\n",
      "2025-04-08 10:19:30,020 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.306s]\n",
      "2025-04-08 10:19:30,533 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.395s]\n",
      "2025-04-08 10:19:31,126 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.348s]\n",
      "2025-04-08 10:19:31,507 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.244s]\n",
      "2025-04-08 10:19:32,081 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.430s]\n",
      "2025-04-08 10:19:32,885 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.676s]\n",
      "2025-04-08 10:19:33,466 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.503s]\n",
      "2025-04-08 10:19:34,098 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.545s]\n",
      "2025-04-08 10:19:34,778 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.468s]\n",
      "2025-04-08 10:19:35,154 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.283s]\n",
      "2025-04-08 10:19:35,618 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.299s]\n",
      "2025-04-08 10:19:35,999 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.287s]\n",
      "2025-04-08 10:19:36,350 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.267s]\n",
      "2025-04-08 10:19:36,667 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.251s]\n",
      "2025-04-08 10:19:37,066 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.273s]\n",
      "2025-04-08 10:19:37,443 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.291s]\n",
      "2025-04-08 10:19:37,911 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.367s]\n",
      "2025-04-08 10:19:38,270 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.265s]\n",
      "2025-04-08 10:19:38,702 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.345s]\n",
      "2025-04-08 10:19:39,068 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.301s]\n",
      "2025-04-08 10:19:40,614 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:1.429s]\n",
      "2025-04-08 10:19:41,046 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.350s]\n",
      "2025-04-08 10:19:41,876 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.716s]\n",
      "2025-04-08 10:19:42,367 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.330s]\n",
      "2025-04-08 10:19:42,788 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.293s]\n",
      "2025-04-08 10:19:43,111 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.236s]\n",
      "2025-04-08 10:19:43,503 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.295s]\n",
      "2025-04-08 10:19:44,807 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:1.166s]\n",
      "2025-04-08 10:19:45,355 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.430s]\n",
      "2025-04-08 10:19:45,733 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.267s]\n",
      "2025-04-08 10:19:46,367 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.416s]\n",
      "2025-04-08 10:19:46,786 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.332s]\n",
      "2025-04-08 10:19:47,102 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.226s]\n",
      "2025-04-08 10:19:47,490 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.327s]\n",
      "2025-04-08 10:19:48,249 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.567s]\n",
      "2025-04-08 10:19:48,719 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.369s]\n",
      "2025-04-08 10:19:49,045 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.259s]\n",
      "2025-04-08 10:19:49,375 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.252s]\n",
      "2025-04-08 10:19:49,742 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.280s]\n",
      "2025-04-08 10:19:50,152 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.347s]\n",
      "2025-04-08 10:19:50,772 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.549s]\n",
      "2025-04-08 10:19:51,297 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.405s]\n",
      "2025-04-08 10:19:52,010 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.394s]\n",
      "2025-04-08 10:19:52,654 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.387s]\n",
      "2025-04-08 10:19:53,174 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.447s]\n",
      "2025-04-08 10:19:53,520 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.274s]\n",
      "2025-04-08 10:19:53,935 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.270s]\n",
      "2025-04-08 10:19:54,497 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.401s]\n",
      "2025-04-08 10:19:54,965 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.366s]\n",
      "2025-04-08 10:19:55,363 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.291s]\n",
      "2025-04-08 10:19:55,817 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.332s]\n",
      "2025-04-08 10:19:56,295 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.399s]\n",
      "2025-04-08 10:19:56,711 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.346s]\n",
      "2025-04-08 10:19:57,361 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.519s]\n",
      "2025-04-08 10:19:57,813 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.352s]\n",
      "2025-04-08 10:19:58,257 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.348s]\n",
      "2025-04-08 10:19:58,636 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.299s]\n",
      "2025-04-08 10:19:59,046 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.345s]\n",
      "2025-04-08 10:19:59,495 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.378s]\n",
      "2025-04-08 10:19:59,909 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.274s]\n",
      "2025-04-08 10:20:00,421 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.386s]\n",
      "2025-04-08 10:20:00,882 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.289s]\n",
      "2025-04-08 10:20:01,399 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.371s]\n",
      "2025-04-08 10:20:01,686 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.194s]\n",
      "2025-04-08 10:20:02,003 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.228s]\n",
      "2025-04-08 10:20:02,239 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.168s]\n",
      "2025-04-08 10:20:02,483 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.159s]\n",
      "2025-04-08 10:20:02,736 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.181s]\n",
      "2025-04-08 10:20:03,063 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.234s]\n",
      "2025-04-08 10:20:03,395 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.253s]\n",
      "2025-04-08 10:20:03,746 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.263s]\n",
      "2025-04-08 10:20:04,045 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.217s]\n",
      "2025-04-08 10:20:04,327 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.188s]\n",
      "2025-04-08 10:20:04,658 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.228s]\n",
      "2025-04-08 10:20:04,909 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.157s]\n",
      "2025-04-08 10:20:05,143 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.173s]\n",
      "2025-04-08 10:20:05,558 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.327s]\n",
      "2025-04-08 10:20:05,872 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.195s]\n",
      "2025-04-08 10:20:06,135 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.179s]\n",
      "2025-04-08 10:20:06,359 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.137s]\n",
      "2025-04-08 10:20:06,623 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.197s]\n",
      "2025-04-08 10:20:06,980 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.297s]\n",
      "2025-04-08 10:20:07,389 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.320s]\n",
      "2025-04-08 10:20:07,635 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.164s]\n",
      "2025-04-08 10:20:07,893 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.200s]\n",
      "2025-04-08 10:20:07,970 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.056s]\n",
      "2025-04-08 10:20:07,977 - INFO - Elasticsearch 벌크 인덱싱 시도 완료: 116218 문서 성공.\n",
      "2025-04-08 10:20:09,926 - INFO - POST http://localhost:9200/book_bm25_index_v2/_refresh [status:200 duration:1.926s]\n",
      "2025-04-08 10:20:09,928 - INFO - Elasticsearch 인덱스 'book_bm25_index_v2' 새로고침 완료.\n",
      "2025-04-08 10:20:10,037 - INFO - Dense retriever (Milvus 벡터 검색) 설정 완료 (k=5).\n",
      "2025-04-08 10:20:10,053 - INFO - HEAD http://localhost:9200/ [status:200 duration:0.009s]\n",
      "2025-04-08 10:20:10,105 - INFO - Sparse retriever (Elasticsearch BM25) 설정 완료 (ElasticsearchRetriever 직접 사용, metadata_field 지정).\n",
      "2025-04-08 10:20:10,116 - INFO - Hybrid ensemble retriever 설정 완료 (Direct ES BM25: 0.5, Milvus Vector: 0.5).\n",
      "2025-04-08 10:20:10,121 - INFO - ISBN Merging Retriever 설정 완료 (Hybrid 결과 기반).\n",
      "2025-04-08 10:20:10,207 - INFO - RetrievalQA 체인 설정 완료 (Merged Hybrid Retriever 사용).\n"
     ]
    }
   ],
   "source": [
    "# Elasticsearch store 설정\n",
    "try:\n",
    "    logger.info(f\"Elasticsearch 연결 시도 중: {es_url}...\")\n",
    "    es_client = Elasticsearch(hosts=[es_url], request_timeout=120)\n",
    "    if not es_client.ping():\n",
    "        raise ConnectionError(\"Elasticsearch 연결 실패. 서버 상태 및 URL 확인 필요.\")\n",
    "    logger.info(\"Elasticsearch 연결 성공\")\n",
    "    if es_client.indices.exists(index=es_index_name):\n",
    "        logger.warning(f\"기존 Elasticsearch 인덱스 '{es_index_name}' 삭제 중...\")\n",
    "        es_client.indices.delete(index=es_index_name, ignore=[400, 404])\n",
    "        logger.info(f\"기존 Elasticsearch 인덱스 '{es_index_name}' 삭제 완료.\")\n",
    "    else:\n",
    "        logger.info(\n",
    "            f\"Elasticsearch 인덱스 '{es_index_name}' 존재하지 않음. 새로 생성됩니다.\"\n",
    "        )\n",
    "    es_store = ElasticsearchStore(\n",
    "        index_name=es_index_name,\n",
    "        es_connection=es_client,\n",
    "        strategy=ElasticsearchStore.ExactRetrievalStrategy(),\n",
    "    )\n",
    "    logger.info(\n",
    "        f\"Langchain ElasticsearchStore 인스턴스 초기화 완료 (인덱스: '{es_index_name}', BM25 검색 전용).\"\n",
    "    )\n",
    "    logger.info(f\"Elasticsearch에 문서 인덱싱 시작 (총 {len(texts)}개)...\")\n",
    "    actions = [\n",
    "        {\n",
    "            \"_index\": es_index_name,\n",
    "            \"_source\": {\"text\": texts[i], \"metadata\": metadatas[i]},\n",
    "        }\n",
    "        for i in range(len(texts))\n",
    "    ]\n",
    "    indexed_count, errors = helpers.bulk(es_client, actions, raise_on_error=False)\n",
    "    logger.info(f\"Elasticsearch 벌크 인덱싱 시도 완료: {indexed_count} 문서 성공.\")\n",
    "    if errors:\n",
    "        logger.error(\n",
    "            f\"Elasticsearch 벌크 인덱싱 중 오류 발생: {len(errors)}개 문서 실패.\"\n",
    "        )\n",
    "        for i, error in enumerate(errors[:5]):\n",
    "            logger.error(f\"  실패 {i+1}: {error}\")\n",
    "    es_client.indices.refresh(index=es_index_name)\n",
    "    logger.info(f\"Elasticsearch 인덱스 '{es_index_name}' 새로고침 완료.\")\n",
    "except ConnectionError as ce:\n",
    "    logger.error(f\"Elasticsearch 연결 실패: {ce}\")\n",
    "    raise\n",
    "except Exception as e:\n",
    "    logger.error(\n",
    "        f\"Elasticsearch 설정 또는 데이터 추가 중 오류 발생: {e}\", exc_info=True\n",
    "    )\n",
    "    raise\n",
    "\n",
    "dense_retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
    "logger.info(\"Dense retriever (Milvus 벡터 검색) 설정 완료 (k=5).\")\n",
    "try:\n",
    "    if \"es_client\" not in locals() or not es_client.ping():\n",
    "        raise ConnectionError(\n",
    "            \"Elasticsearch client가 준비되지 않았거나 연결할 수 없습니다.\"\n",
    "        )\n",
    "    sparse_retriever = ElasticsearchRetriever(\n",
    "        es_client=es_client,\n",
    "        index_name=es_index_name,\n",
    "        body_func=lambda query: {\n",
    "            \"size\": 5,\n",
    "            \"query\": {\"match\": {\"text\": {\"query\": query}}},\n",
    "        },\n",
    "        content_field=\"text\",\n",
    "        metadata_field=\"metadata\",\n",
    "    )\n",
    "    logger.info(\n",
    "        \"Sparse retriever (Elasticsearch BM25) 설정 완료 (ElasticsearchRetriever 직접 사용, metadata_field 지정).\"\n",
    "    )\n",
    "except ConnectionError as ce:\n",
    "    logger.error(f\"Elasticsearch 클라이언트 오류: {ce}\")\n",
    "    raise\n",
    "except Exception as e:\n",
    "    logger.error(f\"ElasticsearchRetriever 직접 설정 중 오류 발생: {e}\", exc_info=True)\n",
    "    raise\n",
    "\n",
    "hybrid_retriever = EnsembleRetriever(\n",
    "    retrievers=[sparse_retriever, dense_retriever], weights=[0.5, 0.5], c=60\n",
    ")\n",
    "logger.info(\n",
    "    \"Hybrid ensemble retriever 설정 완료 (Direct ES BM25: 0.5, Milvus Vector: 0.5).\"\n",
    ")\n",
    "merged_hybrid_retriever = ISBNMergingRetriever(base_retriever=hybrid_retriever)\n",
    "logger.info(\"ISBN Merging Retriever 설정 완료 (Hybrid 결과 기반).\")\n",
    "dpr_qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm_clova, retriever=merged_hybrid_retriever, return_source_documents=True\n",
    ")\n",
    "logger.info(\"RetrievalQA 체인 설정 완료 (Merged Hybrid Retriever 사용).\")\n",
    "\n",
    "MIN_INFO_LENGTH = 10\n",
    "previous_additional_question_embeddings = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 사용자 선호도 추출 프롬프트 (원본)\n",
    "\n",
    "extract_pref_prompt_v2 = PromptTemplate(\n",
    "    input_variables=[\"text\"],\n",
    "    template=\"\"\"\n",
    "다음 사용자 발화에서 사용자의 선호도 및 책에 대한 요구사항을 아래 JSON 형식으로 추출해라. 각 항목은 관련된 정보가 명확할 때만 명확한 항목에 포함(예: 소설 -> category)하고, 없다면 빈 리스트 [] 또는 빈 문자열 \"\"로 남겨라. 여러 개가 추출될 수 있는 항목은 리스트로 추출하라.\n",
    "사용자 입력에서 모호한 정보는 implicit info로 포함해라.\n",
    "존재하지 않는 사용자 선호도 정보는 임의로 생성하지 마라.\n",
    "\n",
    "입력: {{ text }}\n",
    "\n",
    "출력 형식 (JSON, 다른 설명 없이 JSON만 출력):\n",
    "{\n",
    "    \"title\": [<!-- 추출된 책 제목 -->],\n",
    "    \"author\": [<!-- 추출된 책 저자 -->],\n",
    "    \"category\": [<!-- 추출된 책 분류/장르 (예: 소설, 에세이, 기술 등) -->],\n",
    "    \"author_intro\": [<!-- 저자 특성 언급/요구사항 -->],\n",
    "    \"book_intro\": [<!-- 줄거리 관련 언급/요구사항 -->],\n",
    "    \"table_of_contents\": [<!-- 세부적인 키워드 언급/요구사항 -->],\n",
    "    \"purpose\": [<!-- 사용자의 독서 목적/이유 (예: 재미, 학습, 시간 때우기, 기분 등) -->],\n",
    "    \"implicit info\": [<!-- 추천해야 할 책에 대한 암시적 정보/특징/분위기 (예: 밝은 분위기, 특정 상황에 어울리는 책, 최신 기술 동향 등) -->]\n",
    "}\n",
    "\"\"\",\n",
    "    template_format=\"jinja2\",\n",
    ")\n",
    "\n",
    "\n",
    "# 2. 선호도 통합 프롬프트 (원본)\n",
    "\n",
    "\n",
    "\n",
    "consolidate_pref_prompt = PromptTemplate(\n",
    "    input_variables=[\"existing_preferences\", \"new_preferences\"],\n",
    "    template=\"\"\"\n",
    "기존에 수집된 사용자 선호도 정보와 새로 추출된 선호도 정보가 주어졌다. 두 정보를 지능적으로 통합하여 중복을 제거하고 관련 내용을 요약/결합하여 최종 선호도 목록을 생성해라.\n",
    "\n",
    "[기존 선호도]\n",
    "{{ existing_preferences }}\n",
    "\n",
    "[새로운 선호도]\n",
    "{{ new_preferences }}\n",
    "\n",
    "[통합된 최종 선호도 목록]\n",
    "(아래 목록 형태로만 출력, 각 항목은 문자열 리스트)\n",
    "- 항목1: [\"통합 내용1\", \"통합 내용2\"]\n",
    "- 항목2: [\"통합 내용3\"]\n",
    "...\n",
    "\"\"\",\n",
    "    template_format=\"jinja2\",\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# 3. Decision Prompt (원본)\n",
    "\n",
    "\n",
    "\n",
    "decision_prompt_template = PromptTemplate(\n",
    "    input_variables=[\"history\", \"query\", \"preferences\", \"role_instructions\"],\n",
    "    template=\"\"\"\n",
    "[대화 맥락]\n",
    "사용자 대화 내역:\n",
    "{{ history }}\n",
    "사용자의 최신 질문: \"{{ query }}\"\n",
    "수집된 사용자 선호도:\n",
    "{{ preferences }}\n",
    "\n",
    "[역할 및 목표]\n",
    "{{ role_instructions }}\n",
    "\n",
    "현재 대화 상황, 질문, 수집된 선호도를 분석하여 아래 두 가지 행동 중 하나만 결정하고 필요한 정보를 생성해라.\n",
    "- \"추천\": 사용자가 명시적으로 추천을 요청했거나, 사용자의 선호도 정보(예: 카테고리, 저자, 목적, 책 줄거리, 사용자 수준, 분위기 등)를 반드시 3개 이상 수집했을 때 추천.\n",
    "- \"추가 질문\": 정보가 부족하거나 모호할 때, 더 구체적인 선호도 정보를 얻기 위한 추가 질문을 생성.\n",
    "\n",
    "[출력 형식] (반드시 아래 형식만 정확히 따를 것)\n",
    "행동: <추천 또는 추가 질문>\n",
    "추가 질문: <\"추가 질문\" 행동일 경우 구체적인 질문 생성, \"추천\"일 경우 빈 문자열>\n",
    "\"\"\",\n",
    "    template_format=\"jinja2\",\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# 4. Final Query Generation Prompt\n",
    "\n",
    "\n",
    "\n",
    "literature_final_query_template = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "**명령:** 아래 제공된 모든 정보를 **반드시 종합적으로 분석**하여, 문학 도서 검색에 최적화된 **핵심 키워드 중심의 최종 검색 쿼리**를 **단 한 문장**으로 생성하라.\n",
    "\n",
    "**입력 정보:**\n",
    "[대화 요약]\n",
    "{{ history }}\n",
    "[사용자 요청]\n",
    "{{ query }}\n",
    "[페르소나 정보]\n",
    "{{ persona_info }} (감성, 분위기, 문체, 작가 스타일 등 문학적 요소 강조)\n",
    "[사용자 선호도 요약]\n",
    "{{ preferences }}\n",
    "\n",
    "**쿼리 생성 지침:**\n",
    "1.  **정보 통합:** 모든 입력 정보(대화 맥락, 요청, 페르소나, 선호도)를 누락 없이 반영하라.\n",
    "2.  **키워드 중심:** 검색 시스템이 효과적으로 인식할 수 있는 명사, 핵심 형용사 위주로 구성하라.\n",
    "3.  **문학적 뉘앙스:** 페르소나 정보와 선호도의 감성, 분위기, 문체 관련 내용을 키워드에 포함시키되, 검색 효율성을 해치지 않도록 명료하게 표현하라.\n",
    "4.  **단일 문장:** 최종 결과는 오직 검색 쿼리 한 문장이어야 한다.\n",
    "\n",
    "**출력 (오직 최종 검색 쿼리 한 문장, 다른 설명 절대 금지):**\n",
    "\"\"\",\n",
    "    input_variables=[\"history\", \"query\", \"persona_info\", \"preferences\"],\n",
    "    template_format=\"jinja2\",\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "science_final_query_template = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "**명령:** 아래 제공된 모든 정보를 **반드시 종합적으로 분석**하여, 과학/기술 도서 검색에 최적화된 **정확하고 구체적인 키워드 중심의 최종 검색 쿼리**를 **단 한 문장**으로 생성하라.\n",
    "\n",
    "**입력 정보:**\n",
    "[대화 요약]\n",
    "{{ history }}\n",
    "[사용자 요청]\n",
    "{{ query }}\n",
    "[페르소나 정보]\n",
    "정확하고 논리적인 분석, 최신 기술 동향, 전문 지식, 데이터 기반 접근\n",
    "[사용자 선호도 요약]\n",
    "{{ preferences }}\n",
    "\n",
    "**쿼리 생성 지침:**\n",
    "1.  **정보 통합:** 모든 입력 정보(대화 맥락, 요청, 페르소나, 선호도)를 누락 없이 반영하라.\n",
    "2.  **키워드 중심:** 검색 시스템이 효과적으로 인식할 수 있는 전문 용어, 기술 명칭, 핵심 개념 위주로 구성하라.\n",
    "3.  **정확성/구체성:** 페르소나 정보와 선호도의 기술 분야, 난이도, 최신성 요구 등을 명확한 키워드로 반영하라.\n",
    "4.  **단일 문장:** 최종 결과는 오직 검색 쿼리 한 문장이어야 한다.\n",
    "\n",
    "**출력 (오직 최종 검색 쿼리 한 문장, 다른 설명 절대 금지):**\n",
    "\"\"\",\n",
    "    input_variables=[\"history\", \"query\", \"persona_info\", \"preferences\"],\n",
    "    template_format=\"jinja2\",\n",
    ")\n",
    "\n",
    "general_final_query_template = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "**명령:** 아래 제공된 모든 정보를 **반드시 종합적으로 분석**하여, 범용 도서 검색에 가장 유용한 **핵심 키워드 중심의 최종 검색 쿼리**를 **단 한 문장**으로 생성하라.\n",
    "\n",
    "**입력 정보:**\n",
    "[대화 요약]\n",
    "{{ history }}\n",
    "[사용자 요청]\n",
    "{{ query }}\n",
    "[페르소나 정보]\n",
    "{{ persona_info }} (친절, 균형잡힌 정보, 다양한 분야 포괄)\n",
    "[사용자 선호도 요약]\n",
    "{{ preferences }}\n",
    "\n",
    "**쿼리 생성 지침:**\n",
    "1.  **정보 통합:** 모든 입력 정보(대화 맥락, 요청, 페르소나, 선호도)를 누락 없이 반영하라.\n",
    "2.  **키워드 중심:** 검색 시스템이 효과적으로 인식할 수 있는 명확한 명사, 핵심 요구사항 키워드 위주로 구성하라.\n",
    "3.  **균형과 명료성:** 다양한 선호도를 반영하되, 가장 핵심적인 요구사항을 명확한 키워드로 표현하여 검색 효율성을 높여라.\n",
    "4.  **단일 문장:** 최종 결과는 오직 검색 쿼리 한 문장이어야 한다.\n",
    "\n",
    "**출력 (오직 최종 검색 쿼리 한 문장, 다른 설명 절대 금지):**\n",
    "\"\"\",\n",
    "    input_variables=[\"history\", \"query\", \"persona_info\", \"preferences\"],\n",
    "    template_format=\"jinja2\",\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# 5. Refine Prompt\n",
    "\n",
    "literature_refine_template = PromptTemplate(\n",
    "    input_variables=[\"query\"],\n",
    "    template=\"\"\"\n",
    "**명령:** 주어진 [원본 검색 쿼리]를 아래 지침에 따라 **문학적 감성을 반영**하면서도 **검색에 용이한 간결한 단일 문장**으로 정제하라.\n",
    "\n",
    "**정제 지침:**\n",
    "1.  **유사성 표현 처리:** \"~~비슷한\", \"~ 같은\", \"~ 분위기의\" 등의 표현이 있으면, 해당 대상의 **문학적 특징(장르, 문체, 감정선, 시대 등)을 분석하여 명시적인 키워드로 확장**하라. 단, 원본의 책 제목이나 저자 이름은 직접 포함하지 마라.\n",
    "    *   예시 (입력: '데미안' 같은 성장 소설) -> 정제: 내면 성찰을 다루는 철학적 성장 소설 추천\n",
    "2.  **핵심 의도 유지:** 원본 쿼리의 핵심 검색 의도는 반드시 보존해야 한다.\n",
    "3.  **간결성 및 명확성:** 불필요한 수식어나 설명은 제거하고, 검색 키워드가 될 수 있는 명료한 단어 위주로 구성하라.\n",
    "4.  **문학적 표현:** 서정적이거나 감성적인 표현을 사용하되, 검색 시스템이 이해할 수 있는 수준을 유지하라.\n",
    "\n",
    "[원본 검색 쿼리]\n",
    "{{ query }}\n",
    "\n",
    "**출력 (오직 정제된 단일 검색 쿼리 문장, 다른 설명 절대 금지):**\n",
    "[정제된 검색 쿼리]\n",
    "\"\"\",\n",
    "    template_format=\"jinja2\",\n",
    ")\n",
    "\n",
    "science_refine_template = PromptTemplate(\n",
    "    input_variables=[\"query\"],\n",
    "    template=\"\"\"\n",
    "**명령:** 주어진 [원본 검색 쿼리]를 아래 지침에 따라 **객관적이고 논리적인 표현**을 사용하여 **정확하고 간결한 단일 문장**으로 정제하라.\n",
    "\n",
    "**정제 지침:**\n",
    "1.  **유사성 표현 처리:** \"~~비슷한\", \"~ 같은\" 등의 표현이 있으면, 해당 대상의 **기술적 특징(핵심 기술, 분야, 방법론, 난이도 등)을 분석하여 명시적인 키워드로 확장**하라. 단, 원본의 책 제목이나 저자 이름은 직접 포함하지 마라.\n",
    "    *   예시 (입력: '핸즈온 머신러닝' 같은 책) -> 정제: 사이킷런과 텐서플로우 예제 중심의 실습형 머신러닝 입문서 추천\n",
    "2.  **핵심 의도 유지:** 원본 쿼리의 핵심 검색 의도는 반드시 보존해야 한다.\n",
    "3.  **간결성 및 정확성:** 불필요한 표현은 제거하고, 정확한 기술 용어와 핵심 개념 위주로 구성하라.\n",
    "4.  **객관적 표현:** 주관적이거나 모호한 표현 대신, 명확하고 객관적인 과학/기술 용어를 사용하라.\n",
    "\n",
    "[원본 검색 쿼리]\n",
    "{{ query }}\n",
    "\n",
    "**출력 (오직 정제된 단일 검색 쿼리 문장, 다른 설명 절대 금지):**\n",
    "[정제된 검색 쿼리]\n",
    "\"\"\",\n",
    "    template_format=\"jinja2\",\n",
    ")\n",
    "\n",
    "general_refine_template = PromptTemplate(\n",
    "    input_variables=[\"query\"],\n",
    "    template=\"\"\"\n",
    "**명령:** 주어진 [원본 검색 쿼리]를 아래 지침에 따라 **사용자 의도를 명확히 반영**하여 **친절하고 이해하기 쉬운 간결한 단일 문장**으로 정제하라.\n",
    "\n",
    "**정제 지침:**\n",
    "1.  **유사성 표현 처리:** \"~~비슷한\", \"~ 같은\", \"~ 분위기의\" 등의 표현이 있으면, 해당 대상의 **주요 특징(장르, 핵심 소재, 스타일, 목적 등)을 분석하여 명시적인 키워드로 확장**하라. 단, 원본의 책 제목이나 저자 이름은 직접 포함하지 마라.\n",
    "    *   예시 (입력: '나미야 잡화점의 기적' 같은 힐링 소설) -> 정제: 따뜻한 위로와 감동을 주는 일본 힐링 소설 추천\n",
    "2.  **핵심 의도 유지:** 원본 쿼리의 핵심 검색 의도는 반드시 보존해야 한다.\n",
    "3.  **간결성 및 명확성:** 불필요한 수식어나 모호한 표현은 제거하고, 사용자의 요구사항을 명확히 나타내는 단어 위주로 구성하라.\n",
    "4.  **친절한 표현:** 딱딱하거나 전문적이지 않은, 일반 사용자가 이해하기 쉬운 표현을 사용하라.\n",
    "\n",
    "[원본 검색 쿼리]\n",
    "{{ query }}\n",
    "\n",
    "**출력 (오직 정제된 단일 검색 쿼리 문장, 다른 설명 절대 금지):**\n",
    "[정제된 검색 쿼리]\n",
    "\"\"\",\n",
    "    template_format=\"jinja2\",\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# 6. Query Expansion Prompt\n",
    "\n",
    "literature_expansion_template = PromptTemplate(\n",
    "    input_variables=[\"query\"],\n",
    "    template=\"\"\"\n",
    "**명령:** 주어진 [원본 검색 쿼리]의 **핵심 의도를 반드시 유지**하면서, **문학적 감성과 관련된 다양한 측면(유사 장르, 다른 시대, 관련 주제, 다른 작가 등)을 탐색**할 수 있는 **관련성 높은 확장 검색 쿼리 3개**를 생성하라.\n",
    "\n",
    "**확장 지침:**\n",
    "1.  **핵심 의도 유지:** 확장 쿼리는 원본 쿼리의 주제나 분위기에서 크게 벗어나서는 안 된다.\n",
    "2.  **문학적 다양성 추구:** 원본 쿼리와 관련되면서도 다른 각도(예: 다른 감정선, 문체, 배경)에서 탐색할 수 있도록 다양하게 생성하라.\n",
    "3.  **관련성:** 생성된 쿼리는 원본 쿼리와 명확한 관련성을 가져야 한다.\n",
    "4.  **형식 엄수:** **번호(1., 2., 3.)가 매겨진 목록 형식**으로, 각 줄에 확장 쿼리 하나씩만 출력하라. 다른 설명은 절대 포함하지 마라.\n",
    "\n",
    "[원본 검색 쿼리]\n",
    "{{ query }}\n",
    "\n",
    "**출력 (오직 번호 매겨진 확장 쿼리 목록 3개, 다른 설명 절대 금지):**\n",
    "[확장된 검색 쿼리 목록]\n",
    "\"\"\",\n",
    "    template_format=\"jinja2\",\n",
    ")\n",
    "\n",
    "science_expansion_template = PromptTemplate(\n",
    "    input_variables=[\"query\"],\n",
    "    template=\"\"\"\n",
    "**명령:** 주어진 [원본 검색 쿼리]의 **핵심 의도를 반드시 유지**하면서, **과학/기술 관련 하위 주제, 관련 기술, 응용 분야, 다른 접근법 등을 탐색**할 수 있는 **관련성 높은 확장 검색 쿼리 3개**를 생성하라.\n",
    "\n",
    "**확장 지침:**\n",
    "1.  **핵심 의도 유지:** 확장 쿼리는 원본 쿼리의 기술 분야나 주제에서 크게 벗어나서는 안 된다.\n",
    "2.  **기술적 다양성 추구:** 원본 쿼리와 관련되면서도 다른 각도(예: 심화 이론, 실용적 적용, 다른 프로그래밍 언어, 최신 연구)에서 탐색할 수 있도록 다양하게 생성하라.\n",
    "3.  **관련성:** 생성된 쿼리는 원본 쿼리와 명확한 기술적/논리적 관련성을 가져야 한다.\n",
    "4.  **형식 엄수:** **번호(1., 2., 3.)가 매겨진 목록 형식**으로, 각 줄에 확장 쿼리 하나씩만 출력하라. 다른 설명은 절대 포함하지 마라.\n",
    "\n",
    "[원본 검색 쿼리]\n",
    "{{ query }}\n",
    "\n",
    "**출력 (오직 번호 매겨진 확장 쿼리 목록 3개, 다른 설명 절대 금지):**\n",
    "[확장된 검색 쿼리 목록]\n",
    "\"\"\",\n",
    "    template_format=\"jinja2\",\n",
    ")\n",
    "\n",
    "general_expansion_template = PromptTemplate(\n",
    "    input_variables=[\"query\"],\n",
    "    template=\"\"\"\n",
    "**명령:** 주어진 [원본 검색 쿼리]의 **핵심 의도를 반드시 유지**하면서, **관련 주제, 다른 관점, 사용자의 잠재적 관심사 등 다양한 분야를 탐색**할 수 있는 **관련성 높은 확장 검색 쿼리 3개**를 생성하라.\n",
    "\n",
    "**확장 지침:**\n",
    "1.  **핵심 의도 유지:** 확장 쿼리는 원본 쿼리의 핵심 주제나 요구사항에서 크게 벗어나서는 안 된다.\n",
    "2.  **주제 다양성 추구:** 원본 쿼리와 관련되면서도 다른 각도(예: 유사하지만 다른 장르, 관련 인물 이야기, 사회적 배경)에서 탐색할 수 있도록 다양하게 생성하라.\n",
    "3.  **관련성:** 생성된 쿼리는 원본 쿼리와 명확한 관련성을 가져야 한다.\n",
    "4.  **형식 엄수:** **번호(1., 2., 3.)가 매겨진 목록 형식**으로, 각 줄에 확장 쿼리 하나씩만 출력하라. 다른 설명은 절대 포함하지 마라.\n",
    "\n",
    "[원본 검색 쿼리]\n",
    "{{ query }}\n",
    "\n",
    "**출력 (오직 번호 매겨진 확장 쿼리 목록 3개, 다른 설명 절대 금지):**\n",
    "[확장된 검색 쿼리 목록]\n",
    "\"\"\",\n",
    "    template_format=\"jinja2\",\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# 7. Re_ranking Prompt (원본)\n",
    "re_ranking_prompt = PromptTemplate(\n",
    "    input_variables=[\"query\", \"documents\"],\n",
    "    template=\"\"\"\n",
    "사용자의 검색 쿼리는 다음과 같습니다: \"{{ query }}\"\n",
    "다음은 검색된 도서 목록입니다 (내용은 일부만 표시됨):\n",
    "{% for doc in documents %}\n",
    "{{ loop.index }}. 제목: {{ doc.metadata.get('title', '제목 없음') }}, 저자: {{ doc.metadata.get('author', '저자 없음') }}, 내용 일부: {{ doc.page_content | truncate(200) }}\n",
    "{% endfor %}\n",
    "\n",
    "위 검색 결과를 사용자의 검색 쿼리 \"{{ query }}\"와의 관련성 및 문서 내용의 충실도를 종합적으로 고려하여, 가장 관련성이 높은 도서를 목록의 맨 위로 배치하고, 결과를 도서 제목과 저자만 포함하는 다음 형식으로 출력하라.\n",
    "\n",
    "[출력 형식 예시]\n",
    "1. 제목: <가장 관련성 높은 책 제목>, 저자: <저자 이름>\n",
    "2. 제목: <두 번째 관련성 높은 책 제목>, 저자: <저자 이름>\n",
    "...\n",
    "[리랭킹된 도서 목록]\n",
    "\"\"\",\n",
    "    template_format=\"jinja2\",\n",
    ")\n",
    "\n",
    "# 8. HyDE Generation Prompt (원본)\n",
    "hyde_generation_prompt = PromptTemplate(\n",
    "    input_variables=[\"query\"],\n",
    "    template=\"\"\"\n",
    "다음 검색 쿼리에 완벽하게 부합하는 **이상적인 가상의 책**을 추천하고, 이를 기반으로 **간결한 요약(2-3 문장)**을 생성해라. 이 요약은 해당 쿼리로 책을 찾는 사용자가 가장 만족할 만한 내용을 담아야 한다. 오직 생성된 요약 텍스트만 출력하라.\n",
    "\n",
    "[검색 쿼리]\n",
    "{{ query }}\n",
    "\n",
    "[가상의 책 요약]\n",
    "\"\"\",\n",
    "    template_format=\"jinja2\",\n",
    ")\n",
    "\n",
    "# 9. Persona Role Instructions (원본)\n",
    "literature_role = \"너는 감성적이고 문학적인 도서 추천 챗봇이다. 사용자의 감정과 취향을 깊이 이해하고 공감하는 말투로 문학적인 표현을 사용하여 책을 추천해라.\"\n",
    "science_role = \"너는 정확하고 논리적인 과학/기술 도서 추천 챗봇이다. 사용자의 지식 수준과 관심 분야를 파악하고, 최신 정보와 기술 동향을 반영하여 체계적으로 책을 추천해라.\"\n",
    "general_role = \"너는 친절하고 신뢰할 수 있는 범용 도서 추천 챗봇이다. 친근한 말투로 다양한 분야의 책에 대해 균형 잡힌 시각으로 정보를 제공하고, 사용자의 요구사항에 맞춰 명확하고 이해하기 쉽게 책을 추천해라.\"\n",
    "\n",
    "# 10. Hyde Keyword Prompt (원본)\n",
    "hyde_keyword_prompt = PromptTemplate(\n",
    "    input_variables=[\"hyde_summary\"],\n",
    "    template=\"\"\"\n",
    "다음은 사용자의 질문에 이상적으로 부합하는 가상의 책 요약입니다:\n",
    "\"{{ hyde_summary }}\"\n",
    "\n",
    "이 요약 내용에서 **핵심 키워드 5개**를 추출하여 쉼표(,)로 구분하여 나열해라. 오직 키워드 목록만 출력하라.\n",
    "\n",
    "[핵심 키워드 목록]\n",
    "\"\"\",\n",
    "    template_format=\"jinja2\",\n",
    ")\n",
    "\n",
    "# 11. 추천 인삿말 생성 프롬프트\n",
    "recommendation_intro_prompt = PromptTemplate(\n",
    "    input_variables=[\"query\", \"persona_info\"],\n",
    "    template=\"\"\"\n",
    "사용자의 도서 추천 요청은 다음과 같습니다:\n",
    "\"{{ query }}\"\n",
    "\n",
    "챗봇은 다음과 같은 역할을 맡고 있습니다:\n",
    "\"{{ persona_info }}\"\n",
    "\n",
    "위 내용을 고려하여, 추천 리스트를 자연스럽게 시작하는 인삿말을 한두 문장으로 만들어주세요.\n",
    "예: \"이런 책들은 어떠세요?\", \"다음 책들을 추천드려요!\" 등\n",
    "\"\"\",\n",
    "    template_format=\"jinja2\",\n",
    ")\n",
    "\n",
    "## 12. 추천 마무리 멘트 프롬프트\n",
    "recommendation_outro_prompt = PromptTemplate(\n",
    "    input_variables=[\"query\", \"persona_info\"],\n",
    "    template=\"\"\"\n",
    "[사용자의 추천 요청]\n",
    "\"{{ query }}\"\n",
    "\n",
    "[챗봇의 역할]\n",
    "{{ persona_info }}\n",
    "\n",
    "위 정보를 고려하여, 추천 리스트의 **마무리 인사말**을 자연스럽고 친근한 말투로 1~2문장 생성하세요.  \n",
    "사용자가 마음에 드는 책을 발견했기를 바라는 따뜻한 톤이면 좋습니다. 너무 딱딱하지 않게, 대화를 부드럽게 끝맺는 느낌으로 작성하세요.\n",
    "\n",
    "[예시]\n",
    "- \"하나쯤 읽고 싶은 책이 생기셨길 바라요 :)\"\n",
    "- \"마음에 드는 책이 있다면 참 좋겠네요!\"\n",
    "- \"더 궁금한 책이 있다면 언제든지 말씀해주세요.\"\n",
    "\n",
    "[추천 마무리 멘트]\n",
    "\"\"\",\n",
    "    template_format=\"jinja2\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def async_invoke(chain: LLMChain, vars_dict: dict, step_name: str) -> dict:\n",
    "    \"\"\"LLMChain을 비동기로 실행하고 로깅\"\"\"\n",
    "    try:\n",
    "        # 입력 변수 일부 로깅\n",
    "        log_vars = {\n",
    "            k: (v[:100] + \"...\" if isinstance(v, str) and len(v) > 100 else v)\n",
    "            for k, v in vars_dict.items()\n",
    "        }\n",
    "        logger.debug(f\"[{step_name}] Chain 호출 시작. 입력 변수 일부: {log_vars}\")\n",
    "        # chain.invoke를 별도 스레드에서 실행하여 비동기 처리\n",
    "        result = await asyncio.to_thread(chain.invoke, vars_dict)\n",
    "        result_text = result.get(\"text\", \"\")\n",
    "        # 결과 텍스트 일부 로깅\n",
    "        log_result = (\n",
    "            result_text[:200] + \"...\" if len(result_text) > 200 else result_text\n",
    "        )\n",
    "        logger.debug(f\"[{step_name}] Chain 호출 완료. 결과 일부: {log_result}\")\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        logger.error(f\"[{step_name}] Chain 호출 중 예외 발생: {e}\", exc_info=True)\n",
    "        return {\"text\": \"\"}  # 오류 시 빈 결과 반환\n",
    "\n",
    "\n",
    "async def async_invoke_llm(prompt: str, step_name: str) -> str:\n",
    "    \"\"\"LLM 직접 호출을 비동기로 실행하고 로깅\"\"\"\n",
    "    try:\n",
    "        # 프롬프트 일부 로깅\n",
    "        log_prompt = prompt[:200] + \"...\" if len(prompt) > 200 else prompt\n",
    "        logger.debug(f\"[{step_name}] LLM 호출 시작. 프롬프트 일부: {log_prompt}\")\n",
    "        # llm.invoke를 별도 스레드에서 실행\n",
    "        response = await asyncio.to_thread(llm_clova.invoke, prompt)\n",
    "\n",
    "        # 응답 객체에서 텍스트 추출\n",
    "        if hasattr(response, \"content\"):\n",
    "            result_text = response.content.strip()\n",
    "        elif isinstance(response, str):  # ChatClovaX가 문자열 직접 반환하는 경우\n",
    "            result_text = response.strip()\n",
    "        else:\n",
    "            result_text = str(response).strip()\n",
    "\n",
    "        # 응답 텍스트 일부 로깅\n",
    "        log_result = (\n",
    "            result_text[:200] + \"...\" if len(result_text) > 200 else result_text\n",
    "        )\n",
    "        logger.debug(f\"[{step_name}] LLM 호출 완료. 응답 일부: {log_result}\")\n",
    "        return result_text\n",
    "    except Exception as e:\n",
    "        logger.error(f\"[{step_name}] LLM 호출 중 예외 발생: {e}\", exc_info=True)\n",
    "        return \"\"  # 오류 시 빈 문자열"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _extract_metadata_field(doc: Document, field: str, default: str = \"N/A\") -> str:\n",
    "    \"\"\"\n",
    "    Document의 다양한 metadata 구조에서 필드 값을 추출 (예: title, ISBN 등).\n",
    "    \"\"\"\n",
    "    candidates = []\n",
    "\n",
    "    # Case 1: 평평한 구조\n",
    "    candidates.append(doc.metadata)\n",
    "\n",
    "    # Case 2: 1단계 중첩\n",
    "    if \"metadata\" in doc.metadata and isinstance(doc.metadata[\"metadata\"], dict):\n",
    "        candidates.append(doc.metadata[\"metadata\"])\n",
    "\n",
    "        # Case 3: 2단계 중첩\n",
    "        inner = doc.metadata[\"metadata\"]\n",
    "        if \"metadata\" in inner and isinstance(inner[\"metadata\"], dict):\n",
    "            candidates.append(inner[\"metadata\"])\n",
    "\n",
    "    # Case 4: Elasticsearch 구조 (_source.metadata)\n",
    "    if \"_source\" in doc.metadata and isinstance(doc.metadata[\"_source\"], dict):\n",
    "        source_meta = doc.metadata[\"_source\"].get(\"metadata\", {})\n",
    "        if isinstance(source_meta, dict):\n",
    "            candidates.append(source_meta)\n",
    "\n",
    "    # 실제 값 추출\n",
    "    for meta in candidates:\n",
    "        if field in meta:\n",
    "            return (\n",
    "                meta[field].strip()\n",
    "                if isinstance(meta[field], str)\n",
    "                else str(meta[field])\n",
    "            )\n",
    "\n",
    "    return default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseRAGPipeline:\n",
    "    def __init__(\n",
    "        self, config, llm, embeddings, vectorstore, es_store, retriever, documents\n",
    "    ):\n",
    "        self.config = config  # config에 페르소나별 템플릿 및 가중치 포함\n",
    "        self.llm = llm\n",
    "        self.embeddings = embeddings\n",
    "        self.vectorstore = vectorstore\n",
    "        self.es_store = es_store\n",
    "        self.retriever = retriever\n",
    "        self.documents = documents\n",
    "\n",
    "        self.user_history: List[str] = []\n",
    "        self.llm_history: List[str] = []\n",
    "        self.user_preferences: Dict[str, List[str]] = self._initialize_preferences()\n",
    "        self.preferences_text: str = \"수집된 선호도 없음\"\n",
    "        self.preference_update_count: int = 0\n",
    "        self.last_recommendations: List[Document] = []\n",
    "        self.last_action: Optional[str] = None\n",
    "\n",
    "        # 페르소나별 프롬프트 체인 생성\n",
    "        self.extract_pref_chain = LLMChain(\n",
    "            llm=self.llm, prompt=self.config[\"pref_extraction_template\"]\n",
    "        )\n",
    "        self.decision_chain = LLMChain(\n",
    "            llm=self.llm, prompt=self.config.get(\"decision_template\", None)\n",
    "        )\n",
    "        self.final_query_generation_chain = LLMChain(\n",
    "            llm=self.llm, prompt=self.config[\"final_query_template\"]\n",
    "        )\n",
    "        self.refine_chain = LLMChain(\n",
    "            llm=self.llm, prompt=self.config[\"refine_template\"]\n",
    "        )\n",
    "        self.query_expansion_chain = LLMChain(\n",
    "            llm=self.llm, prompt=self.config[\"expansion_template\"]\n",
    "        )\n",
    "        self.re_ranking_chain = LLMChain(\n",
    "            llm=self.llm, prompt=self.config.get(\"re_ranking_template\", None)\n",
    "        )\n",
    "        self.hyde_generation_chain = LLMChain(\n",
    "            llm=self.llm, prompt=self.config.get(\"hyde_generation_template\", None)\n",
    "        )\n",
    "        self.hyde_keyword_chain = LLMChain(\n",
    "            llm=self.llm, prompt=self.config.get(\"hyde_keyword_template\", None)\n",
    "        )\n",
    "        self.recommendation_intro_chain = LLMChain(\n",
    "            llm=self.llm, prompt=self.config[\"recommendation_intro_template\"]\n",
    "        )\n",
    "        self.recommendation_outro_chain = LLMChain(\n",
    "            llm=self.llm, prompt=self.config[\"recommendation_outro_template\"]\n",
    "        )\n",
    "\n",
    "    def _initialize_preferences(self) -> Dict[str, List[str]]:\n",
    "        return {\n",
    "            \"title\": [],\n",
    "            \"author\": [],\n",
    "            \"category\": [],\n",
    "            \"author_intro\": [],\n",
    "            \"book_intro\": [],\n",
    "            \"table_of_contents\": [],\n",
    "            \"purpose\": [],\n",
    "            \"implicit info\": [],\n",
    "        }\n",
    "\n",
    "    def robust_parse_decision_response(\n",
    "        self, response_text: str\n",
    "    ) -> tuple[Optional[str], str]:\n",
    "        action = None\n",
    "        additional_question = \"\"\n",
    "        action_match = re.search(r'행동\\s*[:：]\\s*\"?([^\"\\n]+)\"?', response_text)\n",
    "        if action_match:\n",
    "            action = action_match.group(1).strip().lower()\n",
    "            if action not in [\"추천\", \"추가 질문\"]:\n",
    "                logger.warning(\n",
    "                    f\"알 수 없는 행동 값 파싱됨: '{action}'. '추가 질문'으로 처리.\"\n",
    "                )\n",
    "                action = \"추가 질문\"\n",
    "        follow_match = re.search(\n",
    "            r'추가\\s*질문\\s*[:：]\\s*\"?(.+)\"?', response_text, re.DOTALL\n",
    "        )\n",
    "        if follow_match:\n",
    "            additional_question = follow_match.group(1).strip()\n",
    "        if action == \"추가 질문\" and not additional_question:\n",
    "            additional_question = \"어떤 점이 궁금하신가요? 또는 어떤 책을 찾으시나요?\"\n",
    "            logger.warning(\n",
    "                f\"행동은 '추가 질문'이나 질문 내용 없음. 기본 질문 사용: '{additional_question}'\"\n",
    "            )\n",
    "        if not action:\n",
    "            logger.warning(\n",
    "                f\"행동 결정 파싱 실패: '{response_text}'. 기본 '추가 질문'으로 처리.\"\n",
    "            )\n",
    "            action = \"추가 질문\"\n",
    "            if not additional_question:\n",
    "                additional_question = \"요청을 이해하기 어려웠습니다. 어떤 책을 찾으시는지 다시 말씀해주시겠어요?\"\n",
    "        logger.info(\n",
    "            f\"행동 결정 파싱 결과: 행동='{action}', 추가 질문='{additional_question[:50]}...'\"\n",
    "        )\n",
    "        return action, additional_question\n",
    "\n",
    "    async def update_preferences_from_input(self, user_input: str) -> None:\n",
    "        logger.info(f\"사용자 입력에서 선호도 추출 시작: '{user_input[:100]}...'\")\n",
    "        extract_result = await async_invoke(\n",
    "            self.extract_pref_chain, {\"text\": user_input}, \"선호도 추출\"\n",
    "        )\n",
    "        extracted_text = extract_result.get(\"text\", \"{}\")\n",
    "        extracted_prefs: Dict[str, List[str]] = {}\n",
    "        try:\n",
    "            json_match = re.search(r\"\\{.*\\}\", extracted_text, re.DOTALL)\n",
    "            if json_match:\n",
    "                extracted_prefs_raw = json.loads(json_match.group(0))\n",
    "                defined_keys = self.user_preferences.keys()\n",
    "                for key, value in extracted_prefs_raw.items():\n",
    "                    if key in defined_keys:\n",
    "                        vals_to_add = []\n",
    "                        if isinstance(value, list):\n",
    "                            vals_to_add = [\n",
    "                                str(item).strip()\n",
    "                                for item in value\n",
    "                                if item and str(item).strip()\n",
    "                            ]\n",
    "                        elif isinstance(value, str) and value.strip():\n",
    "                            vals_to_add = [value.strip()]\n",
    "                        if vals_to_add:\n",
    "                            extracted_prefs[key] = vals_to_add\n",
    "                    else:\n",
    "                        logger.warning(\n",
    "                            f\"추출된 선호도 키 '{key}'가 정의된 형식에 없음. 무시.\"\n",
    "                        )\n",
    "            else:\n",
    "                logger.warning(\n",
    "                    f\"선호도 추출 결과에서 JSON 객체를 찾을 수 없음: {extracted_text}\"\n",
    "                )\n",
    "        except json.JSONDecodeError as e:\n",
    "            logger.error(\n",
    "                f\"선호도 추출 결과 JSON 파싱 실패: {e}. 원본 텍스트: {extracted_text}\"\n",
    "            )\n",
    "        except Exception as e:\n",
    "            logger.error(f\"선호도 추출/처리 중 예외 발생: {e}\", exc_info=True)\n",
    "        if not extracted_prefs:\n",
    "            logger.info(\"새로 추출된 유효한 선호도 정보가 없음\")\n",
    "            return\n",
    "        updated_something = False\n",
    "        for key, new_values in extracted_prefs.items():\n",
    "            existing_values_set = set(self.user_preferences.get(key, []))\n",
    "            added_values = [v for v in new_values if v not in existing_values_set]\n",
    "            if added_values:\n",
    "                self.user_preferences[key].extend(added_values)\n",
    "                updated_something = True\n",
    "                logger.info(f\"선호도 업데이트됨 [{key}]: {self.user_preferences[key]}\")\n",
    "        if updated_something:\n",
    "            self.preference_update_count += 1\n",
    "            logger.info(\n",
    "                f\"선호도 업데이트 완료. 누적 업데이트 횟수: {self.preference_update_count}\"\n",
    "            )\n",
    "            self._update_preferences_text()\n",
    "        else:\n",
    "            logger.info(\"기존 선호도에서 변경된 내용 없음.\")\n",
    "\n",
    "    def _update_preferences_text(self):\n",
    "        pref_items = []\n",
    "        display_key_map = {\n",
    "            \"title\": \"관련 제목\",\n",
    "            \"author\": \"선호 저자\",\n",
    "            \"category\": \"선호 장르/분류\",\n",
    "            \"author_intro\": \"저자 관련 요구\",\n",
    "            \"book_intro\": \"내용 관련 요구\",\n",
    "            \"table_of_contents\": \"목차/키워드 요구\",\n",
    "            \"purpose\": \"독서 목적\",\n",
    "            \"implicit info\": \"기타 희망 사항/분위기\",\n",
    "        }\n",
    "        for key, values in self.user_preferences.items():\n",
    "            if values:\n",
    "                display_key = display_key_map.get(key, key)\n",
    "                pref_items.append(f\"- {display_key}: {', '.join(values)}\")\n",
    "        self.preferences_text = (\n",
    "            \"\\n\".join(pref_items) if pref_items else \"수집된 선호도 없음\"\n",
    "        )\n",
    "        logger.debug(f\"업데이트된 선호도 요약 텍스트:\\n{self.preferences_text}\")\n",
    "\n",
    "    async def get_final_query(self, current_user_query: str) -> str:\n",
    "        logger.info(\"최종 검색 쿼리 생성 시작\")\n",
    "        persona_info = self.config.get(\"persona_info\", \"기본 정보\")\n",
    "        final_query_vars = {\n",
    "            \"history\": \"\\n\".join(self.user_history[-5:] + self.llm_history[-5:]),\n",
    "            \"query\": current_user_query,\n",
    "            \"persona_info\": persona_info,\n",
    "            \"preferences\": self.preferences_text,\n",
    "        }\n",
    "        result_gen = await async_invoke(\n",
    "            self.final_query_generation_chain, final_query_vars, \"선호도 종합 쿼리 생성\"\n",
    "        )\n",
    "        generated_query = result_gen.get(\"text\", \"\").strip()\n",
    "        logger.info(f\"LLM 생성 쿼리 (정제 전): '{generated_query}'\")\n",
    "        query_to_use = generated_query\n",
    "        if generated_query:\n",
    "            refine_result = await async_invoke(\n",
    "                self.refine_chain, {\"query\": generated_query}, \"쿼리 정제\"\n",
    "            )\n",
    "            refined_query = refine_result.get(\"text\", \"\").strip().strip('\"')\n",
    "            logger.info(f\"정제된 쿼리: '{refined_query}'\")\n",
    "            negative_keywords = [\n",
    "                \"없\",\n",
    "                \"못\",\n",
    "                \"않\",\n",
    "                \"오류\",\n",
    "                \"잘못\",\n",
    "                \"알 수 없\",\n",
    "                \"죄송\",\n",
    "                \"필요\",\n",
    "            ]\n",
    "            is_invalid_refinement = (\n",
    "                not refined_query\n",
    "                or len(refined_query) < 3\n",
    "                or any(keyword in refined_query for keyword in negative_keywords)\n",
    "                or \"{\" in refined_query\n",
    "                or \"}\" in refined_query\n",
    "                or refined_query.lower() == generated_query.lower()\n",
    "            )\n",
    "            if is_invalid_refinement:\n",
    "                logger.warning(\n",
    "                    f\"정제된 쿼리('{refined_query}')가 유효하지 않아 정제 전 쿼리('{generated_query}') 사용.\"\n",
    "                )\n",
    "            else:\n",
    "                query_to_use = refined_query\n",
    "        else:\n",
    "            logger.warning(\"선호도 종합 쿼리 생성 실패. 원본 사용자 쿼리 사용.\")\n",
    "            query_to_use = current_user_query\n",
    "        if not query_to_use or len(query_to_use) < 3:\n",
    "            logger.warning(\n",
    "                f\"최종 결정된 쿼리('{query_to_use}')가 너무 짧거나 비어있어 원본 사용자 쿼리('{current_user_query}') 사용.\"\n",
    "            )\n",
    "            query_to_use = current_user_query\n",
    "        logger.info(f\"최종 결정된 검색 쿼리: '{query_to_use}'\")\n",
    "        return query_to_use\n",
    "\n",
    "    async def _summarize_chunk_with_llm(self, text: str) -> str:\n",
    "        if not text or len(text.strip()) < MIN_INFO_LENGTH:\n",
    "            return \"요약할 정보가 충분하지 않습니다.\"\n",
    "        max_len = 4000\n",
    "        truncated_text = text[:max_len].strip()\n",
    "        if not truncated_text:\n",
    "            return \"요약할 정보가 없습니다.\"\n",
    "        prompt = f\"\"\"\n",
    "        다음 책 정보를 2~3문장으로 핵심 내용만 요약해줘.  \n",
    "        말투는 너무 딱딱하지 않고, 사용자에게 설명하듯 **자연스럽고 친근한 어조**로 해줘.  \n",
    "        예를 들어 \"~있다\" 대신 \"~있어요\", \"~이다\" 대신 \"~예요\"처럼 말해줘.:\\n\\n{truncated_text}\\n\\n요약:\"\n",
    "        \"\"\"\n",
    "        summary = await async_invoke_llm(prompt, \"청크 요약\")\n",
    "        if (\n",
    "            not summary\n",
    "            or len(summary) < 10\n",
    "            or \"요약할 정보가\" in summary\n",
    "            or \"죄송\" in summary\n",
    "            or \"모르겠\" in summary\n",
    "        ):\n",
    "            fallback_summary = text[:300].strip() + (\"...\" if len(text) > 300 else \"\")\n",
    "            logger.warning(\n",
    "                f\"LLM 요약 실패 또는 부적절. Fallback 요약 사용: '{fallback_summary[:100]}...'\"\n",
    "            )\n",
    "            return (\n",
    "                fallback_summary\n",
    "                if fallback_summary\n",
    "                else \"별도의 상세 정보가 충분치 않습니다.\"\n",
    "            )\n",
    "        return summary\n",
    "\n",
    "    def _merge_documents_by_isbn(self, isbn: str) -> Optional[Document]:\n",
    "        if not isbn:\n",
    "            logger.warning(\"ISBN 없이 문서 병합 시도됨.\")\n",
    "            return None\n",
    "        docs_for_isbn = [\n",
    "            doc\n",
    "            for doc in self.documents\n",
    "            if str(doc.metadata.get(\"ISBN\", \"\")).strip() == str(isbn).strip()\n",
    "        ]\n",
    "        if not docs_for_isbn:\n",
    "            logger.warning(\n",
    "                f\"ISBN '{isbn}'에 해당하는 문서를 마스터 목록에서 찾을 수 없음.\"\n",
    "            )\n",
    "            return None\n",
    "        combined_text = \"\\n\\n---\\n\\n\".join(\n",
    "            doc.page_content for doc in docs_for_isbn if doc.page_content\n",
    "        ).strip()\n",
    "        merged_meta = dict(docs_for_isbn[0].metadata)\n",
    "        logger.debug(\n",
    "            f\"ISBN '{isbn}' 문서 병합 완료 (전체 원본 기준). 병합된 청크 수: {len(docs_for_isbn)}, 총 텍스트 길이: {len(combined_text)}\"\n",
    "        )\n",
    "        return Document(page_content=combined_text, metadata=merged_meta)\n",
    "\n",
    "    async def _embedding_rerank_documents(\n",
    "        self, query: str, documents: List[Document]\n",
    "    ) -> List[Document]:\n",
    "        if not documents:\n",
    "            logger.info(\"리랭킹할 문서가 없습니다.\")\n",
    "            return []\n",
    "        embedding_tasks = {\n",
    "            \"main\": asyncio.to_thread(self.embeddings.embed_query, query)\n",
    "        }\n",
    "        if self.user_preferences.get(\"author\"):\n",
    "            embedding_tasks[\"author\"] = asyncio.to_thread(\n",
    "                self.embeddings.embed_query, self.user_preferences[\"author\"][0]\n",
    "            )\n",
    "        if self.user_preferences.get(\"title\"):\n",
    "            embedding_tasks[\"title\"] = asyncio.to_thread(\n",
    "                self.embeddings.embed_query, self.user_preferences[\"title\"][0]\n",
    "            )\n",
    "        if self.user_preferences.get(\"category\"):\n",
    "            embedding_tasks[\"category\"] = asyncio.to_thread(\n",
    "                self.embeddings.embed_query, self.user_preferences[\"category\"][0]\n",
    "            )\n",
    "        query_embeddings = await asyncio.gather(*embedding_tasks.values())\n",
    "        query_embedding_map = dict(zip(embedding_tasks.keys(), query_embeddings))\n",
    "        # 페르소나별 retrieval_weights 사용 (없으면 기본값)\n",
    "        weights = self.config.get(\n",
    "            \"retrieval_weights\",\n",
    "            {\"main\": 0.1, \"author\": 0.3, \"title\": 0.1, \"category\": 0.5},\n",
    "        )\n",
    "        scored_docs = []\n",
    "        for doc in documents:\n",
    "            score_map: Dict[str, float] = {}\n",
    "            real_meta = doc.metadata.get(\"metadata\", doc.metadata)\n",
    "            doc_embedding = await asyncio.to_thread(\n",
    "                self.embeddings.embed_query, doc.page_content\n",
    "            )\n",
    "            score_map[\"main\"] = cosine_similarity(\n",
    "                [query_embedding_map[\"main\"]], [doc_embedding]\n",
    "            )[0][0]\n",
    "            author_text = real_meta.get(\"author\", \"\")\n",
    "            if author_text and \"author\" in query_embedding_map:\n",
    "                author_emb = await asyncio.to_thread(\n",
    "                    self.embeddings.embed_query, author_text\n",
    "                )\n",
    "                score_map[\"author\"] = cosine_similarity(\n",
    "                    [query_embedding_map[\"author\"]], [author_emb]\n",
    "                )[0][0]\n",
    "            title_text = real_meta.get(\"title\", \"\")\n",
    "            if title_text and \"title\" in query_embedding_map:\n",
    "                title_emb = await asyncio.to_thread(\n",
    "                    self.embeddings.embed_query, title_text\n",
    "                )\n",
    "                score_map[\"title\"] = cosine_similarity(\n",
    "                    [query_embedding_map[\"title\"]], [title_emb]\n",
    "                )[0][0]\n",
    "            category_text = real_meta.get(\"category\", \"\")\n",
    "            if category_text and \"category\" in query_embedding_map:\n",
    "                category_emb = await asyncio.to_thread(\n",
    "                    self.embeddings.embed_query, category_text\n",
    "                )\n",
    "                score_map[\"category\"] = cosine_similarity(\n",
    "                    [query_embedding_map[\"category\"]], [category_emb]\n",
    "                )[0][0]\n",
    "            valid_keys = score_map.keys()\n",
    "            total_weight = sum(weights[k] for k in valid_keys)\n",
    "            final_score = sum(\n",
    "                (weights[k] / total_weight) * score_map[k] for k in valid_keys\n",
    "            )\n",
    "            scored_docs.append((doc, final_score))\n",
    "        sorted_docs = sorted(scored_docs, key=lambda x: x[1], reverse=True)\n",
    "        logger.info(\"리랭킹 완료 (정규화 가중치 방식)\")\n",
    "        for i, (doc, score) in enumerate(sorted_docs):\n",
    "            title = _extract_metadata_field(doc, \"title\", default=\"제목 없음\")\n",
    "            isbn = _extract_metadata_field(doc, \"ISBN\", default=\"N/A\")\n",
    "            logger.info(\n",
    "                f\"{i+1}. 제목: {title} | ISBN: {isbn} | 점수: {round(score, 4)}\"\n",
    "            )\n",
    "\n",
    "        reranked_docs = [doc for doc, score in sorted_docs if score >= 0.5]\n",
    "        logger.info(\"리랭킹 완료 (0.5 이상 필터 적용됨)\")\n",
    "        return reranked_docs\n",
    "\n",
    "    async def _expand_query(self, query: str) -> List[str]:\n",
    "        logger.info(f\"검색 쿼리 확장 시작: '{query}'\")\n",
    "        expansion_result = await async_invoke(\n",
    "            self.query_expansion_chain, {\"query\": query}, \"검색 쿼리 확장\"\n",
    "        )\n",
    "        expanded_queries_text = expansion_result.get(\"text\", \"\").strip()\n",
    "        expanded_queries = []\n",
    "        for line in expanded_queries_text.splitlines():\n",
    "            line_stripped = line.strip()\n",
    "            if not line_stripped:\n",
    "                continue\n",
    "            query_part = re.sub(r\"^\\d+\\.\\s*\", \"\", line_stripped).strip()\n",
    "            if query_part and query_part.lower() != query.lower():\n",
    "                expanded_queries.append(query_part)\n",
    "        final_expanded_queries = expanded_queries[:3]\n",
    "        logger.info(\n",
    "            f\"생성된 확장 쿼리 ({len(final_expanded_queries)}개): {final_expanded_queries}\"\n",
    "        )\n",
    "        return final_expanded_queries\n",
    "\n",
    "    async def _retrieve_documents(\n",
    "        self, query: str, use_hyde: bool = False\n",
    "    ) -> List[Document]:\n",
    "        retrieval_query = query\n",
    "        hyde_summary = \"\"\n",
    "        if use_hyde and self.user_preferences.get(\"implicit info\"):\n",
    "            logger.info(\"HyDE 활성화: 가상 문서 요약 및 키워드 추출 시도\")\n",
    "            hyde_result = await async_invoke(\n",
    "                self.hyde_generation_chain, {\"query\": query}, \"HyDE 가상 문서 생성\"\n",
    "            )\n",
    "            hyde_summary = hyde_result.get(\"text\", \"\").strip()\n",
    "            if hyde_summary:\n",
    "                logger.info(f\"생성된 가상 문서 요약: '{hyde_summary[:200]}...'\")\n",
    "                keyword_result = await async_invoke(\n",
    "                    self.hyde_keyword_chain,\n",
    "                    {\"hyde_summary\": hyde_summary},\n",
    "                    \"HyDE 키워드 추출\",\n",
    "                )\n",
    "                hyde_keywords_text = keyword_result.get(\"text\", \"\").strip()\n",
    "                hyde_keywords = [\n",
    "                    k.strip() for k in hyde_keywords_text.split(\",\") if k.strip()\n",
    "                ]\n",
    "                if hyde_keywords:\n",
    "                    logger.info(f\"추출된 HyDE 키워드: {hyde_keywords}\")\n",
    "                    retrieval_query = f\"{query} {' '.join(hyde_keywords)}\"\n",
    "                    logger.info(f\"HyDE 적용된 검색 쿼리: '{retrieval_query}'\")\n",
    "                else:\n",
    "                    logger.warning(\n",
    "                        \"HyDE 요약에서 키워드를 추출하지 못했습니다. 원본 쿼리 사용.\"\n",
    "                    )\n",
    "            else:\n",
    "                logger.warning(\"HyDE 가상 문서 요약 생성 실패. 원본 쿼리 사용.\")\n",
    "        elif use_hyde:\n",
    "            logger.info(\"HyDE 조건 미충족 ('implicit info' 없음). 일반 쿼리 검색 수행.\")\n",
    "        else:\n",
    "            logger.info(\"일반 쿼리 검색 수행.\")\n",
    "        logger.info(f\"최종 리트리버 호출 시작 (쿼리: '{retrieval_query[:100]}...')\")\n",
    "        try:\n",
    "            retrieved_docs = await self.retriever.aget_relevant_documents(\n",
    "                retrieval_query\n",
    "            )\n",
    "            logger.info(f\"검색된 문서 수 (ISBN 병합 완료됨): {len(retrieved_docs)}\")\n",
    "        except Exception as e:\n",
    "            logger.error(\n",
    "                f\"문서 검색 실패 (쿼리: '{retrieval_query}'): {e}\", exc_info=True\n",
    "            )\n",
    "            retrieved_docs = []\n",
    "        return retrieved_docs\n",
    "\n",
    "    async def _generate_recommendations(self, final_query: str) -> str:\n",
    "        logger.info(f\"추천 생성 시작. 최종 쿼리: '{final_query}'\")\n",
    "        use_hyde = False\n",
    "        use_expansion = False\n",
    "        has_author = bool(self.user_preferences.get(\"author\"))\n",
    "        has_title = bool(self.user_preferences.get(\"title\"))\n",
    "        has_implicit = bool(self.user_preferences.get(\"implicit info\"))\n",
    "        if not has_author and not has_title and has_implicit:\n",
    "            use_hyde = True\n",
    "            use_expansion = True\n",
    "        initial_docs = await self._retrieve_documents(final_query, use_hyde=use_hyde)\n",
    "        all_docs_to_consider = list(initial_docs)\n",
    "        processed_queries = {final_query.lower()}\n",
    "        if use_expansion:\n",
    "            expanded_queries = await self._expand_query(final_query)\n",
    "            expansion_tasks = []\n",
    "            if expanded_queries:\n",
    "                logger.info(\n",
    "                    f\"확장 쿼리 ({len(expanded_queries)}개)로 추가 검색 수행...\"\n",
    "                )\n",
    "                for eq in expanded_queries:\n",
    "                    eq_lower = eq.lower()\n",
    "                    if eq_lower not in processed_queries:\n",
    "                        expansion_tasks.append(\n",
    "                            self._retrieve_documents(eq, use_hyde=False)\n",
    "                        )\n",
    "                        processed_queries.add(eq_lower)\n",
    "                if expansion_tasks:\n",
    "                    expansion_results = await asyncio.gather(*expansion_tasks)\n",
    "                    existing_isbns = {\n",
    "                        doc.metadata.get(\"ISBN\")\n",
    "                        for doc in all_docs_to_consider\n",
    "                        if doc.metadata.get(\"ISBN\")\n",
    "                    }\n",
    "                    for docs_list in expansion_results:\n",
    "                        for doc in docs_list:\n",
    "                            isbn = doc.metadata.get(\"ISBN\")\n",
    "                            if isbn and isbn not in existing_isbns:\n",
    "                                all_docs_to_consider.append(doc)\n",
    "                                existing_isbns.add(isbn)\n",
    "        logger.info(\n",
    "            f\"초기 및 확장 검색 후 고려할 총 고유 문서 수: {len(all_docs_to_consider)}\"\n",
    "        )\n",
    "\n",
    "        for i, doc in enumerate(all_docs_to_consider):\n",
    "            metadata_content = doc.metadata if doc.metadata else {}\n",
    "            logger.debug(\n",
    "                f\"문서 {i+1} Metadata: {json.dumps(metadata_content, indent=2, ensure_ascii=False)}\"\n",
    "            )\n",
    "            try:\n",
    "                isbn_check = metadata_content.get(\"ISBN\", \"ISBN 키 없음\")\n",
    "                title_check = metadata_content.get(\"title\", \"Title 키 없음\")\n",
    "                logger.debug(f\"  -> 확인: ISBN='{isbn_check}', Title='{title_check}'\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"  -> 메타데이터 접근 오류 발생: {e}\")\n",
    "        logger.debug(\"--- 리랭킹 입력 데이터 확인 완료 ---\")\n",
    "        if not all_docs_to_consider:\n",
    "            logger.warning(\"검색 및 확장 결과 문서를 찾지 못했습니다. 추천 생성 불가.\")\n",
    "            return \"죄송합니다, 해당 조건에 맞는 책을 찾지 못했습니다. 다른 조건으로 다시 시도해 보시겠어요?\"\n",
    "        logger.info(\"리랭킹 수행...\")\n",
    "        ranked_docs = await self._embedding_rerank_documents(\n",
    "            final_query, all_docs_to_consider\n",
    "        )\n",
    "        if not ranked_docs:\n",
    "            logger.warning(\"리랭킹 결과 유효한 문서가 없습니다. 추천 생성 불가.\")\n",
    "            self.last_recommendations = []  # 후속 질문 방지\n",
    "            return \"죄송합니다, 요청하신 조건에 맞는 책을 찾지 못했습니다. 다른 조건으로 다시 시도해 보시겠어요?\"\n",
    "        top_docs = ranked_docs[:3]\n",
    "        logger.info(f\"최종 추천 후보 문서 수: {len(top_docs)}\")\n",
    "        recommendations = []\n",
    "        self.last_recommendations = []\n",
    "        processed_isbns = set()\n",
    "        for rank, doc in enumerate(top_docs):\n",
    "            isbn = _extract_metadata_field(doc, \"ISBN\")\n",
    "            title = _extract_metadata_field(doc, \"title\", default=\"제목 없음\")\n",
    "            logger.debug(\n",
    "                f\"추천 후보 처리 중 (Rank {rank+1}): ISBN={isbn}, Title={title}\"\n",
    "            )\n",
    "            if not isbn or isbn == \"N/A\":\n",
    "                logger.warning(\n",
    "                    f\"Rank {rank+1} 추천 후보에 ISBN 없음. 건너뜀. Title: {title}\"\n",
    "                )\n",
    "                continue\n",
    "            if isbn in processed_isbns:\n",
    "                logger.warning(f\"중복 ISBN '{isbn}' 추천 목록에 이미 존재. 건너뜀.\")\n",
    "                continue\n",
    "            full_merged_doc = self._merge_documents_by_isbn(isbn)\n",
    "            if not full_merged_doc:\n",
    "                logger.error(\n",
    "                    f\"치명적 오류: 리랭킹된 문서(ISBN: {isbn})의 전체 정보를 병합하지 못했습니다. 추천 목록에서 제외.\"\n",
    "                )\n",
    "                continue\n",
    "            self.last_recommendations.append(full_merged_doc)\n",
    "            processed_isbns.add(isbn)\n",
    "            metadata = full_merged_doc.metadata\n",
    "            title = metadata.get(\"title\", \"제목 정보 없음\")\n",
    "            author = metadata.get(\"author\", \"저자 정보 없음\")\n",
    "            book_cover = metadata.get(\"book_cover\", \"표지 정보 없음\")\n",
    "            book_intro = extract_field(full_merged_doc.page_content, \"책소개\")\n",
    "            publisher_review = extract_field(full_merged_doc.page_content, \"출판사리뷰\")\n",
    "            recommendation_field = extract_field(full_merged_doc.page_content, \"추천사\")\n",
    "            text_for_summary = \"\"\n",
    "            if book_intro and len(book_intro.strip()) >= MIN_INFO_LENGTH:\n",
    "                text_for_summary = book_intro\n",
    "            elif publisher_review and len(publisher_review.strip()) >= MIN_INFO_LENGTH:\n",
    "                text_for_summary = publisher_review\n",
    "            elif (\n",
    "                recommendation_field\n",
    "                and len(recommendation_field.strip()) >= MIN_INFO_LENGTH\n",
    "            ):\n",
    "                text_for_summary = recommendation_field\n",
    "            else:\n",
    "                page_content_cleaned = re.sub(\n",
    "                    r\"^\\s*.*?\\s*[:：]\\s*\",\n",
    "                    \"\",\n",
    "                    full_merged_doc.page_content,\n",
    "                    flags=re.MULTILINE,\n",
    "                ).strip()\n",
    "                text_for_summary = page_content_cleaned[:500]\n",
    "            if text_for_summary and len(text_for_summary.strip()) >= MIN_INFO_LENGTH:\n",
    "                summary = await self._summarize_chunk_with_llm(text_for_summary)\n",
    "            else:\n",
    "                summary = \"책에 대한 상세 설명이 부족합니다.\"\n",
    "            recommendation_text = f\"{rank+1}. \\r\\n표지: {book_cover}\\r\\n제목: {title}\\r\\n저자: {author}\\r\\n- 추천 이유: {summary}\"\n",
    "            recommendations.append(recommendation_text)\n",
    "            logger.debug(f\"추천 문구 생성됨: {title}\")\n",
    "        if self.last_recommendations:\n",
    "            rec_titles = [\n",
    "                d.metadata.get(\"title\", \"N/A\") for d in self.last_recommendations\n",
    "            ]\n",
    "            logger.info(\n",
    "                f\"'_generate_recommendations' 종료. last_recommendations 업데이트 ({len(self.last_recommendations)}개): {rec_titles}\"\n",
    "            )\n",
    "        else:\n",
    "            logger.warning(\n",
    "                \"'_generate_recommendations' 종료. 최종 추천 목록(last_recommendations)이 비어있음!\"\n",
    "            )\n",
    "        if not recommendations:\n",
    "            return \"추천할 만한 책을 찾지 못했습니다. 조건을 바꿔서 다시 질문해 주시겠어요?\"\n",
    "        persona_info_map = {\n",
    "            \"Literature\": \"감성, 현재 기분, 선호하는 문학 장르 및 작가 스타일\",\n",
    "            \"Science\": \"독자의 지식 수준(초심자/전문가), 관심 기술 분야, 문제 해결 목표\",\n",
    "            \"General\": \"선호 장르, 책을 찾는 이유, 원하는 분위기나 난이도\",\n",
    "        }\n",
    "        intro_vars = {\n",
    "            \"query\": final_query,\n",
    "            \"persona_info\": persona_info_map.get(self.config.get(\"persona\", \"General\")),\n",
    "        }\n",
    "        intro_result = await async_invoke(\n",
    "            self.recommendation_intro_chain, intro_vars, \"추천 인삿말 생성\"\n",
    "        )\n",
    "        recommendation_intro = intro_result.get(\"text\", \"\").strip()\n",
    "        if not recommendation_intro:\n",
    "            recommendation_intro = \"이런 책들은 어떠세요?\"\n",
    "\n",
    "        # 추천 아웃트로 생성\n",
    "        outro_vars = {\n",
    "            \"query\": final_query,\n",
    "            \"persona_info\": persona_info_map.get(self.config.get(\"persona\", \"General\")),\n",
    "        }\n",
    "        try:\n",
    "            outro_result = await async_invoke(\n",
    "                self.recommendation_outro_chain, outro_vars, \"추천 마무리 멘트 생성\"\n",
    "            )\n",
    "            recommendation_outro = outro_result.get(\"text\", \"\").strip()\n",
    "            if not recommendation_outro or len(recommendation_outro) < 3:\n",
    "                recommendation_outro = \"마음에 드는 책이 있으셨으면 좋겠어요 :)\"\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"추천 아웃트로 생성 실패: {e}\")\n",
    "            recommendation_outro = \"마음에 드는 책이 있으셨으면 좋겠어요 :)\"\n",
    "\n",
    "        # 최종 답변 조립\n",
    "        final_answer = (\n",
    "            recommendation_intro\n",
    "            + \"\\n\\n\"\n",
    "            + \"\\n\\n\".join(recommendations)\n",
    "            + \"\\n\\n\"\n",
    "            + recommendation_outro\n",
    "        )\n",
    "        logger.info(\"추천 응답 생성 완료.\")\n",
    "        return final_answer\n",
    "\n",
    "    async def handle_followup_query(self, followup_query: str) -> tuple[bool, str]:\n",
    "        logger.info(f\"후속 질문 처리 시작. Query: '{followup_query}'\")\n",
    "        if not self.last_recommendations:\n",
    "            logger.error(\n",
    "                \"handle_followup_query 진입 오류: last_recommendations가 비어 있음!\"\n",
    "            )\n",
    "            return False, \"\"\n",
    "        rec_info = []\n",
    "        for i, doc in enumerate(self.last_recommendations):\n",
    "            title = doc.metadata.get(\"title\", \"제목 없음\")\n",
    "            isbn = doc.metadata.get(\"ISBN\", \"NO_ISBN\")\n",
    "            snippet = await self._summarize_chunk_with_llm(doc.page_content[:500])\n",
    "            rec_info.append(f\"{i+1}. 제목: {title}, ISBN: {isbn}\\n   요약: {snippet}\")\n",
    "        rec_info_str = \"\\n\".join(rec_info)\n",
    "        prompt = f\"\"\"\n",
    "        이전에 다음 책들을 추천했습니다:\n",
    "        {rec_info_str}\n",
    "\n",
    "        사용자의 후속 질문은 다음과 같습니다: \"{followup_query}\"\n",
    "\n",
    "        이 질문이 위 추천 목록과 관련된 후속 질문인지, 아니면 완전히 새로운 질문인지 판단하고, 후속 질문이라면 그 의도를 분석하여 다음 JSON 형식 중 **하나만** 출력해라. 새로운 질문이면 {{\"action\": \"새 질문\", \"ISBN\": null, \"query\": null}} 형식으로 출력하라. **절대로 다른 설명이나 대화 없이 오직 JSON 객체 하나만 출력해야 한다.**\n",
    "        [후속 질문 의도 분류 및 JSON 형식]\n",
    "        - 특정 책 상세 정보 요청: {{\"action\": \"상세\", \"ISBN\": \"<요청된 책의 ISBN>\", \"query\": \"{followup_query}\"}}\n",
    "        - 특정 책과 유사한 책 추천 요청: {{\"action\": \"유사\", \"ISBN\": \"<기준 책의 ISBN>\", \"query\": \"<유사성 관련 사용자 언급>\"}}\n",
    "        - 추천된 책들 비교 요청: {{\"action\": \"비교\", \"ISBN\": \"<비교 대상 ISBN 목록 (쉼표 구분)>\", \"query\": \"{followup_query}\"}}\n",
    "        - 추천 결과에 대한 피드백/불만: {{\"action\": \"피드백\", \"ISBN\": null, \"query\": \"{followup_query}\"}}\n",
    "        - 완전히 새로운 질문: {{\"action\": \"새 질문\", \"ISBN\": null, \"query\": null}}\n",
    "        [분석 결과 (JSON 객체만 출력)]\n",
    "        \"\"\"\n",
    "        try:\n",
    "            result_text = await async_invoke_llm(prompt, \"후속 질문 의도 분석\")\n",
    "            logger.debug(f\"후속 질문 의도 분석 LLM 원본 응답: {result_text}\")\n",
    "            analysis_result = None\n",
    "            json_match = re.search(r\"\\{.*\\}\", result_text, re.DOTALL)\n",
    "            if json_match:\n",
    "                try:\n",
    "                    analysis_result = json.loads(json_match.group(0))\n",
    "                except json.JSONDecodeError:\n",
    "                    logger.error(\n",
    "                        f\"후속 질문 의도 분석 결과 JSON 파싱 실패 (JSON 형식 오류): {result_text}\"\n",
    "                    )\n",
    "                    analysis_result = {\"action\": \"새 질문\"}\n",
    "            else:\n",
    "                if (\n",
    "                    \"새 질문\" in result_text\n",
    "                    or '\"action\": \"새 질문\"' in result_text.replace(\" \", \"\")\n",
    "                ):\n",
    "                    logger.warning(\n",
    "                        f\"후속 질문 의도 분석 JSON 객체 미발견, '새 질문' 패턴 감지: {result_text}\"\n",
    "                    )\n",
    "                    analysis_result = {\"action\": \"새 질문\"}\n",
    "                else:\n",
    "                    logger.error(\n",
    "                        f\"후속 질문 의도 분석 결과 JSON 파싱 실패 및 '새 질문' 패턴 미감지: {result_text}\"\n",
    "                    )\n",
    "                    return False, \"\"\n",
    "            action = analysis_result.get(\"action\", \"새 질문\")\n",
    "            isbn_str = analysis_result.get(\"ISBN\", \"\")\n",
    "            query_part = analysis_result.get(\"query\", followup_query)\n",
    "            logger.info(\n",
    "                f\"후속 질문 분석 결과: action='{action}', ISBN='{isbn_str}', query='{query_part[:50]}...'\"\n",
    "            )\n",
    "            if action == \"새 질문\":\n",
    "                return False, \"\"\n",
    "            isbn_list = (\n",
    "                [s.strip() for s in str(isbn_str).split(\",\") if s.strip()]\n",
    "                if isbn_str\n",
    "                else []\n",
    "            )\n",
    "            target_isbn = isbn_list[0] if isbn_list else None\n",
    "            if action == \"상세\":\n",
    "                if not target_isbn:\n",
    "                    return (\n",
    "                        True,\n",
    "                        \"어떤 책에 대해 더 알고 싶으신지 알려주시겠어요? (예: 첫 번째 책 또는 책 제목)\",\n",
    "                    )\n",
    "                target_doc = next(\n",
    "                    (\n",
    "                        doc\n",
    "                        for doc in self.last_recommendations\n",
    "                        if str(doc.metadata.get(\"ISBN\", \"\")).strip()\n",
    "                        == str(target_isbn).strip()\n",
    "                    ),\n",
    "                    None,\n",
    "                )\n",
    "                if target_doc:\n",
    "                    logger.debug(\n",
    "                        f\"상세 정보 요청: ISBN '{target_isbn}' 문서 찾음: Title='{target_doc.metadata.get('title')}'\"\n",
    "                    )\n",
    "                    detail_prompt = f\"\"\"\n",
    "                    다음은 사용자가 문의한 '{target_doc.metadata.get(\"title\", \"해당 책\")}'에 대한 정보입니다. 이 정보를 바탕으로 사용자 질문 \"{query_part}\"에 답하거나, 특별한 질문이 없다면 책에 대해 자연스럽게 더 자세히 설명해주세요.\n",
    "                    [책 정보 요약]\n",
    "                    제목: {target_doc.metadata.get(\"title\", \"정보 없음\")}\n",
    "                    저자: {target_doc.metadata.get(\"author\", \"정보 없음\")}\n",
    "                    분류: {target_doc.metadata.get(\"category\", \"정보 없음\")}\n",
    "                    페이지: {target_doc.metadata.get(\"page\", \"정보 없음\")} 쪽\n",
    "                    가격: {target_doc.metadata.get(\"price\", \"정보 없음\")} 원\n",
    "                    [책 소개 및 내용 (일부)]\n",
    "                    {target_doc.page_content[:3000]}...\n",
    "                    [답변 또는 상세 설명]\n",
    "                    \"\"\"\n",
    "                    detailed_info = await async_invoke_llm(\n",
    "                        detail_prompt, \"후속 상세 설명 생성\"\n",
    "                    )\n",
    "                    return True, (\n",
    "                        detailed_info\n",
    "                        if detailed_info\n",
    "                        else \"죄송합니다, 요청하신 내용에 대한 추가 정보를 제공하기 어렵습니다.\"\n",
    "                    )\n",
    "                else:\n",
    "                    available_isbns = [\n",
    "                        d.metadata.get(\"ISBN\") for d in self.last_recommendations\n",
    "                    ]\n",
    "                    return (\n",
    "                        True,\n",
    "                        f\"죄송합니다, 요청하신 ISBN({target_isbn})의 책 정보를 찾을 수 없습니다. 현재 추천된 책들의 ISBN은 다음과 같습니다: {available_isbns}\",\n",
    "                    )\n",
    "            elif action == \"유사\":\n",
    "                if not target_isbn:\n",
    "                    return (\n",
    "                        True,\n",
    "                        \"어떤 책과 유사한 책을 찾으시는지 알려주시겠어요? (예: 두 번째 책 같은 스타일)\",\n",
    "                    )\n",
    "                base_doc = next(\n",
    "                    (\n",
    "                        doc\n",
    "                        for doc in self.last_recommendations\n",
    "                        if str(doc.metadata.get(\"ISBN\", \"\")).strip()\n",
    "                        == str(target_isbn).strip()\n",
    "                    ),\n",
    "                    None,\n",
    "                )\n",
    "                if base_doc:\n",
    "                    logger.debug(\n",
    "                        f\"유사 책 요청: 기준 ISBN '{target_isbn}' 문서 찾음: Title='{base_doc.metadata.get('title')}'\"\n",
    "                    )\n",
    "                    base_title = base_doc.metadata.get(\"title\", \"\")\n",
    "                    base_author = base_doc.metadata.get(\"author\", \"\")\n",
    "                    base_category = base_doc.metadata.get(\"category\", \"\")\n",
    "                    similarity_aspects = (\n",
    "                        f\"{base_category} 장르\"\n",
    "                        if base_category\n",
    "                        else f\"'{base_title}'와 비슷한\"\n",
    "                    )\n",
    "                    if base_author:\n",
    "                        similarity_aspects += f\" {base_author} 작가 스타일\"\n",
    "                    user_refinement = (\n",
    "                        f\" 그리고 '{query_part}' 특징을 가진\"\n",
    "                        if query_part and query_part != followup_query\n",
    "                        else \"\"\n",
    "                    )\n",
    "                    new_query = f\"{similarity_aspects}{user_refinement} 책 추천\"\n",
    "                    logger.info(f\"유사 책 추천을 위한 새 쿼리 생성: {new_query}\")\n",
    "                    recommendation_result = await self._generate_recommendations(\n",
    "                        new_query\n",
    "                    )\n",
    "                    return (\n",
    "                        True,\n",
    "                        f\"네, '{base_title}'와(과) 비슷한 다른 책을 찾아볼게요.\\n\\n\"\n",
    "                        + recommendation_result,\n",
    "                    )\n",
    "                else:\n",
    "                    available_isbns = [\n",
    "                        d.metadata.get(\"ISBN\") for d in self.last_recommendations\n",
    "                    ]\n",
    "                    return (\n",
    "                        True,\n",
    "                        f\"죄송합니다, 기준이 되는 ISBN({target_isbn})의 책 정보를 찾을 수 없습니다. 현재 추천된 책들의 ISBN은 다음과 같습니다: {available_isbns}\",\n",
    "                    )\n",
    "            elif action == \"비교\":\n",
    "                if len(isbn_list) < 2:\n",
    "                    return (\n",
    "                        True,\n",
    "                        \"비교할 책을 두 권 이상 알려주시겠어요? (예: 첫 번째랑 세 번째 책 비교해주세요)\",\n",
    "                    )\n",
    "                valid_comparison_isbns = [\n",
    "                    isbn\n",
    "                    for isbn in isbn_list\n",
    "                    if any(\n",
    "                        str(d.metadata.get(\"ISBN\", \"\")).strip() == str(isbn).strip()\n",
    "                        for d in self.last_recommendations\n",
    "                    )\n",
    "                ]\n",
    "                if len(valid_comparison_isbns) < 2:\n",
    "                    available_isbns = [\n",
    "                        d.metadata.get(\"ISBN\") for d in self.last_recommendations\n",
    "                    ]\n",
    "                    return (\n",
    "                        True,\n",
    "                        f\"죄송합니다, 비교 요청하신 책({isbn_list}) 중 일부를 찾을 수 없거나 유효하지 않습니다. 현재 추천된 책 ISBN: {available_isbns}\",\n",
    "                    )\n",
    "                comparison_result = await self._handle_comparison(\n",
    "                    query_part, valid_comparison_isbns\n",
    "                )\n",
    "                return True, comparison_result\n",
    "            elif action == \"피드백\":\n",
    "                logger.info(f\"사용자 피드백/불만 처리 시도: '{query_part}'\")\n",
    "                feedback_based_query = f\"이전 추천에 대해 '{query_part}' 라는 피드백이 있었습니다. 이 점을 고려하여 다른 책을 추천해주세요.\"\n",
    "                logger.info(f\"피드백 기반 새 쿼리 생성: {feedback_based_query}\")\n",
    "                recommendation_result = await self._generate_recommendations(\n",
    "                    feedback_based_query\n",
    "                )\n",
    "                return (\n",
    "                    True,\n",
    "                    \"피드백 감사합니다. 말씀해주신 점을 바탕으로 다른 책을 찾아보겠습니다.\\n\\n\"\n",
    "                    + recommendation_result,\n",
    "                )\n",
    "            else:\n",
    "                logger.warning(\n",
    "                    f\"처리되지 않은 후속 질문 action: {action}. 새 질문으로 간주.\"\n",
    "                )\n",
    "                return False, \"\"\n",
    "        except Exception as e:\n",
    "            logger.error(f\"후속 질문 처리 중 예외 발생: {e}\", exc_info=True)\n",
    "            return True, \"후속 질문 처리 중 오류가 발생했습니다. 다시 시도해 주세요.\"\n",
    "\n",
    "    async def _handle_comparison(self, query_part: str, isbn_list: List[str]) -> str:\n",
    "        logger.info(\n",
    "            f\"도서 비교 시작. ISBN 목록: {isbn_list}, 비교 관점: '{query_part}'\"\n",
    "        )\n",
    "        comparison_docs_info = []\n",
    "        for isbn in isbn_list:\n",
    "            doc = next(\n",
    "                (\n",
    "                    d\n",
    "                    for d in self.last_recommendations\n",
    "                    if str(d.metadata.get(\"ISBN\", \"\")).strip() == str(isbn).strip()\n",
    "                ),\n",
    "                None,\n",
    "            )\n",
    "            if doc:\n",
    "                metadata = doc.metadata\n",
    "                summary = await self._summarize_chunk_with_llm(doc.page_content[:2000])\n",
    "                comparison_docs_info.append(\n",
    "                    {\n",
    "                        \"title\": metadata.get(\"title\", \"제목 없음\"),\n",
    "                        \"author\": metadata.get(\"author\", \"저자 없음\"),\n",
    "                        \"summary\": summary,\n",
    "                        \"category\": metadata.get(\"category\", \"분류 없음\"),\n",
    "                        \"page\": metadata.get(\"page\", \"페이지 수 없음\"),\n",
    "                        \"price\": metadata.get(\"price\", \"가격 정보 없음\"),\n",
    "                        \"isbn\": isbn,\n",
    "                    }\n",
    "                )\n",
    "            else:\n",
    "                logger.error(\n",
    "                    f\"비교 오류: 유효성 검사 후에도 ISBN '{isbn}' 문서를 last_recommendations에서 찾지 못함.\"\n",
    "                )\n",
    "        if len(comparison_docs_info) < 2:\n",
    "            logger.warning(\n",
    "                f\"비교 가능한 문서가 2개 미만입니다 (찾은 문서 수: {len(comparison_docs_info)}).\"\n",
    "            )\n",
    "            return \"비교할 책 정보를 충분히 찾지 못했습니다.\"\n",
    "        comparison_prompt_template = \"\"\"\n",
    "        다음은 사용자가 비교를 요청한 책들의 정보입니다. 사용자의 비교 요청 관점인 \"{{ query }}\"에 특히 초점을 맞춰 이 책들을 명확하게 비교 설명해주세요. 각 책의 주요 특징, 장르, 내용 스타일, 난이도, 분량, 가격 등 관련 정보를 활용하고, 어떤 독자에게 더 적합할지 등을 포함하여 답변하는 것이 좋습니다. 자연스러운 문장으로 설명해주세요.\n",
    "        [비교 대상 책 정보]\n",
    "        {% for doc in summaries %}\n",
    "        --- 책 {{ loop.index }} (ISBN: {{ doc.isbn }}) ---\n",
    "        제목: {{ doc.title }}\n",
    "        저자: {{ doc.author }}\n",
    "        분류: {{ doc.category }}\n",
    "        페이지 수: {{ doc.page }}\n",
    "        가격: {{ doc.price }} 원\n",
    "        요약: {{ doc.summary }}\n",
    "        {% endfor %}\n",
    "        [사용자 비교 요청 관점/질문]\n",
    "        \"{{ query }}\"\n",
    "        [비교 설명]\n",
    "        \"\"\"\n",
    "        try:\n",
    "            comp_template = PromptTemplate(\n",
    "                template=comparison_prompt_template,\n",
    "                input_variables=[\"summaries\", \"query\"],\n",
    "                template_format=\"jinja2\",\n",
    "            )\n",
    "            rendered_prompt = comp_template.render(\n",
    "                summaries=comparison_docs_info, query=query_part\n",
    "            )\n",
    "            logger.debug(\n",
    "                f\"도서 비교 프롬프트 생성 완료 (일부):\\n{rendered_prompt[:500]}...\"\n",
    "            )\n",
    "            comparison_result = await async_invoke_llm(\n",
    "                rendered_prompt, \"도서 비교 설명 생성\"\n",
    "            )\n",
    "            if (\n",
    "                not comparison_result\n",
    "                or len(comparison_result) < 20\n",
    "                or \"죄송\" in comparison_result\n",
    "                or \"모르겠\" in comparison_result\n",
    "            ):\n",
    "                logger.warning(\"LLM 기반 도서 비교 설명 생성 실패 또는 결과 부적절.\")\n",
    "                return \"죄송합니다, 요청하신 책들을 비교 설명하는 데 어려움이 있습니다.\"\n",
    "            logger.info(\"도서 비교 설명 생성 완료.\")\n",
    "            return comparison_result\n",
    "        except Exception as e:\n",
    "            logger.error(f\"도서 비교 설명 생성 중 예외 발생: {e}\", exc_info=True)\n",
    "            return \"죄송합니다, 책들을 비교하는 중 오류가 발생했습니다.\"\n",
    "\n",
    "    async def process_query(\n",
    "        self, user_query: str, force_recommendation: bool = False\n",
    "    ) -> str:\n",
    "        logger.info(f\"=== 새로운 사용자 쿼리 처리 시작: '{user_query}' ===\")\n",
    "        self.user_history.append(f\"사용자: {user_query}\")\n",
    "        await self.update_preferences_from_input(user_query)\n",
    "        is_potential_followup = self.last_action == \"추천\" and self.last_recommendations\n",
    "        if is_potential_followup:\n",
    "            logger.info(\"이전 추천에 대한 후속 질문 가능성 확인 중...\")\n",
    "            handled, followup_output = await self.handle_followup_query(user_query)\n",
    "            if handled:\n",
    "                logger.info(\"후속 질문 처리 완료.\")\n",
    "                self.llm_history.append(f\"챗봇: {followup_output}\")\n",
    "                return followup_output\n",
    "            else:\n",
    "                logger.info(\"후속 질문이 아님. 일반 질문 처리 로직으로 진행합니다.\")\n",
    "        action: Optional[str] = None\n",
    "        additional_question: str = \"\"\n",
    "        if not force_recommendation:\n",
    "            logger.info(\"행동 결정 요청 (추천 vs 추가 질문)\")\n",
    "            meaningful_prefs_count = sum(\n",
    "                1 for k, v in self.user_preferences.items() if v and k != \"title\"\n",
    "            )\n",
    "            should_recommend_heuristically = (\n",
    "                meaningful_prefs_count >= 1 or self.preference_update_count >= 2\n",
    "            )\n",
    "            if not should_recommend_heuristically and self.preference_update_count < 2:\n",
    "                logger.info(\n",
    "                    f\"선호도 부족 ({meaningful_prefs_count}개 / {self.preference_update_count}번 업데이트). '추가 질문' 강제 실행.\"\n",
    "                )\n",
    "                action = \"추가 질문\"\n",
    "                additional_question = \"어떤 종류의 책을 찾으시는지 좀 더 자세히 말씀해주시겠어요? (예: 구체적인 카테고리, 특정 작가, 책의 수준/분위기 등)\"\n",
    "            else:\n",
    "                prompt_vars = {\n",
    "                    \"history\": \"\\n\".join(\n",
    "                        self.user_history[-5:] + self.llm_history[-5:]\n",
    "                    ),\n",
    "                    \"query\": user_query,\n",
    "                    \"preferences\": self.preferences_text,\n",
    "                    \"role_instructions\": self.config.get(\n",
    "                        \"role_instructions\", general_role\n",
    "                    ),\n",
    "                }\n",
    "                try:\n",
    "                    decision_result = await async_invoke(\n",
    "                        self.decision_chain, prompt_vars, \"행동 결정\"\n",
    "                    )\n",
    "                    decision_text = decision_result.get(\"text\", \"\").strip()\n",
    "                    action, additional_question_llm = (\n",
    "                        self.robust_parse_decision_response(decision_text)\n",
    "                    )\n",
    "                    if action == \"추가 질문\" and additional_question_llm:\n",
    "                        additional_question = additional_question_llm\n",
    "                except Exception as e:\n",
    "                    logger.error(\n",
    "                        f\"행동 결정 LLM 호출 실패: {e}. '추가 질문'으로 안전하게 진행.\",\n",
    "                        exc_info=True,\n",
    "                    )\n",
    "                    action = \"추가 질문\"\n",
    "                    additional_question = \"요청을 이해하는 데 어려움이 있었습니다. 어떤 책을 찾으시는지 다시 말씀해주시겠어요?\"\n",
    "        else:\n",
    "            logger.info(\"강제 추천 모드 활성화. 행동='추천'\")\n",
    "            action = \"추천\"\n",
    "        response = \"\"\n",
    "        if action == \"추가 질문\":\n",
    "            logger.info(\"행동: 추가 질문\")\n",
    "            self.last_action = \"추가 질문\"\n",
    "            if additional_question:\n",
    "                try:\n",
    "                    add_q_emb = await asyncio.to_thread(\n",
    "                        self.embeddings.embed_query, additional_question\n",
    "                    )\n",
    "                    if is_similar_question(\n",
    "                        add_q_emb,\n",
    "                        previous_additional_question_embeddings,\n",
    "                        threshold=0.90,\n",
    "                    ):\n",
    "                        logger.warning(\n",
    "                            \"이전과 매우 유사한 추가 질문 생성됨. 추천 강제 시도.\"\n",
    "                        )\n",
    "                        return await self.process_query(\n",
    "                            user_query, force_recommendation=True\n",
    "                        )\n",
    "                    else:\n",
    "                        previous_additional_question_embeddings.append(add_q_emb)\n",
    "                        if len(previous_additional_question_embeddings) > 5:\n",
    "                            previous_additional_question_embeddings.pop(0)\n",
    "                        response = additional_question\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"추가 질문 임베딩 또는 유사도 비교 중 오류: {e}\")\n",
    "                    response = additional_question\n",
    "            else:\n",
    "                logger.warning(\"추가 질문 행동 결정되었으나 질문 내용 없음. 추천 시도.\")\n",
    "                action = \"추천\"\n",
    "        if action == \"추천\":\n",
    "            logger.info(\"행동: 추천\")\n",
    "            self.last_action = \"추천\"\n",
    "            final_query = await self.get_final_query(user_query)\n",
    "            if not final_query:\n",
    "                logger.error(\"최종 검색 쿼리 생성 실패. 추천 불가.\")\n",
    "                self.last_action = None\n",
    "                response = \"죄송합니다, 검색어를 만드는 데 실패했습니다. 다시 질문해 주시겠어요?\"\n",
    "            else:\n",
    "                recommendation_result = await self._generate_recommendations(\n",
    "                    final_query\n",
    "                )\n",
    "                response = recommendation_result\n",
    "                if (\n",
    "                    not self.last_recommendations\n",
    "                    and \"죄송합니다\" not in response\n",
    "                    and \"찾지 못했습니다\" not in response\n",
    "                ):\n",
    "                    logger.warning(\n",
    "                        \"추천 생성 과정 완료 후 self.last_recommendations가 비어있으나, 응답은 성공 메시지 형태임.\"\n",
    "                    )\n",
    "                    self.last_action = None\n",
    "        if response:\n",
    "            self.llm_history.append(f\"챗봇: {response}\")\n",
    "            logger.info(\n",
    "                f\"챗봇 응답 생성 완료 (Action: {self.last_action}). 응답 일부: {response[:200]}...\"\n",
    "            )\n",
    "            return response\n",
    "        else:\n",
    "            logger.error(f\"최종 응답 생성 실패 (Action: {action}).\")\n",
    "            self.last_action = None\n",
    "            fallback_msg = (\n",
    "                \"죄송합니다, 요청을 처리하는 중 문제가 발생했습니다. 다시 시도해주세요.\"\n",
    "            )\n",
    "            self.llm_history.append(f\"챗봇: {fallback_msg}\")\n",
    "            return fallback_msg\n",
    "\n",
    "    async def interactive_multi_turn_qa(self):\n",
    "        persona_greetings = {\n",
    "            \"Literature\": \"안녕하세요~ 감성적인 문학 도서 추천 챗봇입니다. 어떤 책을 찾으시나요? 당신의 이야기나 감정을 들려주셔도 좋아요.\",\n",
    "            \"Science\": \"안녕하십니까. 과학/기술 도서 전문 챗봇입니다. 관심 분야, 알고 계신 내용, 찾으시는 정보의 깊이 등을 알려주시면 더 정확한 추천을 드릴 수 있습니다.\",\n",
    "            \"General\": \"안녕하세요! 도서 추천 챗봇입니다. 어떤 종류의 책을 찾으시는지 편하게 말씀해주세요.\",\n",
    "        }\n",
    "        persona = self.config.get(\"persona\", \"General\")\n",
    "        greeting = persona_greetings.get(persona, persona_greetings[\"General\"])\n",
    "        self.llm_history.append(f\"챗봇: {greeting}\")\n",
    "        print(\"-\" * 70)\n",
    "        print(f\"[{self.config.get('persona', '챗봇')}] {greeting}\")\n",
    "        print(\"-\" * 70)\n",
    "        turn_count = 0\n",
    "        while True:\n",
    "            turn_count += 1\n",
    "            print(f\"\\n--- Turn {turn_count} ---\")\n",
    "            logger.info(f\"--- Turn {turn_count} 시작 ---\")\n",
    "            logger.debug(\n",
    "                f\"Turn 시작 | last_action: {self.last_action} | last_recs: {len(self.last_recommendations)}\"\n",
    "            )\n",
    "            try:\n",
    "                user_query = input(\"[사용자] \").strip()\n",
    "            except (KeyboardInterrupt, EOFError):\n",
    "                print(\"\\n[대화 종료]\")\n",
    "                break\n",
    "            if user_query.lower() in [\"quit\", \"exit\", \"종료\", \"그만\"]:\n",
    "                print(\"\\n[대화 종료]\")\n",
    "                break\n",
    "            if not user_query:\n",
    "                continue\n",
    "            try:\n",
    "                final_answer = await self.process_query(user_query)\n",
    "            except Exception as e:\n",
    "                logger.critical(\n",
    "                    f\"대화 처리 중 치명적 오류 발생 (Turn {turn_count}): {e}\",\n",
    "                    exc_info=True,\n",
    "                )\n",
    "                final_answer = \"죄송합니다. 요청을 처리하는 중에 예상치 못한 오류가 발생했습니다. 잠시 후 다시 시도해주세요.\"\n",
    "            print(\"-\" * 70)\n",
    "            print(f\"[{self.config.get('persona', '챗봇')}]\\n{final_answer}\")\n",
    "            print(\"-\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LiteratureRAGPipeline(BaseRAGPipeline):\n",
    "    def __init__(self, llm, embeddings, vectorstore, es_store, retriever, documents):\n",
    "        config = {\n",
    "            \"persona\": \"Literature\",\n",
    "            \"role_instructions\": literature_role,\n",
    "            \"pref_extraction_template\": extract_pref_prompt_v2,  # literature_pref_template,\n",
    "            \"consolidate_pref_template\": consolidate_pref_prompt,\n",
    "            \"decision_template\": decision_prompt_template,\n",
    "            \"final_query_template\": literature_final_query_template,\n",
    "            \"refine_template\": literature_refine_template,\n",
    "            \"expansion_template\": literature_expansion_template,\n",
    "            \"re_ranking_template\": re_ranking_prompt,\n",
    "            \"hyde_generation_template\": hyde_generation_prompt,\n",
    "            \"hyde_keyword_template\": hyde_keyword_prompt,\n",
    "            \"retrieval_weights\": {\n",
    "                \"main\": 0.1,\n",
    "                \"author\": 0.5,\n",
    "                \"title\": 0.1,\n",
    "                \"category\": 0.3,\n",
    "            },\n",
    "            \"persona_info\": \"감성, 현재 기분, 선호하는 문학 장르 및 작가 스타일\",\n",
    "            \"recommendation_intro_template\": recommendation_intro_prompt,\n",
    "            \"recommendation_outro_template\": recommendation_outro_prompt,\n",
    "        }\n",
    "        super().__init__(\n",
    "            config, llm, embeddings, vectorstore, es_store, retriever, documents\n",
    "        )\n",
    "\n",
    "\n",
    "class ScienceRAGPipeline(BaseRAGPipeline):\n",
    "    def __init__(self, llm, embeddings, vectorstore, es_store, retriever, documents):\n",
    "        config = {\n",
    "            \"persona\": \"Science\",\n",
    "            \"role_instructions\": science_role,\n",
    "            \"pref_extraction_template\": extract_pref_prompt_v2,  # science_pref_template,\n",
    "            \"consolidate_pref_template\": consolidate_pref_prompt,\n",
    "            \"decision_template\": decision_prompt_template,\n",
    "            \"final_query_template\": science_final_query_template,\n",
    "            \"refine_template\": science_refine_template,\n",
    "            \"expansion_template\": science_expansion_template,\n",
    "            \"re_ranking_template\": re_ranking_prompt,\n",
    "            \"hyde_generation_template\": hyde_generation_prompt,\n",
    "            \"hyde_keyword_template\": hyde_keyword_prompt,\n",
    "            \"retrieval_weights\": {\n",
    "                \"main\": 0.2,\n",
    "                \"author\": 0.1,\n",
    "                \"title\": 0.3,\n",
    "                \"category\": 0.4,\n",
    "            },\n",
    "            \"persona_info\": \"정확, 논리, 최신 기술 동향 및 전문 지식을 반영\",\n",
    "            \"recommendation_intro_template\": recommendation_intro_prompt,\n",
    "            \"recommendation_outro_template\": recommendation_outro_prompt,\n",
    "        }\n",
    "        super().__init__(\n",
    "            config, llm, embeddings, vectorstore, es_store, retriever, documents\n",
    "        )\n",
    "\n",
    "\n",
    "class GeneralRAGPipeline(BaseRAGPipeline):\n",
    "    def __init__(self, llm, embeddings, vectorstore, es_store, retriever, documents):\n",
    "        config = {\n",
    "            \"persona\": \"General\",\n",
    "            \"role_instructions\": general_role,\n",
    "            \"pref_extraction_template\": extract_pref_prompt_v2,  # general_pref_template,\n",
    "            \"consolidate_pref_template\": consolidate_pref_prompt,\n",
    "            \"decision_template\": decision_prompt_template,\n",
    "            \"final_query_template\": general_final_query_template,\n",
    "            \"refine_template\": general_refine_template,\n",
    "            \"expansion_template\": general_expansion_template,\n",
    "            \"re_ranking_template\": re_ranking_prompt,\n",
    "            \"hyde_generation_template\": hyde_generation_prompt,\n",
    "            \"hyde_keyword_template\": hyde_keyword_prompt,\n",
    "            \"retrieval_weights\": {\n",
    "                \"main\": 0.25,\n",
    "                \"author\": 0.25,\n",
    "                \"title\": 0.25,\n",
    "                \"category\": 0.25,\n",
    "            },\n",
    "            \"persona_info\": \"친절, 균형잡힌 정보, 사용자의 선호와 분위기를 반영\",\n",
    "            \"recommendation_intro_template\": recommendation_intro_prompt,\n",
    "            \"recommendation_outro_template\": recommendation_outro_prompt,\n",
    "        }\n",
    "        super().__init__(\n",
    "            config, llm, embeddings, vectorstore, es_store, retriever, documents\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "페르소나를 선택해주세요:\n",
      "1. 예술/문학 (감성적, 문학적 표현)\n",
      "2. 과학/기술 (논리적, 정확한 정보)\n",
      "3. 범용/일반 (친절, 균형잡힌 정보)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-08 11:34:59,494 - INFO - 선택된 페르소나: Literature\n",
      "2025-04-08 11:34:59,495 - INFO - --- Turn 1 시작 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'Literature' 페르소나로 대화를 시작합니다.\n",
      "대화를 종료하려면 'quit', 'exit', '종료', '그만' 중 하나를 입력하세요.\n",
      "----------------------------------------------------------------------\n",
      "[Literature] 안녕하세요~ 감성적인 문학 도서 추천 챗봇입니다. 어떤 책을 찾으시나요? 당신의 이야기나 감정을 들려주셔도 좋아요.\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "--- Turn 1 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-08 11:35:08,366 - INFO - === 새로운 사용자 쿼리 처리 시작: '해리포터 시리즈같은 소설 추천해줘.' ===\n",
      "2025-04-08 11:35:08,366 - INFO - 사용자 입력에서 선호도 추출 시작: '해리포터 시리즈같은 소설 추천해줘....'\n",
      "2025-04-08 11:35:09,835 - INFO - HTTP Request: POST https://clovastudio.stream.ntruss.com/testapp/v1/chat-completions/HCX-003 \"HTTP/1.1 200 OK\"\n",
      "2025-04-08 11:35:09,839 - INFO - 선호도 업데이트됨 [category]: ['소설']\n",
      "2025-04-08 11:35:09,840 - INFO - 선호도 업데이트됨 [implicit info]: ['해리포터 시리즈 같은']\n",
      "2025-04-08 11:35:09,840 - INFO - 선호도 업데이트 완료. 누적 업데이트 횟수: 1\n",
      "2025-04-08 11:35:09,841 - INFO - 행동 결정 요청 (추천 vs 추가 질문)\n",
      "2025-04-08 11:35:15,911 - INFO - HTTP Request: POST https://clovastudio.stream.ntruss.com/testapp/v1/chat-completions/HCX-003 \"HTTP/1.1 200 OK\"\n",
      "2025-04-08 11:35:15,913 - INFO - 행동 결정 파싱 결과: 행동='추천', 추가 질문='...'\n",
      "2025-04-08 11:35:15,913 - INFO - 행동: 추천\n",
      "2025-04-08 11:35:15,913 - INFO - 최종 검색 쿼리 생성 시작\n",
      "2025-04-08 11:35:16,729 - INFO - HTTP Request: POST https://clovastudio.stream.ntruss.com/testapp/v1/chat-completions/HCX-003 \"HTTP/1.1 200 OK\"\n",
      "2025-04-08 11:35:16,742 - INFO - LLM 생성 쿼리 (정제 전): '해리포터 시리즈 같은 감성적인 판타지 소설 추천'\n",
      "2025-04-08 11:35:17,539 - INFO - HTTP Request: POST https://clovastudio.stream.ntruss.com/testapp/v1/chat-completions/HCX-003 \"HTTP/1.1 200 OK\"\n",
      "2025-04-08 11:35:17,543 - INFO - 정제된 쿼리: '감성적인 판타지 소설 추천'\n",
      "2025-04-08 11:35:17,544 - INFO - 최종 결정된 검색 쿼리: '감성적인 판타지 소설 추천'\n",
      "2025-04-08 11:35:17,545 - INFO - 추천 생성 시작. 최종 쿼리: '감성적인 판타지 소설 추천'\n",
      "2025-04-08 11:35:17,545 - INFO - HyDE 활성화: 가상 문서 요약 및 키워드 추출 시도\n",
      "2025-04-08 11:35:20,617 - INFO - HTTP Request: POST https://clovastudio.stream.ntruss.com/testapp/v1/chat-completions/HCX-003 \"HTTP/1.1 200 OK\"\n",
      "2025-04-08 11:35:20,622 - INFO - 생성된 가상 문서 요약: '이 책은 마법과 신화가 공존하는 세계를 배경으로 한 감성적인 판타지 소설이다. 주인공 소녀가 자신의 정체성을 찾아가며 겪는 모험과 성장 이야기를 담고 있으며, 아름다운 묘사와 섬세한 감정선이 돋보인다....'\n",
      "2025-04-08 11:35:21,665 - INFO - HTTP Request: POST https://clovastudio.stream.ntruss.com/testapp/v1/chat-completions/HCX-003 \"HTTP/1.1 200 OK\"\n",
      "2025-04-08 11:35:21,670 - INFO - 추출된 HyDE 키워드: ['마법', '신화', '판타지', '정체성', '모험']\n",
      "2025-04-08 11:35:21,671 - INFO - HyDE 적용된 검색 쿼리: '감성적인 판타지 소설 추천 마법 신화 판타지 정체성 모험'\n",
      "2025-04-08 11:35:21,671 - INFO - 최종 리트리버 호출 시작 (쿼리: '감성적인 판타지 소설 추천 마법 신화 판타지 정체성 모험...')\n",
      "2025-04-08 11:35:21,772 - INFO - HTTP Request: POST https://clovastudio.stream.ntruss.com/testapp/v1/api-tools/embedding/v2 \"HTTP/1.1 200 OK\"\n",
      "2025-04-08 11:35:21,784 - INFO - POST http://localhost:9200/book_bm25_index_v2/_search [status:200 duration:0.110s]\n",
      "2025-04-08 11:35:22,707 - INFO - Async 검색 결과 총 문서 수: 10\n",
      "2025-04-08 11:35:22,707 - INFO - [Async] 병합 전 입력 문서 수: 10\n",
      "2025-04-08 11:35:22,712 - INFO - [Async] ISBN 병합 그룹 수: 9\n",
      "2025-04-08 11:35:22,712 - INFO - [Async] 병합 후 최종 문서 수: 9\n",
      "2025-04-08 11:35:22,714 - INFO - 검색된 문서 수 (ISBN 병합 완료됨): 9\n",
      "2025-04-08 11:35:22,714 - INFO - 검색 쿼리 확장 시작: '감성적인 판타지 소설 추천'\n",
      "2025-04-08 11:35:24,381 - INFO - HTTP Request: POST https://clovastudio.stream.ntruss.com/testapp/v1/chat-completions/HCX-003 \"HTTP/1.1 200 OK\"\n",
      "2025-04-08 11:35:24,388 - INFO - 생성된 확장 쿼리 (3개): ['중세시대를 배경으로 한 감성적인 판타지 소설 추천', '로맨스 요소가 들어간 감성적인 판타지 소설 추천', '인간의 내면을 다룬 감성적인 판타지 소설 추천']\n",
      "2025-04-08 11:35:24,389 - INFO - 확장 쿼리 (3개)로 추가 검색 수행...\n",
      "2025-04-08 11:35:24,392 - INFO - 일반 쿼리 검색 수행.\n",
      "2025-04-08 11:35:24,393 - INFO - 최종 리트리버 호출 시작 (쿼리: '중세시대를 배경으로 한 감성적인 판타지 소설 추천...')\n",
      "2025-04-08 11:35:24,395 - INFO - 일반 쿼리 검색 수행.\n",
      "2025-04-08 11:35:24,396 - INFO - 최종 리트리버 호출 시작 (쿼리: '로맨스 요소가 들어간 감성적인 판타지 소설 추천...')\n",
      "2025-04-08 11:35:24,397 - INFO - 일반 쿼리 검색 수행.\n",
      "2025-04-08 11:35:24,398 - INFO - 최종 리트리버 호출 시작 (쿼리: '인간의 내면을 다룬 감성적인 판타지 소설 추천...')\n",
      "2025-04-08 11:35:24,469 - INFO - HTTP Request: POST https://clovastudio.stream.ntruss.com/testapp/v1/api-tools/embedding/v2 \"HTTP/1.1 200 OK\"\n",
      "2025-04-08 11:35:24,484 - INFO - HTTP Request: POST https://clovastudio.stream.ntruss.com/testapp/v1/api-tools/embedding/v2 \"HTTP/1.1 200 OK\"\n",
      "2025-04-08 11:35:24,486 - INFO - HTTP Request: POST https://clovastudio.stream.ntruss.com/testapp/v1/api-tools/embedding/v2 \"HTTP/1.1 200 OK\"\n",
      "2025-04-08 11:35:24,492 - INFO - POST http://localhost:9200/book_bm25_index_v2/_search [status:200 duration:0.085s]\n",
      "2025-04-08 11:35:24,493 - INFO - POST http://localhost:9200/book_bm25_index_v2/_search [status:200 duration:0.091s]\n",
      "2025-04-08 11:35:24,501 - INFO - POST http://localhost:9200/book_bm25_index_v2/_search [status:200 duration:0.100s]\n",
      "2025-04-08 11:35:24,619 - INFO - Async 검색 결과 총 문서 수: 10\n",
      "2025-04-08 11:35:24,619 - INFO - [Async] 병합 전 입력 문서 수: 10\n",
      "2025-04-08 11:35:24,621 - INFO - [Async] ISBN 병합 그룹 수: 10\n",
      "2025-04-08 11:35:24,622 - INFO - [Async] 병합 후 최종 문서 수: 10\n",
      "2025-04-08 11:35:24,623 - INFO - 검색된 문서 수 (ISBN 병합 완료됨): 10\n",
      "2025-04-08 11:35:24,657 - INFO - Async 검색 결과 총 문서 수: 10\n",
      "2025-04-08 11:35:24,658 - INFO - [Async] 병합 전 입력 문서 수: 10\n",
      "2025-04-08 11:35:24,659 - INFO - [Async] ISBN 병합 그룹 수: 10\n",
      "2025-04-08 11:35:24,659 - INFO - [Async] 병합 후 최종 문서 수: 10\n",
      "2025-04-08 11:35:24,660 - INFO - 검색된 문서 수 (ISBN 병합 완료됨): 10\n",
      "2025-04-08 11:35:24,991 - INFO - Async 검색 결과 총 문서 수: 10\n",
      "2025-04-08 11:35:24,992 - INFO - [Async] 병합 전 입력 문서 수: 10\n",
      "2025-04-08 11:35:24,992 - INFO - [Async] ISBN 병합 그룹 수: 10\n",
      "2025-04-08 11:35:24,993 - INFO - [Async] 병합 후 최종 문서 수: 10\n",
      "2025-04-08 11:35:24,995 - INFO - 검색된 문서 수 (ISBN 병합 완료됨): 10\n",
      "2025-04-08 11:35:24,995 - INFO - 초기 및 확장 검색 후 고려할 총 고유 문서 수: 18\n",
      "2025-04-08 11:35:24,999 - INFO - 리랭킹 수행...\n",
      "2025-04-08 11:35:25,062 - INFO - HTTP Request: POST https://clovastudio.stream.ntruss.com/testapp/v1/api-tools/embedding/v2 \"HTTP/1.1 200 OK\"\n",
      "2025-04-08 11:35:25,065 - INFO - HTTP Request: POST https://clovastudio.stream.ntruss.com/testapp/v1/api-tools/embedding/v2 \"HTTP/1.1 200 OK\"\n",
      "2025-04-08 11:35:25,164 - INFO - HTTP Request: POST https://clovastudio.stream.ntruss.com/testapp/v1/api-tools/embedding/v2 \"HTTP/1.1 200 OK\"\n",
      "2025-04-08 11:35:25,237 - INFO - HTTP Request: POST https://clovastudio.stream.ntruss.com/testapp/v1/api-tools/embedding/v2 \"HTTP/1.1 200 OK\"\n",
      "2025-04-08 11:35:25,313 - INFO - HTTP Request: POST https://clovastudio.stream.ntruss.com/testapp/v1/api-tools/embedding/v2 \"HTTP/1.1 200 OK\"\n",
      "2025-04-08 11:35:25,392 - INFO - HTTP Request: POST https://clovastudio.stream.ntruss.com/testapp/v1/api-tools/embedding/v2 \"HTTP/1.1 200 OK\"\n",
      "2025-04-08 11:35:25,462 - INFO - HTTP Request: POST https://clovastudio.stream.ntruss.com/testapp/v1/api-tools/embedding/v2 \"HTTP/1.1 200 OK\"\n",
      "2025-04-08 11:35:25,527 - INFO - HTTP Request: POST https://clovastudio.stream.ntruss.com/testapp/v1/api-tools/embedding/v2 \"HTTP/1.1 200 OK\"\n",
      "2025-04-08 11:35:25,697 - INFO - HTTP Request: POST https://clovastudio.stream.ntruss.com/testapp/v1/api-tools/embedding/v2 \"HTTP/1.1 200 OK\"\n",
      "2025-04-08 11:35:25,782 - INFO - HTTP Request: POST https://clovastudio.stream.ntruss.com/testapp/v1/api-tools/embedding/v2 \"HTTP/1.1 200 OK\"\n",
      "2025-04-08 11:35:25,870 - INFO - HTTP Request: POST https://clovastudio.stream.ntruss.com/testapp/v1/api-tools/embedding/v2 \"HTTP/1.1 200 OK\"\n",
      "2025-04-08 11:35:25,946 - INFO - HTTP Request: POST https://clovastudio.stream.ntruss.com/testapp/v1/api-tools/embedding/v2 \"HTTP/1.1 200 OK\"\n",
      "2025-04-08 11:35:26,013 - INFO - HTTP Request: POST https://clovastudio.stream.ntruss.com/testapp/v1/api-tools/embedding/v2 \"HTTP/1.1 200 OK\"\n",
      "2025-04-08 11:35:26,123 - INFO - HTTP Request: POST https://clovastudio.stream.ntruss.com/testapp/v1/api-tools/embedding/v2 \"HTTP/1.1 200 OK\"\n",
      "2025-04-08 11:35:26,192 - INFO - HTTP Request: POST https://clovastudio.stream.ntruss.com/testapp/v1/api-tools/embedding/v2 \"HTTP/1.1 200 OK\"\n",
      "2025-04-08 11:35:26,287 - INFO - HTTP Request: POST https://clovastudio.stream.ntruss.com/testapp/v1/api-tools/embedding/v2 \"HTTP/1.1 200 OK\"\n",
      "2025-04-08 11:35:26,400 - INFO - HTTP Request: POST https://clovastudio.stream.ntruss.com/testapp/v1/api-tools/embedding/v2 \"HTTP/1.1 200 OK\"\n",
      "2025-04-08 11:35:26,481 - INFO - HTTP Request: POST https://clovastudio.stream.ntruss.com/testapp/v1/api-tools/embedding/v2 \"HTTP/1.1 200 OK\"\n",
      "2025-04-08 11:35:26,581 - INFO - HTTP Request: POST https://clovastudio.stream.ntruss.com/testapp/v1/api-tools/embedding/v2 \"HTTP/1.1 200 OK\"\n",
      "2025-04-08 11:35:26,649 - INFO - HTTP Request: POST https://clovastudio.stream.ntruss.com/testapp/v1/api-tools/embedding/v2 \"HTTP/1.1 200 OK\"\n",
      "2025-04-08 11:35:26,751 - INFO - HTTP Request: POST https://clovastudio.stream.ntruss.com/testapp/v1/api-tools/embedding/v2 \"HTTP/1.1 200 OK\"\n",
      "2025-04-08 11:35:26,831 - INFO - HTTP Request: POST https://clovastudio.stream.ntruss.com/testapp/v1/api-tools/embedding/v2 \"HTTP/1.1 200 OK\"\n",
      "2025-04-08 11:35:26,934 - INFO - HTTP Request: POST https://clovastudio.stream.ntruss.com/testapp/v1/api-tools/embedding/v2 \"HTTP/1.1 200 OK\"\n",
      "2025-04-08 11:35:27,000 - INFO - HTTP Request: POST https://clovastudio.stream.ntruss.com/testapp/v1/api-tools/embedding/v2 \"HTTP/1.1 200 OK\"\n",
      "2025-04-08 11:35:27,109 - INFO - HTTP Request: POST https://clovastudio.stream.ntruss.com/testapp/v1/api-tools/embedding/v2 \"HTTP/1.1 200 OK\"\n",
      "2025-04-08 11:35:27,186 - INFO - HTTP Request: POST https://clovastudio.stream.ntruss.com/testapp/v1/api-tools/embedding/v2 \"HTTP/1.1 200 OK\"\n",
      "2025-04-08 11:35:27,271 - INFO - HTTP Request: POST https://clovastudio.stream.ntruss.com/testapp/v1/api-tools/embedding/v2 \"HTTP/1.1 200 OK\"\n",
      "2025-04-08 11:35:27,337 - INFO - HTTP Request: POST https://clovastudio.stream.ntruss.com/testapp/v1/api-tools/embedding/v2 \"HTTP/1.1 200 OK\"\n",
      "2025-04-08 11:35:27,419 - INFO - HTTP Request: POST https://clovastudio.stream.ntruss.com/testapp/v1/api-tools/embedding/v2 \"HTTP/1.1 200 OK\"\n",
      "2025-04-08 11:35:27,495 - INFO - HTTP Request: POST https://clovastudio.stream.ntruss.com/testapp/v1/api-tools/embedding/v2 \"HTTP/1.1 200 OK\"\n",
      "2025-04-08 11:35:27,612 - INFO - HTTP Request: POST https://clovastudio.stream.ntruss.com/testapp/v1/api-tools/embedding/v2 \"HTTP/1.1 200 OK\"\n",
      "2025-04-08 11:35:27,678 - INFO - HTTP Request: POST https://clovastudio.stream.ntruss.com/testapp/v1/api-tools/embedding/v2 \"HTTP/1.1 200 OK\"\n",
      "2025-04-08 11:35:27,789 - INFO - HTTP Request: POST https://clovastudio.stream.ntruss.com/testapp/v1/api-tools/embedding/v2 \"HTTP/1.1 200 OK\"\n",
      "2025-04-08 11:35:27,859 - INFO - HTTP Request: POST https://clovastudio.stream.ntruss.com/testapp/v1/api-tools/embedding/v2 \"HTTP/1.1 200 OK\"\n",
      "2025-04-08 11:35:27,863 - INFO - 리랭킹 완료 (정규화 가중치 방식)\n",
      "2025-04-08 11:35:27,864 - INFO - 1. 제목: 온화한 귀족의 휴가의 권장5 | ISBN: 9791169181075 | 점수: 0.5548\n",
      "2025-04-08 11:35:27,864 - INFO - 2. 제목: 유럽의 판타지 백과사전 | ISBN: 9791189576561 | 점수: 0.5228\n",
      "2025-04-08 11:35:27,865 - INFO - 3. 제목: 삶이 길을 묻거든 | ISBN: 9791166496240 | 점수: 0.5183\n",
      "2025-04-08 11:35:27,867 - INFO - 4. 제목: 하루 한 편, 세상에서 가장 짧은 명작 읽기 1 | ISBN: 9791190908986 | 점수: 0.5129\n",
      "2025-04-08 11:35:27,868 - INFO - 5. 제목: 죄와 벌 | ISBN: 9791170360421 | 점수: 0.5081\n",
      "2025-04-08 11:35:27,869 - INFO - 6. 제목: 섀도우 앤 본 | ISBN: 9791135498114 | 점수: 0.5058\n",
      "2025-04-08 11:35:27,869 - INFO - 7. 제목: 사랑을 묻다 | ISBN: 9788974162542 | 점수: 0.502\n",
      "2025-04-08 11:35:27,870 - INFO - 8. 제목: 어머니의 음성같이 옛 애인의 음성같이 | ISBN: 9791188862856 | 점수: 0.4996\n",
      "2025-04-08 11:35:27,871 - INFO - 9. 제목: 고전 여행자의 책 | ISBN: 9788960906211 | 점수: 0.4956\n",
      "2025-04-08 11:35:27,871 - INFO - 10. 제목: [큰글자도서] 고전 여행자의 책 1 | ISBN: 9788960907164 | 점수: 0.4951\n",
      "2025-04-08 11:35:27,871 - INFO - 11. 제목: 깊은 밤 마법 열차 | ISBN: 9788901258423 | 점수: 0.4907\n",
      "2025-04-08 11:35:27,872 - INFO - 12. 제목: 인생맛 세상맛 | ISBN: 9791191735451 | 점수: 0.483\n",
      "2025-04-08 11:35:27,873 - INFO - 13. 제목: 불타는 광야 | ISBN: 9788977347670 | 점수: 0.4754\n",
      "2025-04-08 11:35:27,875 - INFO - 14. 제목: 신화의 힘 | ISBN: 9788950987220 | 점수: 0.4678\n",
      "2025-04-08 11:35:27,875 - INFO - 15. 제목: 길 위에서는 누구나 청춘이다 | ISBN: 9791160543759 | 점수: 0.4656\n",
      "2025-04-08 11:35:27,876 - INFO - 16. 제목: 그림 영혼의 부딪힘 | ISBN: 9788925577258 | 점수: 0.4563\n",
      "2025-04-08 11:35:27,876 - INFO - 17. 제목: 예술속의 삶 삶속의 예술 | ISBN: 9791197321405 | 점수: 0.4563\n",
      "2025-04-08 11:35:27,877 - INFO - 18. 제목: 그림과 수다와 속삭임 | ISBN: 9791157771301 | 점수: 0.408\n",
      "2025-04-08 11:35:27,877 - INFO - 리랭킹 완료 (0.5 이상 필터 적용됨)\n",
      "2025-04-08 11:35:27,878 - INFO - 최종 추천 후보 문서 수: 3\n",
      "2025-04-08 11:35:30,684 - INFO - HTTP Request: POST https://clovastudio.stream.ntruss.com/testapp/v1/chat-completions/HCX-003 \"HTTP/1.1 200 OK\"\n",
      "2025-04-08 11:35:37,634 - INFO - HTTP Request: POST https://clovastudio.stream.ntruss.com/testapp/v1/chat-completions/HCX-003 \"HTTP/1.1 200 OK\"\n",
      "2025-04-08 11:35:41,052 - INFO - HTTP Request: POST https://clovastudio.stream.ntruss.com/testapp/v1/chat-completions/HCX-003 \"HTTP/1.1 200 OK\"\n",
      "2025-04-08 11:35:41,055 - INFO - '_generate_recommendations' 종료. last_recommendations 업데이트 (3개): ['온화한 귀족의 휴가의 권장5', '유럽의 판타지 백과사전', '삶이 길을 묻거든']\n",
      "2025-04-08 11:35:43,531 - INFO - HTTP Request: POST https://clovastudio.stream.ntruss.com/testapp/v1/chat-completions/HCX-003 \"HTTP/1.1 200 OK\"\n",
      "2025-04-08 11:35:45,316 - INFO - HTTP Request: POST https://clovastudio.stream.ntruss.com/testapp/v1/chat-completions/HCX-003 \"HTTP/1.1 200 OK\"\n",
      "2025-04-08 11:35:45,322 - INFO - 추천 응답 생성 완료.\n",
      "2025-04-08 11:35:45,324 - INFO - 챗봇 응답 생성 완료 (Action: 추천). 응답 일부: 네. 감성적인 판타지 소설을 찾으시는군요. 마음을 따뜻하게 해줄 수 있는 작품들로 추천해 드리겠습니다.\n",
      "\n",
      "1. \n",
      "표지: https://image.aladin.co.kr/product/29624/14/cover500/k702838374_1.jpg\n",
      "제목: 온화한 귀족의 휴가의 권장5\n",
      "저자: Misaki 지음 / Momochi 일러스트\n",
      "- 추천 이유: 이...\n",
      "2025-04-08 11:35:45,325 - INFO - --- Turn 2 시작 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------\n",
      "[Literature]\n",
      "네. 감성적인 판타지 소설을 찾으시는군요. 마음을 따뜻하게 해줄 수 있는 작품들로 추천해 드리겠습니다.\n",
      "\n",
      "1. \n",
      "표지: https://image.aladin.co.kr/product/29624/14/cover500/k702838374_1.jpg\n",
      "제목: 온화한 귀족의 휴가의 권장5\n",
      "저자: Misaki 지음 / Momochi 일러스트\n",
      "- 추천 이유: 이 책은 판타지 세계에서 재상으로 활약하던 청년 리젤이 갑작스러운 이세계 전이 후에도 자신의 능력을 발휘하여 상급 모험가와 함께 모험을 떠나는 이야기예요. 주인공은 휴가라고 생각하며 이세계에서의 삶을 즐기고 있어요.\n",
      "\n",
      "2. \n",
      "표지: https://image.aladin.co.kr/product/23616/15/cover500/k332638520_1.jpg\n",
      "제목: 유럽의 판타지 백과사전\n",
      "저자: 도현신 지음\n",
      "- 추천 이유: 이 책은 유럽의 다양한 신화와 전설을 바탕으로 한 판타지 세계를 다루고 있어요. 그리스 신화부터 북유럽, 켈트, 동유럽, 핀란드 신화까지 다루면서, 세상의 시작, 신, 영웅, 마법사, 괴물, 요정 등 다양한 주제에 대한 이야기를 110가지 항목으로 정리했죠. 이 책을 통해 유럽의 판타지 세계를 깊이 이해하면, 한국형 판타지 창작에도 큰 도움이 될 거예요. 또한, 이 책은 총 7권으로 기획된 '판타지 백과사전 시리즈'의 네 번째 책으로, 세계인이 함께 즐길 수 있는 다양한 문화 콘텐츠가 만들어지길 바라는 작가의 희망이 담겨 있답니다!\n",
      "\n",
      "3. \n",
      "표지: https://image.aladin.co.kr/product/27031/26/cover500/k022730629_1.jpg\n",
      "제목: 삶이 길을 묻거든\n",
      "저자: 문규연 지음\n",
      "- 추천 이유: 이 책은 삶의 다양한 고민과 감정, 그리고 인생 여정에서 마주치는 여러 문제들을 시로 표현한 작품이에요. 작가가 어린 시절의 추억과 사랑의 아픔, 그리고 노년의 회상 등을 다루며, 독자들에게 공감과 감동을 선사해요. 또한, 과거의 소중한 순간들을 떠올리며 현재와 미래를 생각해보는 계기를 제공하기도 해요.\n",
      "\n",
      "\"제가 추천 드린 감성적인 판타지 소설 중에서 꼭 마음에 드는 책을 찾으셨으면 좋겠어요! 새로운 세계와 이야기 속에서 즐거운 시간 보내시길 바랍니다 :)\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "--- Turn 2 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-08 11:35:47,792 - INFO - --- Turn 3 시작 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Turn 3 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-08 11:35:58,059 - INFO - Default Milvus 연결 해제 완료.\n",
      "2025-04-08 11:35:58,059 - INFO - 프로그램 종료.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[대화 종료]\n"
     ]
    }
   ],
   "source": [
    "nest_asyncio.apply()\n",
    "\n",
    "\n",
    "def main():\n",
    "    previous_additional_question_embeddings.clear()\n",
    "    print(\"페르소나를 선택해주세요:\")\n",
    "    print(\"1. 예술/문학 (감성적, 문학적 표현)\")\n",
    "    print(\"2. 과학/기술 (논리적, 정확한 정보)\")\n",
    "    print(\"3. 범용/일반 (친절, 균형잡힌 정보)\")\n",
    "    pipeline = None\n",
    "    while pipeline is None:\n",
    "        choice = input(\"원하는 페르소나 번호를 입력하세요 (1, 2, 3): \").strip()\n",
    "        pipeline_map = {\n",
    "            \"1\": LiteratureRAGPipeline,\n",
    "            \"2\": ScienceRAGPipeline,\n",
    "            \"3\": GeneralRAGPipeline,\n",
    "        }\n",
    "        if choice in pipeline_map:\n",
    "            PipelineClass = pipeline_map[choice]\n",
    "            try:\n",
    "                pipeline = PipelineClass(\n",
    "                    llm=llm_clova,\n",
    "                    embeddings=ncp_embeddings,\n",
    "                    vectorstore=vectorstore,\n",
    "                    es_store=es_store,\n",
    "                    retriever=merged_hybrid_retriever,\n",
    "                    documents=documents,\n",
    "                )\n",
    "                logger.info(f\"선택된 페르소나: {pipeline.config['persona']}\")\n",
    "                print(f\"\\n'{pipeline.config['persona']}' 페르소나로 대화를 시작합니다.\")\n",
    "                print(\n",
    "                    \"대화를 종료하려면 'quit', 'exit', '종료', '그만' 중 하나를 입력하세요.\"\n",
    "                )\n",
    "            except Exception as e:\n",
    "                logger.critical(\n",
    "                    f\"파이프라인 초기화 중 치명적 오류 발생: {e}\", exc_info=True\n",
    "                )\n",
    "                print(\"오류: 파이프라인을 초기화할 수 없습니다. 로그를 확인하세요.\")\n",
    "                return\n",
    "        else:\n",
    "            print(\"잘못된 선택입니다. 1, 2, 3 중 하나를 입력해주세요.\")\n",
    "    try:\n",
    "        asyncio.run(pipeline.interactive_multi_turn_qa())\n",
    "    except Exception as e:\n",
    "        logger.critical(f\"메인 실행 루프에서 치명적 오류 발생: {e}\", exc_info=True)\n",
    "    finally:\n",
    "        try:\n",
    "            if connections.get_connection_addr(\"default\"):\n",
    "                connections.disconnect(\"default\")\n",
    "                logger.info(\"Default Milvus 연결 해제 완료.\")\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Milvus 연결 해제 중 오류 발생 (무시 가능): {e}\")\n",
    "        logger.info(\"프로그램 종료.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kill_the_RAG_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
