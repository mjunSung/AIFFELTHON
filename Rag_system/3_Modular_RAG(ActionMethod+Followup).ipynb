{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import pickle\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "import pandas as pd\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from IPython.display import clear_output\n",
    "from typing import List\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.chains import RetrievalQA, LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.embeddings import ClovaXEmbeddings\n",
    "from langchain_community.chat_models import ChatClovaX\n",
    "from pymilvus import connections, utility\n",
    "from langchain_community.vectorstores.milvus import Milvus\n",
    "from langchain.schema import BaseRetriever\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from pydantic import BaseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ISBNMergingRetriever(BaseRetriever):\n",
    "    \"\"\"\n",
    "    BaseRetriever를 감싸서, 검색 결과를 ISBN 기준으로 그룹화하고\n",
    "    각 그룹의 청크를 하나의 Document로 병합하여 반환한다.\n",
    "    \"\"\"\n",
    "\n",
    "    base_retriever: BaseRetriever  # Pydantic 필드 선언\n",
    "\n",
    "    def _get_relevant_documents(self, query: str) -> List[Document]:\n",
    "        docs = self.base_retriever.get_relevant_documents(query)\n",
    "        grouped = {}\n",
    "        for doc in docs:\n",
    "            isbn = doc.metadata.get(\"ISBN\", \"NO_ISBN\")\n",
    "            grouped.setdefault(isbn, []).append(doc)\n",
    "        merged_docs = []\n",
    "        for isbn, doc_list in grouped.items():\n",
    "            combined_text = \"\\n\".join(d.page_content for d in doc_list)\n",
    "            merged_meta = dict(doc_list[0].metadata)\n",
    "            print(\n",
    "                f\"[디버그] ISBN: {isbn}, 병합된 청크 수: {len(doc_list)}, 병합 텍스트 길이: {len(combined_text)}\"\n",
    "            )\n",
    "            merged_docs.append(\n",
    "                Document(page_content=combined_text, metadata=merged_meta)\n",
    "            )\n",
    "        return merged_docs\n",
    "\n",
    "    async def _aget_relevant_documents(self, query: str) -> List[Document]:\n",
    "        docs = await self.base_retriever.aget_relevant_documents(query)\n",
    "        grouped = {}\n",
    "        for doc in docs:\n",
    "            isbn = doc.metadata.get(\"ISBN\", \"NO_ISBN\")\n",
    "            grouped.setdefault(isbn, []).append(doc)\n",
    "        merged_docs = []\n",
    "        for isbn, doc_list in grouped.items():\n",
    "            combined_text = \"\\n\".join(d.page_content for d in doc_list)\n",
    "            merged_meta = dict(doc_list[0].metadata)\n",
    "            merged_docs.append(\n",
    "                Document(page_content=combined_text, metadata=merged_meta)\n",
    "            )\n",
    "        return merged_docs\n",
    "\n",
    "    def add_documents(self, documents: List[Document], **kwargs) -> None:\n",
    "        pass\n",
    "\n",
    "    def get_type(self) -> str:\n",
    "        return \"isbn_merging_retriever\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 환경설정, 임베딩, 문서 구성 등\n",
    "\n",
    "previous_additional_question_embeddings = []\n",
    "\n",
    "\n",
    "def is_similar_question(new_emb, prev_embeds, threshold=0.65):\n",
    "    if not prev_embeds:\n",
    "        return False\n",
    "    sim_scores = cosine_similarity([new_emb], prev_embeds)[0]\n",
    "    max_score = max(sim_scores)\n",
    "    print(f\"[중복 유사도 판단] Max = {max_score:.3f}\")\n",
    "    return max_score > threshold\n",
    "\n",
    "\n",
    "load_dotenv(dotenv_path=r\"\")\n",
    "\n",
    "os.environ[\"NCP_CLOVASTUDIO_API_KEY\"] = os.getenv(\"NCP_CLOVASTUDIO_API_KEY\")\n",
    "os.environ[\"NCP_CLOVASTUDIO_API_URL\"] = os.getenv(\n",
    "    \"NCP_CLOVASTUDIO_API_URL\", \"https://clovastudio.stream.ntruss.com/\"\n",
    ")\n",
    "\n",
    "connections.connect(\n",
    "    alias=\"default\",\n",
    "    host=os.getenv(\"MILVUS_HOST\", \"localhost\"),\n",
    "    port=os.getenv(\"MILVUS_PORT\", \"19530\"),\n",
    ")\n",
    "\n",
    "ncp_embeddings = ClovaXEmbeddings(model=\"bge-m3\")\n",
    "llm_clova = ChatClovaX(model=\"HCX-003\", max_tokens=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "임베딩 데이터 불러오기\n"
     ]
    }
   ],
   "source": [
    "embedding_file = r\"\"\n",
    "if os.path.exists(embedding_file):\n",
    "    with open(embedding_file, \"rb\") as f:\n",
    "        saved_data = pickle.load(f)\n",
    "    all_text_embedding_pairs = saved_data[\"embeddings\"]\n",
    "    all_metadata_list = saved_data[\"metadata\"]\n",
    "    print(\"임베딩 데이터 불러오기\")\n",
    "else:\n",
    "    raise FileNotFoundError(f\"임베딩 파일을 찾을 수 없습니다: {embedding_file}\")\n",
    "\n",
    "metadata_mapping = {\n",
    "    \"ISBN\": \"ISBN\",\n",
    "    \"페이지\": \"page\",\n",
    "    \"가격\": \"price\",\n",
    "    \"제목\": \"title\",\n",
    "    \"저자\": \"author\",\n",
    "    \"분류\": \"category\",\n",
    "    \"저자소개\": \"author_intro\",\n",
    "    \"책소개\": \"book_intro\",\n",
    "    \"목차\": \"table_of_contents\",\n",
    "    \"출판사리뷰\": \"publisher_review\",\n",
    "    \"추천사\": \"recommendation\",\n",
    "}\n",
    "\n",
    "all_metadata_list_mapped = []\n",
    "for meta in all_metadata_list:\n",
    "    mapped_meta = {metadata_mapping.get(key, key): value for key, value in meta.items()}\n",
    "    all_metadata_list_mapped.append(mapped_meta)\n",
    "\n",
    "documents = [\n",
    "    Document(page_content=pair[0], metadata=meta)\n",
    "    for pair, meta in zip(all_text_embedding_pairs, all_metadata_list_mapped)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\computer\\AppData\\Local\\Temp\\ipykernel_40208\\3539998358.py:5: LangChainDeprecationWarning: The class `Milvus` was deprecated in LangChain 0.2.0 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-milvus package and should be used instead. To use it run `pip install -U :class:`~langchain-milvus` and import as `from :class:`~langchain_milvus import MilvusVectorStore``.\n",
      "  vectorstore = Milvus(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[457017515479502109,\n",
       " 457017515479502110,\n",
       " 457017515479502111,\n",
       " 457017515479502112,\n",
       " 457017515479502113,\n",
       " 457017515479502114,\n",
       " 457017515479502115,\n",
       " 457017515479502116,\n",
       " 457017515479502117,\n",
       " 457017515479502118,\n",
       " 457017515479502119,\n",
       " 457017515479502120,\n",
       " 457017515479502121,\n",
       " 457017515479502122,\n",
       " 457017515479502123,\n",
       " 457017515479502124,\n",
       " 457017515479502125,\n",
       " 457017515479502126,\n",
       " 457017515479502127,\n",
       " 457017515479502128,\n",
       " 457017515479502129,\n",
       " 457017515479502130,\n",
       " 457017515479502131,\n",
       " 457017515479502132,\n",
       " 457017515479502133,\n",
       " 457017515479502134,\n",
       " 457017515479502135,\n",
       " 457017515479502136,\n",
       " 457017515479502137,\n",
       " 457017515479502138,\n",
       " 457017515479502139,\n",
       " 457017515479502140,\n",
       " 457017515479502141,\n",
       " 457017515479502142,\n",
       " 457017515479502143,\n",
       " 457017515479502144,\n",
       " 457017515479502145,\n",
       " 457017515479502146,\n",
       " 457017515479502147,\n",
       " 457017515479502148,\n",
       " 457017515479502149,\n",
       " 457017515479502150,\n",
       " 457017515479502151,\n",
       " 457017515479502152,\n",
       " 457017515479502153,\n",
       " 457017515479502154,\n",
       " 457017515479502155,\n",
       " 457017515479502156,\n",
       " 457017515479502157,\n",
       " 457017515479502158,\n",
       " 457017515479502159,\n",
       " 457017515479502160,\n",
       " 457017515479502161,\n",
       " 457017515479502162,\n",
       " 457017515479502163,\n",
       " 457017515479502164,\n",
       " 457017515479502165,\n",
       " 457017515479502166,\n",
       " 457017515479502167,\n",
       " 457017515479502168,\n",
       " 457017515479502169,\n",
       " 457017515479502170,\n",
       " 457017515479502171,\n",
       " 457017515479502172,\n",
       " 457017515479502173,\n",
       " 457017515479502174,\n",
       " 457017515479502175,\n",
       " 457017515479502176,\n",
       " 457017515479502177,\n",
       " 457017515479502178,\n",
       " 457017515479502179,\n",
       " 457017515479502180,\n",
       " 457017515479502181,\n",
       " 457017515479502182,\n",
       " 457017515479502183,\n",
       " 457017515479502184,\n",
       " 457017515479502185,\n",
       " 457017515479502186,\n",
       " 457017515479502187,\n",
       " 457017515479502188,\n",
       " 457017515479502189,\n",
       " 457017515479502190,\n",
       " 457017515479502191,\n",
       " 457017515479502192,\n",
       " 457017515479502193,\n",
       " 457017515479502194,\n",
       " 457017515479502195,\n",
       " 457017515479502196,\n",
       " 457017515479502197,\n",
       " 457017515479502198,\n",
       " 457017515479502199,\n",
       " 457017515479502200,\n",
       " 457017515479502201,\n",
       " 457017515479502202,\n",
       " 457017515479502203,\n",
       " 457017515479502204,\n",
       " 457017515479502205,\n",
       " 457017515479502206,\n",
       " 457017515479502207,\n",
       " 457017515479502208,\n",
       " 457017515479502209,\n",
       " 457017515479502210,\n",
       " 457017515479502211,\n",
       " 457017515479502212,\n",
       " 457017515479502213,\n",
       " 457017515479502214,\n",
       " 457017515479502215,\n",
       " 457017515479502216,\n",
       " 457017515479502217,\n",
       " 457017515479502218,\n",
       " 457017515479502219,\n",
       " 457017515479502220,\n",
       " 457017515479502221,\n",
       " 457017515479502222,\n",
       " 457017515479502223,\n",
       " 457017515479502224,\n",
       " 457017515479502225,\n",
       " 457017515479502226,\n",
       " 457017515479502227,\n",
       " 457017515479502228,\n",
       " 457017515479502229,\n",
       " 457017515479502230,\n",
       " 457017515479502231,\n",
       " 457017515479502232,\n",
       " 457017515479502233,\n",
       " 457017515479502234,\n",
       " 457017515479502235,\n",
       " 457017515479502236,\n",
       " 457017515479502237,\n",
       " 457017515479502238,\n",
       " 457017515479502239,\n",
       " 457017515479502240,\n",
       " 457017515479502241,\n",
       " 457017515479502242,\n",
       " 457017515479502243,\n",
       " 457017515479502244,\n",
       " 457017515479502245,\n",
       " 457017515479502246,\n",
       " 457017515479502247,\n",
       " 457017515479502248,\n",
       " 457017515479502249,\n",
       " 457017515479502250,\n",
       " 457017515479502251,\n",
       " 457017515479502252,\n",
       " 457017515479502253,\n",
       " 457017515479502254,\n",
       " 457017515479502255,\n",
       " 457017515479502256,\n",
       " 457017515479502257,\n",
       " 457017515479502258,\n",
       " 457017515479502259,\n",
       " 457017515479502260,\n",
       " 457017515479502261,\n",
       " 457017515479502262,\n",
       " 457017515479502263,\n",
       " 457017515479502264,\n",
       " 457017515479502265,\n",
       " 457017515479502266,\n",
       " 457017515479502267,\n",
       " 457017515479502268,\n",
       " 457017515479502269,\n",
       " 457017515479502270,\n",
       " 457017515479502271,\n",
       " 457017515479502272,\n",
       " 457017515479502273,\n",
       " 457017515479502274,\n",
       " 457017515479502275,\n",
       " 457017515479502276,\n",
       " 457017515479502277,\n",
       " 457017515479502278,\n",
       " 457017515479502279,\n",
       " 457017515479502280,\n",
       " 457017515479502281,\n",
       " 457017515479502282,\n",
       " 457017515479502283,\n",
       " 457017515479502284,\n",
       " 457017515479502285,\n",
       " 457017515479502286,\n",
       " 457017515479502287,\n",
       " 457017515479502288,\n",
       " 457017515479502289,\n",
       " 457017515479502290,\n",
       " 457017515479502291,\n",
       " 457017515479502292,\n",
       " 457017515479502293,\n",
       " 457017515479502294,\n",
       " 457017515479502295,\n",
       " 457017515479502296,\n",
       " 457017515479502297,\n",
       " 457017515479502298,\n",
       " 457017515479502299,\n",
       " 457017515479502300,\n",
       " 457017515479502301,\n",
       " 457017515479502302,\n",
       " 457017515479502303,\n",
       " 457017515479502304,\n",
       " 457017515479502305,\n",
       " 457017515479502306,\n",
       " 457017515479502307,\n",
       " 457017515479502308,\n",
       " 457017515479502309,\n",
       " 457017515479502310,\n",
       " 457017515479502311,\n",
       " 457017515479502312,\n",
       " 457017515479502313,\n",
       " 457017515479502314,\n",
       " 457017515479502315,\n",
       " 457017515479502316,\n",
       " 457017515479502317,\n",
       " 457017515479502318,\n",
       " 457017515479502319,\n",
       " 457017515479502320,\n",
       " 457017515479502321,\n",
       " 457017515479502322,\n",
       " 457017515479502323,\n",
       " 457017515479502324,\n",
       " 457017515479502325,\n",
       " 457017515479502326,\n",
       " 457017515479502327,\n",
       " 457017515479502328,\n",
       " 457017515479502329,\n",
       " 457017515479502330,\n",
       " 457017515479502331,\n",
       " 457017515479502332,\n",
       " 457017515479502333,\n",
       " 457017515479502334,\n",
       " 457017515479502335,\n",
       " 457017515479502336,\n",
       " 457017515479502337,\n",
       " 457017515479502338,\n",
       " 457017515479502339,\n",
       " 457017515479502340,\n",
       " 457017515479502341,\n",
       " 457017515479502342,\n",
       " 457017515479502343,\n",
       " 457017515479502344,\n",
       " 457017515479502345,\n",
       " 457017515479502346,\n",
       " 457017515479502347,\n",
       " 457017515479502348,\n",
       " 457017515479502349,\n",
       " 457017515479502350,\n",
       " 457017515479502351,\n",
       " 457017515479502352,\n",
       " 457017515479502353,\n",
       " 457017515479502354,\n",
       " 457017515479502355,\n",
       " 457017515479502356,\n",
       " 457017515479502357,\n",
       " 457017515479502358,\n",
       " 457017515479502359,\n",
       " 457017515479502360,\n",
       " 457017515479502361,\n",
       " 457017515479502362,\n",
       " 457017515479502363,\n",
       " 457017515479502364,\n",
       " 457017515479502365,\n",
       " 457017515479502366,\n",
       " 457017515479502367,\n",
       " 457017515479502368,\n",
       " 457017515479502369,\n",
       " 457017515479502370,\n",
       " 457017515479502371,\n",
       " 457017515479502372,\n",
       " 457017515479502373,\n",
       " 457017515479502374,\n",
       " 457017515479502375,\n",
       " 457017515479502376,\n",
       " 457017515479502377,\n",
       " 457017515479502378,\n",
       " 457017515479502379,\n",
       " 457017515479502380,\n",
       " 457017515479502381,\n",
       " 457017515479502382,\n",
       " 457017515479502383,\n",
       " 457017515479502384,\n",
       " 457017515479502385,\n",
       " 457017515479502386,\n",
       " 457017515479502387,\n",
       " 457017515479502388,\n",
       " 457017515479502389,\n",
       " 457017515479502390,\n",
       " 457017515479502391,\n",
       " 457017515479502392,\n",
       " 457017515479502393,\n",
       " 457017515479502394,\n",
       " 457017515479502395,\n",
       " 457017515479502396,\n",
       " 457017515479502397,\n",
       " 457017515479502398,\n",
       " 457017515479502399,\n",
       " 457017515479502400,\n",
       " 457017515479502401,\n",
       " 457017515479502402,\n",
       " 457017515479502403,\n",
       " 457017515479502404,\n",
       " 457017515479502405,\n",
       " 457017515479502406,\n",
       " 457017515479502407,\n",
       " 457017515479502408,\n",
       " 457017515479502409,\n",
       " 457017515479502410,\n",
       " 457017515479502411,\n",
       " 457017515479502412,\n",
       " 457017515479502413,\n",
       " 457017515479502414,\n",
       " 457017515479502415,\n",
       " 457017515479502416,\n",
       " 457017515479502417,\n",
       " 457017515479502418,\n",
       " 457017515479502419,\n",
       " 457017515479502420,\n",
       " 457017515479502421,\n",
       " 457017515479502422,\n",
       " 457017515479502423,\n",
       " 457017515479502424,\n",
       " 457017515479502425,\n",
       " 457017515479502426,\n",
       " 457017515479502427,\n",
       " 457017515479502428,\n",
       " 457017515479502429,\n",
       " 457017515479502430,\n",
       " 457017515479502431,\n",
       " 457017515479502432,\n",
       " 457017515479502433,\n",
       " 457017515479502434,\n",
       " 457017515479502435,\n",
       " 457017515479502436,\n",
       " 457017515479502437,\n",
       " 457017515479502438,\n",
       " 457017515479502439,\n",
       " 457017515479502440,\n",
       " 457017515479502441,\n",
       " 457017515479502442,\n",
       " 457017515479502443,\n",
       " 457017515479502444,\n",
       " 457017515479502445,\n",
       " 457017515479502446,\n",
       " 457017515479502447,\n",
       " 457017515479502448,\n",
       " 457017515479502449,\n",
       " 457017515479502450,\n",
       " 457017515479502451,\n",
       " 457017515479502452,\n",
       " 457017515479502453,\n",
       " 457017515479502454,\n",
       " 457017515479502455,\n",
       " 457017515479502456,\n",
       " 457017515479502457,\n",
       " 457017515479502458,\n",
       " 457017515479502459,\n",
       " 457017515479502460,\n",
       " 457017515479502461,\n",
       " 457017515479502462,\n",
       " 457017515479502463,\n",
       " 457017515479502464,\n",
       " 457017515479502465,\n",
       " 457017515479502466,\n",
       " 457017515479502467,\n",
       " 457017515479502468,\n",
       " 457017515479502469,\n",
       " 457017515479502470,\n",
       " 457017515479502471,\n",
       " 457017515479502472,\n",
       " 457017515479502473,\n",
       " 457017515479502474,\n",
       " 457017515479502475,\n",
       " 457017515479502476,\n",
       " 457017515479502477,\n",
       " 457017515479502478,\n",
       " 457017515479502479,\n",
       " 457017515479502480,\n",
       " 457017515479502481,\n",
       " 457017515479502482,\n",
       " 457017515479502483,\n",
       " 457017515479502484,\n",
       " 457017515479502485,\n",
       " 457017515479502486,\n",
       " 457017515479502487,\n",
       " 457017515479502488,\n",
       " 457017515479502489,\n",
       " 457017515479502490,\n",
       " 457017515479502491,\n",
       " 457017515479502492,\n",
       " 457017515479502493,\n",
       " 457017515479502494,\n",
       " 457017515479502495,\n",
       " 457017515479502496,\n",
       " 457017515479502497,\n",
       " 457017515479502498,\n",
       " 457017515479502499,\n",
       " 457017515479502500,\n",
       " 457017515479502501,\n",
       " 457017515479502502,\n",
       " 457017515479502503,\n",
       " 457017515479502504,\n",
       " 457017515479502505,\n",
       " 457017515479502506,\n",
       " 457017515479502507,\n",
       " 457017515479502508,\n",
       " 457017515479502509,\n",
       " 457017515479502510,\n",
       " 457017515479502511,\n",
       " 457017515479502512,\n",
       " 457017515479502513,\n",
       " 457017515479502514,\n",
       " 457017515479502515,\n",
       " 457017515479502516,\n",
       " 457017515479502517,\n",
       " 457017515479502518,\n",
       " 457017515479502519,\n",
       " 457017515479502520,\n",
       " 457017515479502521,\n",
       " 457017515479502522,\n",
       " 457017515479502523,\n",
       " 457017515479502524,\n",
       " 457017515479502525,\n",
       " 457017515479502526,\n",
       " 457017515479502527,\n",
       " 457017515479502528,\n",
       " 457017515479502529,\n",
       " 457017515479502530,\n",
       " 457017515479502531,\n",
       " 457017515479502532,\n",
       " 457017515479502533,\n",
       " 457017515479502534,\n",
       " 457017515479502535,\n",
       " 457017515479502536,\n",
       " 457017515479502537,\n",
       " 457017515479502538,\n",
       " 457017515479502539,\n",
       " 457017515479502540,\n",
       " 457017515479502541,\n",
       " 457017515479502542,\n",
       " 457017515479502543,\n",
       " 457017515479502544,\n",
       " 457017515479502545,\n",
       " 457017515479502546,\n",
       " 457017515479502547,\n",
       " 457017515479502548,\n",
       " 457017515479502549,\n",
       " 457017515479502550,\n",
       " 457017515479502551,\n",
       " 457017515479502552,\n",
       " 457017515479502553,\n",
       " 457017515479502554,\n",
       " 457017515479502555,\n",
       " 457017515479502556,\n",
       " 457017515479502557,\n",
       " 457017515479502558,\n",
       " 457017515479502559,\n",
       " 457017515479502560,\n",
       " 457017515479502561,\n",
       " 457017515479502562,\n",
       " 457017515479502563,\n",
       " 457017515479502564,\n",
       " 457017515479502565,\n",
       " 457017515479502566,\n",
       " 457017515479502567,\n",
       " 457017515479502568,\n",
       " 457017515479502569,\n",
       " 457017515479502570,\n",
       " 457017515479502571,\n",
       " 457017515479502572,\n",
       " 457017515479502573,\n",
       " 457017515479502574,\n",
       " 457017515479502575,\n",
       " 457017515479502576,\n",
       " 457017515479502577,\n",
       " 457017515479502578,\n",
       " 457017515479502579,\n",
       " 457017515479502580,\n",
       " 457017515479502581,\n",
       " 457017515479502582,\n",
       " 457017515479502583,\n",
       " 457017515479502584,\n",
       " 457017515479502585,\n",
       " 457017515479502586,\n",
       " 457017515479502587,\n",
       " 457017515479502588,\n",
       " 457017515479502589,\n",
       " 457017515479502590,\n",
       " 457017515479502591,\n",
       " 457017515479502592,\n",
       " 457017515479502593,\n",
       " 457017515479502594,\n",
       " 457017515479502595,\n",
       " 457017515479502596,\n",
       " 457017515479502597,\n",
       " 457017515479502598,\n",
       " 457017515479502599,\n",
       " 457017515479502600,\n",
       " 457017515479502601,\n",
       " 457017515479502602,\n",
       " 457017515479502603,\n",
       " 457017515479502604,\n",
       " 457017515479502605,\n",
       " 457017515479502606,\n",
       " 457017515479502607,\n",
       " 457017515479502608,\n",
       " 457017515479502609,\n",
       " 457017515479502610,\n",
       " 457017515479502611,\n",
       " 457017515479502612,\n",
       " 457017515479502613,\n",
       " 457017515479502614,\n",
       " 457017515479502615,\n",
       " 457017515479502616,\n",
       " 457017515479502617,\n",
       " 457017515479502618,\n",
       " 457017515479502619,\n",
       " 457017515479502620,\n",
       " 457017515479502621,\n",
       " 457017515479502622,\n",
       " 457017515479502623,\n",
       " 457017515479502624,\n",
       " 457017515479502625,\n",
       " 457017515479502626,\n",
       " 457017515479502627,\n",
       " 457017515479502628,\n",
       " 457017515479502629,\n",
       " 457017515479502630,\n",
       " 457017515479502631,\n",
       " 457017515479502632,\n",
       " 457017515479502633,\n",
       " 457017515479502634,\n",
       " 457017515479502635,\n",
       " 457017515479502636,\n",
       " 457017515479502637,\n",
       " 457017515479502638,\n",
       " 457017515479502639,\n",
       " 457017515479502640,\n",
       " 457017515479502641,\n",
       " 457017515479502642,\n",
       " 457017515479502643,\n",
       " 457017515479502644,\n",
       " 457017515479502645,\n",
       " 457017515479502646,\n",
       " 457017515479502647,\n",
       " 457017515479502648,\n",
       " 457017515479502649,\n",
       " 457017515479502650,\n",
       " 457017515479502651,\n",
       " 457017515479502652,\n",
       " 457017515479502653,\n",
       " 457017515479502654,\n",
       " 457017515479502655,\n",
       " 457017515479502656,\n",
       " 457017515479502657,\n",
       " 457017515479502658,\n",
       " 457017515479502659,\n",
       " 457017515479502660,\n",
       " 457017515479502661,\n",
       " 457017515479502662,\n",
       " 457017515479502663,\n",
       " 457017515479502664,\n",
       " 457017515479502665,\n",
       " 457017515479502666,\n",
       " 457017515479502667,\n",
       " 457017515479502668,\n",
       " 457017515479502669,\n",
       " 457017515479502670,\n",
       " 457017515479502671,\n",
       " 457017515479502672,\n",
       " 457017515479502673,\n",
       " 457017515479502674,\n",
       " 457017515479502675,\n",
       " 457017515479502676,\n",
       " 457017515479502677,\n",
       " 457017515479502678,\n",
       " 457017515479502679,\n",
       " 457017515479502680,\n",
       " 457017515479502681,\n",
       " 457017515479502682,\n",
       " 457017515479502683,\n",
       " 457017515479502684,\n",
       " 457017515479502685,\n",
       " 457017515479502686,\n",
       " 457017515479502687,\n",
       " 457017515479502688,\n",
       " 457017515479502689,\n",
       " 457017515479502690,\n",
       " 457017515479502691,\n",
       " 457017515479502692,\n",
       " 457017515479502693,\n",
       " 457017515479502694,\n",
       " 457017515479502695,\n",
       " 457017515479502696,\n",
       " 457017515479502697,\n",
       " 457017515479502698,\n",
       " 457017515479502699,\n",
       " 457017515479502700,\n",
       " 457017515479502701,\n",
       " 457017515479502702,\n",
       " 457017515479502703,\n",
       " 457017515479502704,\n",
       " 457017515479502705,\n",
       " 457017515479502706,\n",
       " 457017515479502707,\n",
       " 457017515479502708,\n",
       " 457017515479502709,\n",
       " 457017515479502710,\n",
       " 457017515479502711,\n",
       " 457017515479502712,\n",
       " 457017515479502713,\n",
       " 457017515479502714,\n",
       " 457017515479502715,\n",
       " 457017515479502716,\n",
       " 457017515479502717,\n",
       " 457017515479502718,\n",
       " 457017515479502719,\n",
       " 457017515479502720,\n",
       " 457017515479502721,\n",
       " 457017515479502722,\n",
       " 457017515479502723,\n",
       " 457017515479502724,\n",
       " 457017515479502725,\n",
       " 457017515479502726,\n",
       " 457017515479502727,\n",
       " 457017515479502728,\n",
       " 457017515479502729,\n",
       " 457017515479502730,\n",
       " 457017515479502731,\n",
       " 457017515479502732,\n",
       " 457017515479502733,\n",
       " 457017515479502734,\n",
       " 457017515479502735,\n",
       " 457017515479502736,\n",
       " 457017515479502737,\n",
       " 457017515479502738,\n",
       " 457017515479502739,\n",
       " 457017515479502740,\n",
       " 457017515479502741,\n",
       " 457017515479502742,\n",
       " 457017515479502743,\n",
       " 457017515479502744,\n",
       " 457017515479502745,\n",
       " 457017515479502746,\n",
       " 457017515479502747,\n",
       " 457017515479502748,\n",
       " 457017515479502749,\n",
       " 457017515479502750,\n",
       " 457017515479502751,\n",
       " 457017515479502752,\n",
       " 457017515479502753,\n",
       " 457017515479502754,\n",
       " 457017515479502755,\n",
       " 457017515479502756,\n",
       " 457017515479502757,\n",
       " 457017515479502758,\n",
       " 457017515479502759,\n",
       " 457017515479502760,\n",
       " 457017515479502761,\n",
       " 457017515479502762,\n",
       " 457017515479502763,\n",
       " 457017515479502764,\n",
       " 457017515479502765,\n",
       " 457017515479502766,\n",
       " 457017515479502767,\n",
       " 457017515479502768,\n",
       " 457017515479502769,\n",
       " 457017515479502770,\n",
       " 457017515479502771,\n",
       " 457017515479502772,\n",
       " 457017515479502773,\n",
       " 457017515479502774,\n",
       " 457017515479502775,\n",
       " 457017515479502776,\n",
       " 457017515479502777,\n",
       " 457017515479502778,\n",
       " 457017515479502779,\n",
       " 457017515479502780,\n",
       " 457017515479502781,\n",
       " 457017515479502782,\n",
       " 457017515479502783,\n",
       " 457017515479502784,\n",
       " 457017515479502785,\n",
       " 457017515479502786,\n",
       " 457017515479502787,\n",
       " 457017515479502788,\n",
       " 457017515479502789,\n",
       " 457017515479502790,\n",
       " 457017515479502791,\n",
       " 457017515479502792,\n",
       " 457017515479502793,\n",
       " 457017515479502794,\n",
       " 457017515479502795,\n",
       " 457017515479502796,\n",
       " 457017515479502797,\n",
       " 457017515479502798,\n",
       " 457017515479502799,\n",
       " 457017515479502800,\n",
       " 457017515479502801,\n",
       " 457017515479502802,\n",
       " 457017515479502803,\n",
       " 457017515479502804,\n",
       " 457017515479502805,\n",
       " 457017515479502806,\n",
       " 457017515479502807,\n",
       " 457017515479502808,\n",
       " 457017515479502809,\n",
       " 457017515479502810,\n",
       " 457017515479502811,\n",
       " 457017515479502812,\n",
       " 457017515479502813,\n",
       " 457017515479502814,\n",
       " 457017515479502815,\n",
       " 457017515479502816,\n",
       " 457017515479502817,\n",
       " 457017515479502818,\n",
       " 457017515479502819,\n",
       " 457017515479502820,\n",
       " 457017515479502821,\n",
       " 457017515479502822,\n",
       " 457017515479502823,\n",
       " 457017515479502824,\n",
       " 457017515479502825,\n",
       " 457017515479502826,\n",
       " 457017515479502827,\n",
       " 457017515479502828,\n",
       " 457017515479502829,\n",
       " 457017515479502830,\n",
       " 457017515479502831,\n",
       " 457017515479502832,\n",
       " 457017515479502833,\n",
       " 457017515479502834,\n",
       " 457017515479502835,\n",
       " 457017515479502836,\n",
       " 457017515479502837,\n",
       " 457017515479502838,\n",
       " 457017515479502839,\n",
       " 457017515479502840,\n",
       " 457017515479502841,\n",
       " 457017515479502842,\n",
       " 457017515479502843,\n",
       " 457017515479502844,\n",
       " 457017515479502845,\n",
       " 457017515479502846,\n",
       " 457017515479502847,\n",
       " 457017515479502848,\n",
       " 457017515479502849,\n",
       " 457017515479502850,\n",
       " 457017515479502851,\n",
       " 457017515479502852,\n",
       " 457017515479502853,\n",
       " 457017515479502854,\n",
       " 457017515479502855,\n",
       " 457017515479502856,\n",
       " 457017515479502857,\n",
       " 457017515479502858,\n",
       " 457017515479502859,\n",
       " 457017515479502860,\n",
       " 457017515479502861,\n",
       " 457017515479502862,\n",
       " 457017515479502863,\n",
       " 457017515479502864,\n",
       " 457017515479502865,\n",
       " 457017515479502866,\n",
       " 457017515479502867,\n",
       " 457017515479502868,\n",
       " 457017515479502869,\n",
       " 457017515479502870,\n",
       " 457017515479502871,\n",
       " 457017515479502872,\n",
       " 457017515479502873,\n",
       " 457017515479502874,\n",
       " 457017515479502875,\n",
       " 457017515479502876,\n",
       " 457017515479502877,\n",
       " 457017515479502878,\n",
       " 457017515479502879,\n",
       " 457017515479502880,\n",
       " 457017515479502881,\n",
       " 457017515479502882,\n",
       " 457017515479502883,\n",
       " 457017515479502884,\n",
       " 457017515479502885,\n",
       " 457017515479502886,\n",
       " 457017515479502887,\n",
       " 457017515479502888,\n",
       " 457017515479502889,\n",
       " 457017515479502890,\n",
       " 457017515479502891,\n",
       " 457017515479502892,\n",
       " 457017515479502893,\n",
       " 457017515479502894,\n",
       " 457017515479502895,\n",
       " 457017515479502896,\n",
       " 457017515479502897,\n",
       " 457017515479502898,\n",
       " 457017515479502899,\n",
       " 457017515479502900,\n",
       " 457017515479502901,\n",
       " 457017515479502902,\n",
       " 457017515479502903,\n",
       " 457017515479502904,\n",
       " 457017515479502905,\n",
       " 457017515479502906,\n",
       " 457017515479502907,\n",
       " 457017515479502908,\n",
       " 457017515479502909,\n",
       " 457017515479502910,\n",
       " 457017515479502911,\n",
       " 457017515479502912,\n",
       " 457017515479502913,\n",
       " 457017515479502914,\n",
       " 457017515479502915,\n",
       " 457017515479502916,\n",
       " 457017515479502917,\n",
       " 457017515479502918,\n",
       " 457017515479502919,\n",
       " 457017515479502920,\n",
       " 457017515479502921,\n",
       " 457017515479502922,\n",
       " 457017515479502923,\n",
       " 457017515479502924,\n",
       " 457017515479502925,\n",
       " 457017515479502926,\n",
       " 457017515479502927,\n",
       " 457017515479502928,\n",
       " 457017515479502929,\n",
       " 457017515479502930,\n",
       " 457017515479502931,\n",
       " 457017515479502932,\n",
       " 457017515479502933,\n",
       " 457017515479502934,\n",
       " 457017515479502935,\n",
       " 457017515479502936,\n",
       " 457017515479502937,\n",
       " 457017515479502938,\n",
       " 457017515479502939,\n",
       " 457017515479502940,\n",
       " 457017515479502941,\n",
       " 457017515479502942,\n",
       " 457017515479502943,\n",
       " 457017515479502944,\n",
       " 457017515479502945,\n",
       " 457017515479502946,\n",
       " 457017515479502947,\n",
       " 457017515479502948,\n",
       " 457017515479502949,\n",
       " 457017515479502950,\n",
       " 457017515479502951,\n",
       " 457017515479502952,\n",
       " 457017515479502953,\n",
       " 457017515479502954,\n",
       " 457017515479502955,\n",
       " 457017515479502956,\n",
       " 457017515479502957,\n",
       " 457017515479502958,\n",
       " 457017515479502959,\n",
       " 457017515479502960,\n",
       " 457017515479502961,\n",
       " 457017515479502962,\n",
       " 457017515479502963,\n",
       " 457017515479502964,\n",
       " 457017515479502965,\n",
       " 457017515479502966,\n",
       " 457017515479502967,\n",
       " 457017515479502968,\n",
       " 457017515479502969,\n",
       " 457017515479502970,\n",
       " 457017515479502971,\n",
       " 457017515479502972,\n",
       " 457017515479502973,\n",
       " 457017515479502974,\n",
       " 457017515479502975,\n",
       " 457017515479502976,\n",
       " 457017515479502977,\n",
       " 457017515479502978,\n",
       " 457017515479502979,\n",
       " 457017515479502980,\n",
       " 457017515479502981,\n",
       " 457017515479502982,\n",
       " 457017515479502983,\n",
       " 457017515479502984,\n",
       " 457017515479502985,\n",
       " 457017515479502986,\n",
       " 457017515479502987,\n",
       " 457017515479502988,\n",
       " 457017515479502989,\n",
       " 457017515479502990,\n",
       " 457017515479502991,\n",
       " 457017515479502992,\n",
       " 457017515479502993,\n",
       " 457017515479502994,\n",
       " 457017515479502995,\n",
       " 457017515479502996,\n",
       " 457017515479502997,\n",
       " 457017515479502998,\n",
       " 457017515479502999,\n",
       " 457017515479503000,\n",
       " 457017515479503001,\n",
       " 457017515479503002,\n",
       " 457017515479503003,\n",
       " 457017515479503004,\n",
       " 457017515479503005,\n",
       " 457017515479503006,\n",
       " 457017515479503007,\n",
       " 457017515479503008,\n",
       " 457017515479503009,\n",
       " 457017515479503010,\n",
       " 457017515479503011,\n",
       " 457017515479503012,\n",
       " 457017515479503013,\n",
       " 457017515479503014,\n",
       " 457017515479503015,\n",
       " 457017515479503016,\n",
       " 457017515479503017,\n",
       " 457017515479503018,\n",
       " 457017515479503019,\n",
       " 457017515479503020,\n",
       " 457017515479503021,\n",
       " 457017515479503022,\n",
       " 457017515479503023,\n",
       " 457017515479503024,\n",
       " 457017515479503025,\n",
       " 457017515479503026,\n",
       " 457017515479503027,\n",
       " 457017515479503028,\n",
       " 457017515479503029,\n",
       " 457017515479503030,\n",
       " 457017515479503031,\n",
       " 457017515479503032,\n",
       " 457017515479503033,\n",
       " 457017515479503034,\n",
       " 457017515479503035,\n",
       " 457017515479503036,\n",
       " 457017515479503037,\n",
       " 457017515479503038,\n",
       " 457017515479503039,\n",
       " 457017515479503040,\n",
       " 457017515479503041,\n",
       " 457017515479503042,\n",
       " 457017515479503043,\n",
       " 457017515479503044,\n",
       " 457017515479503045,\n",
       " 457017515479503046,\n",
       " 457017515479503047,\n",
       " 457017515479503048,\n",
       " 457017515479503049,\n",
       " 457017515479503050,\n",
       " 457017515479503051,\n",
       " 457017515479503052,\n",
       " 457017515479503053,\n",
       " 457017515479503054,\n",
       " 457017515479503055,\n",
       " 457017515479503056,\n",
       " 457017515479503057,\n",
       " 457017515479503058,\n",
       " 457017515479503059,\n",
       " 457017515479503060,\n",
       " 457017515479503061,\n",
       " 457017515479503062,\n",
       " 457017515479503063,\n",
       " 457017515479503064,\n",
       " 457017515479503065,\n",
       " 457017515479503066,\n",
       " 457017515479503067,\n",
       " 457017515479503068,\n",
       " 457017515479503069,\n",
       " 457017515479503070,\n",
       " 457017515479503071,\n",
       " 457017515479503072,\n",
       " 457017515479503073,\n",
       " 457017515479503074,\n",
       " 457017515479503075,\n",
       " 457017515479503076,\n",
       " 457017515479503077,\n",
       " 457017515479503078,\n",
       " 457017515479503079,\n",
       " 457017515479503080,\n",
       " 457017515479503081,\n",
       " 457017515479503082,\n",
       " 457017515479503083,\n",
       " 457017515479503084,\n",
       " 457017515479503085,\n",
       " 457017515479503086,\n",
       " 457017515479503087,\n",
       " 457017515479503088,\n",
       " 457017515479503089,\n",
       " 457017515479503090,\n",
       " 457017515479503091,\n",
       " 457017515479503092,\n",
       " 457017515479503093,\n",
       " 457017515479503094,\n",
       " 457017515479503095,\n",
       " 457017515479503096,\n",
       " 457017515479503097,\n",
       " 457017515479503098,\n",
       " 457017515479503099,\n",
       " 457017515479503100,\n",
       " 457017515479503101,\n",
       " 457017515479503102,\n",
       " 457017515479503103,\n",
       " 457017515479503104,\n",
       " 457017515479503105,\n",
       " 457017515479503106,\n",
       " 457017515479503107,\n",
       " 457017515479503108,\n",
       " ...]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection_name = \"book_rag_db\"\n",
    "if utility.has_collection(collection_name):\n",
    "    utility.drop_collection(collection_name)\n",
    "\n",
    "vectorstore = Milvus(\n",
    "    embedding_function=ncp_embeddings,\n",
    "    collection_name=collection_name,\n",
    "    connection_args={\"host\": \"localhost\", \"port\": \"19530\"},\n",
    "    auto_id=True,\n",
    ")\n",
    "\n",
    "texts = [pair[0] for pair in all_text_embedding_pairs]\n",
    "embeds = [pair[1] for pair in all_text_embedding_pairs]\n",
    "\n",
    "\n",
    "def precomputed_embed_documents(cls, input_texts):\n",
    "    if input_texts != texts:\n",
    "        raise ValueError(\n",
    "            \"ERROR : 입력 텍스트 순서가 사전 계산된 임베딩과 일치하지 않음\"\n",
    "        )\n",
    "    return embeds\n",
    "\n",
    "\n",
    "ClovaXEmbeddings.embed_documents = classmethod(precomputed_embed_documents)\n",
    "vectorstore.add_texts(\n",
    "    texts=texts, metadatas=all_metadata_list_mapped, embeddings=embeds\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기존 dense_retriever 생성 → custom retriever로 감싸기\n",
    "\n",
    "dense_retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "merged_retriever = ISBNMergingRetriever(base_retriever=dense_retriever)\n",
    "\n",
    "dpr_qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm_clova, retriever=merged_retriever, return_source_documents=True\n",
    ")\n",
    "\n",
    "\n",
    "def extract_field(text, field_name):\n",
    "    pattern = rf\"{re.escape(field_name)}\\s*:\\s*(.*)\"\n",
    "    match = re.search(pattern, text)\n",
    "    return match.group(1).strip() if match else \"\"\n",
    "\n",
    "\n",
    "MIN_INFO_LENGTH = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_prompt_template = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "[대화 맥락]\n",
    "사용자 대화 내역:\n",
    "{{ history }}\n",
    "사용자의 최신 질문: \"{{ query }}\"\n",
    "\n",
    "[역할 및 목표]\n",
    "{{ role_instructions }}\n",
    "현재 대화 상황과 질문의 맥락을 분석하여 아래 중 하나의 행동만을 출력해라.\n",
    "- \"추천\": 사용자가 책 추천을 명확히 요청하거나, 선호도 정보(예: 선호하는 카테고리, 선호하는 작가, 책을 찾는 목적, 사전지식 등)가 **구체적**이고 충분하다고 판단되는 경우에만.\n",
    "- \"추가 질문\": 위 조건을 충족하지 못해, 추가로 선호도 정보를 더 알아내야 할 경우, 새로운 선호도 정보를 얻을 수 있는 구체적인 추가 질문을 생성할 것.\n",
    "출력 형식 (반드시 아래 내용만 출력):\n",
    "행동: \"<추천 또는 추가 질문>\"\n",
    "추가 질문: \"<추가 질문인 경우 구체적인 추가 질문을, 추천인 경우 빈 문자열>\"\n",
    "\"\"\",\n",
    "    input_variables=[\"history\", \"query\", \"role_instructions\"],\n",
    "    template_format=\"jinja2\",\n",
    ")\n",
    "\n",
    "final_query_generation_template = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "[대화 요약]\n",
    "{{ history }}\n",
    "\n",
    "[사용자 요청]\n",
    "{{ query }}\n",
    "\n",
    "[페르소나 정보]\n",
    "{{ persona_info }}\n",
    "\n",
    "[사용자 선호도]\n",
    "{{ preferences }}\n",
    "\n",
    "위 정보를 바탕으로, 사용자가 제공한 선호도 정보(카테고리, 작가, 목적 등)를 모두 반영하여, 책 추천에 유용한 최종 검색 쿼리만을 생성해라.\n",
    "출력 형식:\n",
    "쿼리: <최종 검색 쿼리>\n",
    "- 반드시 위 형식만을 사용하고, 추가 설명이나 안내 문구는 포함하지 말라.\n",
    "- \"최종 검색 쿼리\"는 질문 형태가 아니어야 하며, '추가 질문'이라는 표현은 사용하지 말라.\n",
    "\"\"\",\n",
    "    input_variables=[\"history\", \"query\", \"persona_info\", \"preferences\"],\n",
    "    template_format=\"jinja2\",\n",
    ")\n",
    "\n",
    "# 페르소나별 Pipeline 클래스\n",
    "\n",
    "literature_role = \"너는 감성적이고 문학적인 도서 추천 챗봇이다. 사용자의 감정과 취향을 섬세하게 파악하여, 감성적인 어투를 활용해 책을 추천해라.\"\n",
    "science_role = \"너는 정확하고 논리적인 과학/기술 도서 추천 챗봇이다. 사용자의 관심 분야와 요구를 분석하여, 명확하고 구체적인 정보를 활용하여 책을 추천해라.\"\n",
    "general_role = \"너는 친절하고 신뢰할 수 있는 범용 도서 추천 챗봇이다. 사용자의 관심사와 목적을 파악하여, 다양한 분야의 책을 적절하게 추천해라. 문학, 과학 외에도 자기계발, 역사, 에세이, 경제경영 등 모든 장르에 유연하게 대응해라.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import contextlib\n",
    "from langchain_core.runnables import RunnableSequence\n",
    "\n",
    "\n",
    "class SummarizeFinalQueryChain:\n",
    "    async def __call__(self, input_data: dict) -> dict:\n",
    "        query = input_data.get(\"final_query\") or input_data.get(\"text\", \"\")\n",
    "        prompt = f\"다음 내용을 하나의 자연스러운 문장으로 정제해줘:\\n{query}\\n정제된 검색 쿼리:\"\n",
    "        result_text = await async_invoke_llm(prompt, \"최종 쿼리 정제\")\n",
    "        return {\"text\": result_text.strip()}\n",
    "\n",
    "\n",
    "async def async_invoke(chain: LLMChain, vars_dict: dict, step_name: str) -> dict:\n",
    "    try:\n",
    "        print(f\"\\n[디버그] {step_name} 호출 전 변수: {vars_dict}\")\n",
    "        result = await asyncio.to_thread(chain.invoke, vars_dict)\n",
    "        print(f\"\\n[디버그] {step_name} 결과: {result}\")\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"[에러] {step_name}에서 예외 발생: {str(e)}\")\n",
    "        return {\"text\": \"\"}\n",
    "\n",
    "\n",
    "async def async_invoke_llm(prompt: str, step_name: str) -> str:\n",
    "    try:\n",
    "        print(f\"\\n[디버그] {step_name} 프롬프트 호출:\\n{prompt}\")\n",
    "        response = await asyncio.to_thread(llm_clova.invoke, prompt)\n",
    "        result_text = response.text().strip()\n",
    "        print(f\"\\n[디버그] {step_name} 응답: {result_text}\")\n",
    "        return result_text\n",
    "    except Exception as e:\n",
    "        print(f\"[에러] {step_name}에서 예외 발생: {str(e)}\")\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseRAGPipeline:\n",
    "    def __init__(self, config, llm, retriever, qa_chain, documents):\n",
    "        self.config = config\n",
    "        self.llm = llm\n",
    "        self.retriever = retriever\n",
    "        self.qa_chain = qa_chain\n",
    "        self.documents = documents\n",
    "\n",
    "        # 사용자와 LLM 히스토리 분리\n",
    "        self.user_history = []\n",
    "        self.llm_history = []\n",
    "\n",
    "        self.user_preferences = defaultdict(list)\n",
    "        self.preferences_text = \"\"\n",
    "        self.preference_update_count = 0\n",
    "\n",
    "        # 마지막 추천 결과 저장 (병합된 Document 리스트)\n",
    "        self.last_recommendations = []\n",
    "        # 마지막 행동 추적 (예: \"추천\", \"추가 질문\" 등)\n",
    "        self.last_action = None\n",
    "\n",
    "        self.decision_chain = LLMChain(llm=self.llm, prompt=decision_prompt_template)\n",
    "        self.final_query_generation_chain = LLMChain(\n",
    "            llm=self.llm, prompt=final_query_generation_template\n",
    "        )\n",
    "\n",
    "    def robust_parse_decision_response(self, response_text):\n",
    "        action_match = re.search(r'행동\\s*[:：]\\s*\"?([^\"\\n]+)\"?', response_text)\n",
    "        action = action_match.group(1).strip() if action_match else None\n",
    "\n",
    "        book_info_match = re.search(\n",
    "            r'추천\\s*책\\s*정보\\s*[:：]\\s*\"?([^\"\\n]+)\"?', response_text\n",
    "        )\n",
    "        book_info = book_info_match.group(1).strip() if book_info_match else \"\"\n",
    "\n",
    "        follow_match = re.search(r'추가\\s*질문\\s*[:：]\\s*\"?([^\"\\n]+)\"?', response_text)\n",
    "        additional_question = follow_match.group(1).strip() if follow_match else \"\"\n",
    "        return action, book_info, additional_question\n",
    "\n",
    "    async def get_final_query(self, final_query_vars):\n",
    "        composite_final_chain = RunnableSequence(\n",
    "            *[self.final_query_generation_chain, SummarizeFinalQueryChain()]\n",
    "        )\n",
    "        composite_result = await composite_final_chain.ainvoke(final_query_vars)\n",
    "        final_query = composite_result.get(\"text\", \"\").strip()\n",
    "        return final_query\n",
    "\n",
    "    async def summarize_user_preferences(self, existing_preferences, new_input):\n",
    "        prompt = (\n",
    "            f\"다음 사용자 선호도 내용들을 하나의 자연스러운 문장으로 요약해줘:\\n\"\n",
    "            f\"기존 선호도: {existing_preferences}\\n\"\n",
    "            f\"새로운 입력: {new_input}\\n\"\n",
    "            f\"요약된 선호도:\"\n",
    "        )\n",
    "        return await async_invoke_llm(prompt, \"사용자 선호도 요약\")\n",
    "\n",
    "    async def generate_answer(self, query):\n",
    "        # 일반 QA 시나리오: RetrievalQA 체인을 사용\n",
    "        author_match = re.search(r\"(?:저자|작가)\\s*[:：]\\s*(\\S+)\", query)\n",
    "        if author_match:\n",
    "            author_name = author_match.group(1).strip().lower()\n",
    "            dense_results = self.qa_chain.invoke(query)[\"source_documents\"]\n",
    "            keyword_results = [\n",
    "                doc\n",
    "                for doc in self.documents\n",
    "                if doc.metadata.get(\"author\", \"\").strip().lower() == author_name\n",
    "            ]\n",
    "            source_docs = list(\n",
    "                {\n",
    "                    doc.metadata.get(\"ISBN\"): doc\n",
    "                    for doc in (dense_results + keyword_results)\n",
    "                    if doc.metadata.get(\"ISBN\")\n",
    "                }.values()\n",
    "            )\n",
    "        else:\n",
    "            result = self.qa_chain.invoke(query)\n",
    "            source_docs = result[\"source_documents\"]\n",
    "\n",
    "        retrieved_isbns = set()\n",
    "        for doc in source_docs:\n",
    "            isbn = doc.metadata.get(\"ISBN\")\n",
    "            if isbn:\n",
    "                retrieved_isbns.add(isbn)\n",
    "\n",
    "        aggregated_docs = []\n",
    "        for isbn in retrieved_isbns:\n",
    "            book_docs = [\n",
    "                doc for doc in self.documents if doc.metadata.get(\"ISBN\") == isbn\n",
    "            ]\n",
    "            if not book_docs:\n",
    "                continue\n",
    "            aggregated_text = \"\\n\".join(doc.page_content for doc in book_docs)\n",
    "            aggregated_docs.append(\n",
    "                Document(page_content=aggregated_text, metadata=book_docs[0].metadata)\n",
    "            )\n",
    "\n",
    "        formatted_answers = []\n",
    "        for doc in aggregated_docs:\n",
    "            metadata = doc.metadata\n",
    "            title = metadata.get(\"title\") or extract_field(doc.page_content, \"제목\")\n",
    "            author = metadata.get(\"author\") or extract_field(doc.page_content, \"저자\")\n",
    "            aggregated_text = doc.page_content\n",
    "            book_intro = extract_field(aggregated_text, \"책소개\")\n",
    "            publisher_review = extract_field(aggregated_text, \"출판사리뷰\")\n",
    "            recommendation_field = extract_field(aggregated_text, \"추천사\")\n",
    "\n",
    "            if book_intro and len(book_intro.strip()) >= MIN_INFO_LENGTH:\n",
    "                selected_info = book_intro\n",
    "            elif publisher_review and len(publisher_review.strip()) >= MIN_INFO_LENGTH:\n",
    "                selected_info = publisher_review\n",
    "            elif (\n",
    "                recommendation_field\n",
    "                and len(recommendation_field.strip()) >= MIN_INFO_LENGTH\n",
    "            ):\n",
    "                selected_info = recommendation_field\n",
    "            else:\n",
    "                selected_info = \"\"\n",
    "\n",
    "            if not selected_info:\n",
    "                reason = \"추천 정보 생성 불가\"\n",
    "            else:\n",
    "                reason_prompt = (\n",
    "                    f\"다음 정보와 검색에 활용된 쿼리를 참고하여, \"\n",
    "                    f\"이 책이 추천되는 이유를 명확하게 요약해라.\\n\"\n",
    "                    f\"정보:\\n{selected_info}\"\n",
    "                )\n",
    "                generated_reason = await async_invoke_llm(\n",
    "                    reason_prompt, \"추천 이유 생성\"\n",
    "                )\n",
    "                if (\n",
    "                    not generated_reason\n",
    "                    or len(generated_reason) < 10\n",
    "                    or \"추천 정보 생성 불가\" in generated_reason\n",
    "                ):\n",
    "                    reason = \"추천 정보 생성 불가\"\n",
    "                else:\n",
    "                    reason = generated_reason\n",
    "\n",
    "            formatted = f\"책 제목: {title}\\n저자: {author}\\n추천 이유: {reason}\"\n",
    "            formatted_answers.append(formatted)\n",
    "\n",
    "        answer = \"\\n\\n\".join(formatted_answers)\n",
    "        refined_answer = await async_invoke_llm(\n",
    "            f\"아래 원본 추천 결과를 읽고, 각 책의 정보를 다음 형식에 맞춰 재작성해라.\\n\\n\"\n",
    "            f\"형식:\\n책 제목: <책 제목>\\n저자: <저자>\\n추천 이유: <추천 이유>\\n\\n\"\n",
    "            f\"원본 추천 결과:\\n{answer}\\n\\n\"\n",
    "            f\"출력 시, 반드시 위 형식만을 사용하고 불필요한 안내 문구는 포함하지 말아라.\",\n",
    "            \"추천 결과 재정제\",\n",
    "        )\n",
    "        return refined_answer, None\n",
    "\n",
    "    async def _summarize_chunk_with_llm(self, text: str) -> str:\n",
    "        prompt = f\"다음 책 정보를 200자 이내로 요약해줘:\\n{text}\\n\\n요약:\"\n",
    "        summary = await async_invoke_llm(prompt, \"chunk summary\")\n",
    "        if not summary or len(summary) < 10:\n",
    "            summary = \"별도의 상세 정보가 충분치 않습니다.\"\n",
    "        return summary\n",
    "\n",
    "    def _merge_documents_by_isbn(self, isbn: str) -> Document:\n",
    "        docs = [doc for doc in self.documents if doc.metadata.get(\"ISBN\") == isbn]\n",
    "        if not docs:\n",
    "            return None\n",
    "        combined_text = \"\\n\".join(doc.page_content for doc in docs)\n",
    "        merged_meta = docs[0].metadata\n",
    "        return Document(page_content=combined_text, metadata=merged_meta)\n",
    "\n",
    "    async def _some_simple_recommendation(self, final_query):\n",
    "        source_docs = self.retriever.get_relevant_documents(final_query)\n",
    "        top_docs = source_docs[:3]\n",
    "        merged_top_docs = []\n",
    "        for doc in top_docs:\n",
    "            isbn = doc.metadata.get(\"ISBN\", \"NO_ISBN\")\n",
    "            merged_doc = self._merge_documents_by_isbn(isbn)\n",
    "            if merged_doc:\n",
    "                merged_top_docs.append(merged_doc)\n",
    "                print(\n",
    "                    f\"[추천 디버그] ISBN: {isbn}, 병합된 전체 청크 길이: {len(merged_doc.page_content)}\"\n",
    "                )\n",
    "        recommendations = []\n",
    "        for doc in merged_top_docs:\n",
    "            metadata = doc.metadata\n",
    "            title = metadata.get(\"title\", \"제목 정보 없음\")\n",
    "            author = metadata.get(\"author\", \"저자 정보 없음\")\n",
    "            book_intro = extract_field(doc.page_content, \"책소개\")\n",
    "            publisher_review = extract_field(doc.page_content, \"출판사리뷰\")\n",
    "            recommendation_field = extract_field(doc.page_content, \"추천사\")\n",
    "            if book_intro and len(book_intro.strip()) >= MIN_INFO_LENGTH:\n",
    "                selected_info = book_intro\n",
    "            elif publisher_review and len(publisher_review.strip()) >= MIN_INFO_LENGTH:\n",
    "                selected_info = publisher_review\n",
    "            elif (\n",
    "                recommendation_field\n",
    "                and len(recommendation_field.strip()) >= MIN_INFO_LENGTH\n",
    "            ):\n",
    "                selected_info = recommendation_field\n",
    "            else:\n",
    "                selected_info = \"\"\n",
    "            if selected_info:\n",
    "                summary = await self._summarize_chunk_with_llm(selected_info)\n",
    "            else:\n",
    "                summary = \"별도의 상세 정보가 충분치 않습니다.\"\n",
    "            if len(summary) > 200:\n",
    "                summary = summary[:200] + \"...\"\n",
    "            recommendation_text = (\n",
    "                f\"책 제목: {title}\\n저자: {author}\\n추천 이유: {summary}\"\n",
    "            )\n",
    "            recommendations.append(recommendation_text)\n",
    "        self.last_recommendations = merged_top_docs\n",
    "        if not recommendations:\n",
    "            return \"해당 검색 쿼리에 대한 직접 추천 결과가 없습니다.\"\n",
    "        return \"\\n\\n\".join(recommendations)\n",
    "\n",
    "    # 후속 질문 처리 함수 (LLM을 통해 사용자의 의도를 분석)\n",
    "    async def handle_followup_query(self, followup_query: str) -> (bool, str):\n",
    "        rec_info = []\n",
    "        for doc in self.last_recommendations:\n",
    "            title = doc.metadata.get(\"title\", \"제목 정보 없음\")\n",
    "            isbn = doc.metadata.get(\"ISBN\", \"NO_ISBN\")\n",
    "            # 책 전문 중 1000자까지만 보게\n",
    "            snippet = doc.page_content[:1000].replace(\"\\n\", \" \")\n",
    "            rec_info.append(f\"제목: {title}, ISBN: {isbn}, 내용 일부: {snippet}\")\n",
    "        rec_info_str = \"\\n\".join(rec_info)\n",
    "\n",
    "        prompt = f\"\"\"\n",
    "        다음 후속 질문: \"{followup_query}\"\n",
    "        추천된 책 목록:\n",
    "        {rec_info_str}\n",
    "\n",
    "        위 책 목록을 참고하여, 사용자의 후속 질문 의도를 분석해라.\n",
    "        - 만약 사용자가 특정 책에 대해 더 자세한 정보를 원한다면, \"action\"을 \"상세\"로, \"ISBN\"에 해당 책의 ISBN을, \"query\"는 빈 문자열로 출력해라.\n",
    "        - 만약 사용자가 특정 책과 유사한 책을 추천받고자 한다면, \"action\"을 \"유사\"로, \"ISBN\"에 해당 책의 ISBN을, \"query\"에 해당 책 전문을 요약한 내용을 출력해라.\n",
    "        출력 형식은 반드시 JSON 형식으로, 예:\n",
    "        {\"{\"} \"action\": \"상세\", \"ISBN\": \"1234567890\", \"query\": \"\" {\"}\"}\n",
    "        또는\n",
    "        {\"{\"} \"action\": \"유사\", \"ISBN\": \"1234567890\", \"query\": \"요약문\" {\"}\"}\n",
    "        단, 불필요한 설명이나 추가 문구 없이 오직 JSON 형식만 출력해라.\n",
    "        \"\"\"\n",
    "        result_text = await async_invoke_llm(prompt, \"후속 질문 의도 분석\")\n",
    "        try:\n",
    "            result = json.loads(result_text)\n",
    "            action = result.get(\"action\", \"\")\n",
    "            isbn = result.get(\"ISBN\", \"\")\n",
    "            query_part = result.get(\"query\", \"\")\n",
    "        except Exception as e:\n",
    "            print(f\"[에러] 후속 질문 의도 분석 결과 파싱 실패: {e}\")\n",
    "            return (False, \"후속 질문 처리 중 오류가 발생했습니다.\")\n",
    "\n",
    "        if action == \"상세\":\n",
    "            target_doc = None\n",
    "            for doc in self.last_recommendations:\n",
    "                if doc.metadata.get(\"ISBN\", \"\") == isbn:\n",
    "                    target_doc = doc\n",
    "                    break\n",
    "            if target_doc:\n",
    "                detail_prompt = f\"다음 책 정보에 대해 더 자세한 설명을 해줘:\\n\\n{target_doc.page_content}\\n\\n자세한 설명:\"\n",
    "                detailed_info = await async_invoke_llm(detail_prompt, \"후속 상세 설명\")\n",
    "                return (True, detailed_info)\n",
    "            else:\n",
    "                return (True, \"해당 ISBN의 책 정보를 찾을 수 없습니다.\")\n",
    "        elif action == \"유사\":\n",
    "            if query_part:\n",
    "                # 기존 단순 제목 나열 대신, _some_simple_recommendation을 호출하여\n",
    "                # 제목, 저자, 추천이유 형식의 재추천 결과를 생성함.\n",
    "                recommendation_result = await self._some_simple_recommendation(\n",
    "                    query_part\n",
    "                )\n",
    "                return (True, recommendation_result)\n",
    "            else:\n",
    "                return (True, \"요약된 쿼리 정보가 부족합니다.\")\n",
    "        else:\n",
    "            return (False, \"후속 질문 의도 분석 결과 알 수 없는 행동입니다.\")\n",
    "\n",
    "    async def search_and_generate_answer(self, user_query, force_recommendation=False):\n",
    "        self.preferences_text = \" \".join(self.user_preferences[\"preferences\"])\n",
    "        query_summary = \"\\n\".join(self.user_history[-5:])\n",
    "\n",
    "        if self.config.get(\"persona\") == \"Literature\":\n",
    "            persona_info = \"감성, 현재 기분, 선호하는 문학 장르 및 작가 정보\"\n",
    "        elif self.config.get(\"persona\") == \"Science\":\n",
    "            persona_info = \"초심자 여부, 관심 분야, 구체적인 기술 정보\"\n",
    "        elif self.config.get(\"persona\") == \"General\":\n",
    "            persona_info = \"장르, 책을 찾는 이유, 독서 취향 정보\"\n",
    "        else:\n",
    "            persona_info = \"\"\n",
    "\n",
    "        if force_recommendation:\n",
    "            action = \"추천\"\n",
    "            print(\"[디버그] force_recommendation 적용: 추천 행동으로 전환합니다.\")\n",
    "            additional_question = \"\"\n",
    "        else:\n",
    "            prompt_vars = {\n",
    "                \"history\": query_summary,\n",
    "                \"query\": user_query,\n",
    "                \"role_instructions\": self.config[\"role_instructions\"],\n",
    "            }\n",
    "            decision_result = await async_invoke(\n",
    "                self.decision_chain, prompt_vars, \"행동 결정\"\n",
    "            )\n",
    "            decision_text = decision_result.get(\"text\", \"\").strip()\n",
    "            print(f\"\\n[디버그] Decision 응답: {decision_text}\")\n",
    "            action, _, additional_question = self.robust_parse_decision_response(\n",
    "                decision_text\n",
    "            )\n",
    "            print(f\"[디버그] 행동: {action}\")\n",
    "\n",
    "        if action == \"추가 질문\":\n",
    "            try:\n",
    "                add_q_emb = ncp_embeddings.embed_query(additional_question)\n",
    "            except Exception as e:\n",
    "                print(f\"[에러] 추가 질문 임베딩 생성 중 문제 발생: {str(e)}\")\n",
    "                add_q_emb = None\n",
    "\n",
    "            if add_q_emb is not None and is_similar_question(\n",
    "                add_q_emb, previous_additional_question_embeddings\n",
    "            ):\n",
    "                print(\"[정보] 동일 추가 질문이 재입력되어 추천 행동으로 전환합니다.\")\n",
    "                return await self.search_and_generate_answer(\n",
    "                    user_query, force_recommendation=True\n",
    "                )\n",
    "            else:\n",
    "                if add_q_emb is not None:\n",
    "                    previous_additional_question_embeddings.append(add_q_emb)\n",
    "\n",
    "            if additional_question:\n",
    "                self.llm_history.append(f\"챗봇: {additional_question}\")\n",
    "                print(\"-\" * 50)\n",
    "                print(f\"[챗봇] {additional_question}\")\n",
    "                print(\"-\" * 50)\n",
    "\n",
    "            raw_user_input = input(\"[사용자] \")\n",
    "            self.user_history.append(raw_user_input)\n",
    "\n",
    "            if self.preferences_text:\n",
    "                updated_pref = await self.summarize_user_preferences(\n",
    "                    self.preferences_text, raw_user_input\n",
    "                )\n",
    "            else:\n",
    "                updated_pref = raw_user_input\n",
    "\n",
    "            self.preferences_text = updated_pref\n",
    "            self.preference_update_count += 1\n",
    "            print(f\"\\n[디버그] 업데이트된 사용자 선호도: {self.preferences_text}\")\n",
    "            print(f\"[디버그] 선호도 업데이트 횟수: {self.preference_update_count}\")\n",
    "\n",
    "            if self.preference_update_count >= 3:\n",
    "                print(\"[디버그] 선호도 업데이트가 3회가 되어 추천 행동으로 전환합니다.\")\n",
    "                action = \"추천\"\n",
    "            else:\n",
    "                updated_prompt_vars = {\n",
    "                    \"history\": \"\\n\".join(self.user_history[-5:]),\n",
    "                    \"query\": user_query,\n",
    "                    \"role_instructions\": self.config[\"role_instructions\"],\n",
    "                }\n",
    "                decision_result = await async_invoke(\n",
    "                    self.decision_chain, updated_prompt_vars, \"재결정\"\n",
    "                )\n",
    "                decision_text = decision_result.get(\"text\", \"\").strip()\n",
    "                print(f\"\\n[디버그] 재결정 응답: {decision_text}\")\n",
    "                action, _, additional_question = self.robust_parse_decision_response(\n",
    "                    decision_text\n",
    "                )\n",
    "                print(f\"[디버그] 재결정 행동: {action}\")\n",
    "                if action == \"추가 질문\":\n",
    "                    if additional_question:\n",
    "                        self.llm_history.append(f\"챗봇: {additional_question}\")\n",
    "                        print(\"-\" * 50)\n",
    "                        print(f\"[챗봇] {additional_question}\")\n",
    "                        print(\"-\" * 50)\n",
    "                    return additional_question\n",
    "\n",
    "        final_query_vars = {\n",
    "            \"history\": \"\\n\".join(self.user_history[-5:]),\n",
    "            \"query\": user_query,\n",
    "            \"persona_info\": persona_info,\n",
    "            \"preferences\": self.preferences_text,\n",
    "        }\n",
    "        final_query = await self.get_final_query(final_query_vars)\n",
    "        print(f\"\\n[디버그] 최종 검색 쿼리: {final_query}\")\n",
    "\n",
    "        if action == \"추천\":\n",
    "            self.last_action = \"추천\"\n",
    "            answer = await self._some_simple_recommendation(final_query)\n",
    "            return answer\n",
    "        else:\n",
    "            self.last_action = action\n",
    "            answer, _ = await self.generate_answer(final_query)\n",
    "            return answer\n",
    "\n",
    "    async def interactive_multi_turn_qa(self):\n",
    "        if self.config[\"persona\"] == \"Literature\":\n",
    "            greeting = \"안녕하세요~ 감성적이고 문학적인 도서 추천 챗봇입니다. 어떤 책을 추천해드릴까요?\"\n",
    "        elif self.config[\"persona\"] == \"Science\":\n",
    "            greeting = \"안녕하십니까. 정확하고 논리적인 과학/기술 도서 추천 챗봇입니다. 관심 있는 기술 분야에 대해 편하게 이야기해 주세요.\"\n",
    "        else:\n",
    "            greeting = \"안녕하세요! 범용/일반 도서 추천 챗봇입니다. 관심 있는 분야에 대해 편하게 이야기해 주세요.\"\n",
    "\n",
    "        self.llm_history.append(f\"챗봇: {greeting}\")\n",
    "        print(\"-\" * 50)\n",
    "        print(f\"[챗봇] {greeting}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "        while True:\n",
    "            try:\n",
    "                user_query = input(\"[사용자] \")\n",
    "            except (KeyboardInterrupt, EOFError):\n",
    "                print(\"\\n[대화 종료]\")\n",
    "                break\n",
    "\n",
    "            if user_query.lower() == \"quit\":\n",
    "                print(\"\\n[대화 저장 중...]\")\n",
    "                print(\"대화 저장 완료\")\n",
    "                import sys\n",
    "\n",
    "                sys.exit()\n",
    "\n",
    "            # 만약 직전 행동이 \"추천\"이었다면 후속 질문으로 처리 시도\n",
    "            if self.last_action == \"추천\" and self.last_recommendations:\n",
    "                handled, followup_output = await self.handle_followup_query(user_query)\n",
    "                if handled:\n",
    "                    answer = followup_output\n",
    "                    self.last_action = None\n",
    "                    self.last_recommendations = []\n",
    "                else:\n",
    "                    self.user_history.append(user_query)\n",
    "                    answer = await self.search_and_generate_answer(user_query)\n",
    "            else:\n",
    "                self.user_history.append(user_query)\n",
    "                answer = await self.search_and_generate_answer(user_query)\n",
    "\n",
    "            if answer is not None:\n",
    "                self.llm_history.append(f\"챗봇: {answer}\")\n",
    "                print(\"-\" * 50)\n",
    "                print(f\"[챗봇] {answer}\")\n",
    "                print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LiteratureRAGPipeline(BaseRAGPipeline):\n",
    "    def __init__(self, llm, retriever, qa_chain, documents):\n",
    "        config = {\"persona\": \"Literature\", \"role_instructions\": literature_role}\n",
    "        super().__init__(config, llm, retriever, qa_chain, documents)\n",
    "\n",
    "\n",
    "class ScienceRAGPipeline(BaseRAGPipeline):\n",
    "    def __init__(self, llm, retriever, qa_chain, documents):\n",
    "        config = {\"persona\": \"Science\", \"role_instructions\": science_role}\n",
    "        super().__init__(config, llm, retriever, qa_chain, documents)\n",
    "\n",
    "\n",
    "class GeneralRAGPipeline(BaseRAGPipeline):\n",
    "    def __init__(self, llm, retriever, qa_chain, documents):\n",
    "        config = {\"persona\": \"General\", \"role_instructions\": general_role}\n",
    "        super().__init__(config, llm, retriever, qa_chain, documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "페르소나 선택:\n",
      "1. 예술/문학\n",
      "2. 과학/기술\n",
      "3. 범용/일반\n",
      "--------------------------------------------------\n",
      "[챗봇] 안녕하세요~ 감성적이고 문학적인 도서 추천 챗봇입니다. 어떤 책을 추천해드릴까요?\n",
      "--------------------------------------------------\n",
      "\n",
      "[디버그] 행동 결정 호출 전 변수: {'history': '소설책.', 'query': '소설책.', 'role_instructions': '너는 감성적이고 문학적인 도서 추천 챗봇이다. 사용자의 감정과 취향을 섬세하게 파악하여, 감성적인 어투를 활용해 책을 추천해라.'}\n",
      "\n",
      "[디버그] 행동 결정 결과: {'history': '소설책.', 'query': '소설책.', 'role_instructions': '너는 감성적이고 문학적인 도서 추천 챗봇이다. 사용자의 감정과 취향을 섬세하게 파악하여, 감성적인 어투를 활용해 책을 추천해라.', 'text': '행동: \"추가 질문\"\\n추가 질문: 어떤 장르의 소설책을 좋아하시나요?'}\n",
      "\n",
      "[디버그] Decision 응답: 행동: \"추가 질문\"\n",
      "추가 질문: 어떤 장르의 소설책을 좋아하시나요?\n",
      "[디버그] 행동: 추가 질문\n",
      "--------------------------------------------------\n",
      "[챗봇] 어떤 장르의 소설책을 좋아하시나요?\n",
      "--------------------------------------------------\n",
      "\n",
      "[디버그] 업데이트된 사용자 선호도: \n",
      "[디버그] 선호도 업데이트 횟수: 1\n",
      "\n",
      "[디버그] 재결정 호출 전 변수: {'history': '소설책.\\n', 'query': '소설책.', 'role_instructions': '너는 감성적이고 문학적인 도서 추천 챗봇이다. 사용자의 감정과 취향을 섬세하게 파악하여, 감성적인 어투를 활용해 책을 추천해라.'}\n",
      "\n",
      "[디버그] 재결정 결과: {'history': '소설책.\\n', 'query': '소설책.', 'role_instructions': '너는 감성적이고 문학적인 도서 추천 챗봇이다. 사용자의 감정과 취향을 섬세하게 파악하여, 감성적인 어투를 활용해 책을 추천해라.', 'text': '행동: \"추가 질문\"\\n추가 질문 : 어떤 장르의 소설책을 좋아하시나요?'}\n",
      "\n",
      "[디버그] 재결정 응답: 행동: \"추가 질문\"\n",
      "추가 질문 : 어떤 장르의 소설책을 좋아하시나요?\n",
      "[디버그] 재결정 행동: 추가 질문\n",
      "--------------------------------------------------\n",
      "[챗봇] 어떤 장르의 소설책을 좋아하시나요?\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "[챗봇] 어떤 장르의 소설책을 좋아하시나요?\n",
      "--------------------------------------------------\n",
      "\n",
      "[디버그] 행동 결정 호출 전 변수: {'history': '소설책.\\n\\n스릴러.', 'query': '스릴러.', 'role_instructions': '너는 감성적이고 문학적인 도서 추천 챗봇이다. 사용자의 감정과 취향을 섬세하게 파악하여, 감성적인 어투를 활용해 책을 추천해라.'}\n",
      "\n",
      "[디버그] 행동 결정 결과: {'history': '소설책.\\n\\n스릴러.', 'query': '스릴러.', 'role_instructions': '너는 감성적이고 문학적인 도서 추천 챗봇이다. 사용자의 감정과 취향을 섬세하게 파악하여, 감성적인 어투를 활용해 책을 추천해라.', 'text': '행동: \"추천\"\\n다양한 스릴러 소설이 있지만 그 중 몇 가지를 추천해 드릴게요. \\n- \\'그리고 아무도 없었다\\' 애거서 크리스티 저 : 전 세계에서 가장 많이 팔린 추리소설이에요. 인디언 섬에 초대받은 10명의 손님들이 한 명씩 살해되면서 벌어지는 이야기예요.\\n\\n- \\'모방범\\' 미야베 미유키 저 : 범죄와 가족 붕괴라는 주제를 다룬 작품으로, 사회파 미스터리의 대표작이예요. \\n\\n- \\'7년의 밤\\' 정유정 저 : 세령호에서 벌어진 살인사건을 배경으로 7년 전의 진실과 7년 후의 복수를 그린 작품이에요. 영화로도 제작되어 많은 사랑을 받았어요.\\n\\n위의 목록들은 대중적으로 인기 있는 스릴러 소설들이니 한번 읽어보시는 건 어떠신가요?'}\n",
      "\n",
      "[디버그] Decision 응답: 행동: \"추천\"\n",
      "다양한 스릴러 소설이 있지만 그 중 몇 가지를 추천해 드릴게요. \n",
      "- '그리고 아무도 없었다' 애거서 크리스티 저 : 전 세계에서 가장 많이 팔린 추리소설이에요. 인디언 섬에 초대받은 10명의 손님들이 한 명씩 살해되면서 벌어지는 이야기예요.\n",
      "\n",
      "- '모방범' 미야베 미유키 저 : 범죄와 가족 붕괴라는 주제를 다룬 작품으로, 사회파 미스터리의 대표작이예요. \n",
      "\n",
      "- '7년의 밤' 정유정 저 : 세령호에서 벌어진 살인사건을 배경으로 7년 전의 진실과 7년 후의 복수를 그린 작품이에요. 영화로도 제작되어 많은 사랑을 받았어요.\n",
      "\n",
      "위의 목록들은 대중적으로 인기 있는 스릴러 소설들이니 한번 읽어보시는 건 어떠신가요?\n",
      "[디버그] 행동: 추천\n",
      "\n",
      "[디버그] 최종 쿼리 정제 프롬프트 호출:\n",
      "다음 내용을 하나의 자연스러운 문장으로 정제해줘:\n",
      "쿼리 : 스릴러 소설책 추천\n",
      "정제된 검색 쿼리:\n",
      "\n",
      "[디버그] 최종 쿼리 정제 응답: 스릴러 장르의 소설책 추천해주세요.\n",
      "\n",
      "[디버그] 최종 검색 쿼리: 스릴러 장르의 소설책 추천해주세요.\n",
      "[디버그] ISBN: 9791156759454, 병합된 청크 수: 1, 병합 텍스트 길이: 902\n",
      "[디버그] ISBN: 9791167640222, 병합된 청크 수: 1, 병합 텍스트 길이: 369\n",
      "[디버그] ISBN: 9791158886660, 병합된 청크 수: 1, 병합 텍스트 길이: 2000\n",
      "[추천 디버그] ISBN: 9791156759454, 병합된 전체 청크 길이: 4904\n",
      "[추천 디버그] ISBN: 9791167640222, 병합된 전체 청크 길이: 2370\n",
      "[추천 디버그] ISBN: 9791158886660, 병합된 전체 청크 길이: 3043\n",
      "\n",
      "[디버그] chunk summary 프롬프트 호출:\n",
      "다음 책 정보를 200자 이내로 요약해줘:\n",
      "기이하고도 놀라운 피터 스완슨의 세계에 오신 것을 환영합니다! 보스턴의 한 추리소설 전문 서점을 운영하며 하루하루 성실히 살아가고 있는 맬컴 커쇼. 어느 날 FBI 요원이 그를 찾아와 ‘당신이 몇 년 전 서점 블로그에 올린 포스팅을 기억하는가’라고 질문한다. 지금까지 발표된 범죄소설 가운데 가장 똑똑하고 독창적이면서 실패할 확률이 없는 살인을 저지른 여덟 작품을 모아놓은 포스팅인데, 누군가 이를 따라 범죄를 저지르고 있다는 것이다. 만약 그 책들에 나오는 살인 방법을 성공적으로 모방했다면 범인은 결코 잡히지 않을 것이다. 처음에는 낯모르는 이들이 살해당했으나 곧 그의 타깃에 서점 단골손님도 포함되고, 어쩌면 커쇼의 아내의 죽음과도 연관이 있는 것 같다. 살인자의 손길은 치밀하고도 지능적으로 점점 커쇼를 향해 다가오는데…. 범인은 대체 누구이며 왜 이런 일을 저지르는 것일까? “메스처럼 예리한 문체로 냉정한 악의 본질을 탐구하는 작가 ([퍼블리셔스 위클리])”라는 극찬과 함께 단숨에 길리언 플린과 같은 스릴러 소설계 신예 거장 반열에 오른 피터 스완슨. 국내 독자 10만 명을 만족시킨 전작 『죽여 마땅한 사람들』 등 흡입력 있는 스릴러 작품을 주로 선보이던 그가 이번에는 탄탄한 구성과 짜임새 높은 촘촘한 전개로 전작과 또 다른 맛을 선보인다. 범인과 주인공의 쫓고 쫓기는 추리, 주인공의 유려한 심리 묘사, 곳곳에서 하나둘 새어나오는 놀라운 진실과 배신, 예상을 뒤엎는 기이한 반전들이 주는 서늘함은 스릴러 소설 독자들을 매료시키기에 충분하다.\n",
      "\n",
      "요약:\n",
      "\n",
      "[디버그] chunk summary 응답: 추리소설 전문 서점을 운영하는 맬컴 커쇼에게 FBI 요원이 찾아와 자신이 쓴 범죄소설 속 살인 방법을 모방한 연쇄살인 사건이 일어났다고 말한다. 범인은 점차 커쇼와 주변 인물들을 위협하기 시작하고, 커쇼는 범인을 추적하며 과거의 비밀과 마주하게 된다. 메스처럼 예리한 문체로 유명한 피터 스완슨의 신작으로, 치밀한 구성과 서늘한 반전이 돋보이는 스릴러 소설이다.\n",
      "\n",
      "[디버그] chunk summary 프롬프트 호출:\n",
      "다음 책 정보를 200자 이내로 요약해줘:\n",
      "방문객 금지, 아파트 밖에서 밤을 보내는 것도 금지, 이곳의 주민들을 귀찮게 하는 것도 금지 바솔로뮤 아파트 시터의 규칙이다. 이 규칙만 지킨다면 나는 한 달에 사천 달러를 받게 된다. 충격적인 보수다. 석 달을 비어 있는 방에서 살아 줄 사람을 구하고 있다고 했으니, 계산해 보면 석 달 이 집에서 사는 보수로 만 이천 달러를 가지게 되는 셈이다. 가족도, 가진 것도, 직장도 없어 오갈 데 없는 나에게 어떻게 이런 행운이 생긴 것일까? 대체 누가 석 달 동안 살면서 아무런 대가도 없이 거금을 나에게 주는 걸까? 애초에 이 꿈만 같은 이야기를 믿어도 될까? 친구가 내 준 소파의 자리를 제외한 모든 것을 잃은 줄스 라슨. 그녀의 앞에 바솔로뮤로 들어가는 문이 보인다. 그녀는 말 그대로 뉴욕 맨해튼에서 모르는 사람이 없다는 그 유명한 건물, 바솔로뮤의 시터로 취직한다. 시터가 하는 일이라고는 그저 바솔로뮤에서 석 달만 살기. 너무나 간단한 일이지만, 보수는 말도 안 되는 금액이다. 줄스는 곧바로 아파트 주민이자 시터의 일원이 된다. 그러나 쉬운 일에는 그만한 대가가 있는 법. 첫날에 우연히 친해지게 된 아래층 아파트 시터 인그리드가 이상한 말을 꺼낸다. 바솔로뮤는 무서운 곳이라고. 인그리드는 왜 이 건물이 무서운 것일까? 외벽의 가고일이 든든하게 지키는 이 건물을. 바솔로뮤에서의 첫날 밤, 줄스는 아랫집에서 나는 비명소리를 듣는다. 이건 인그리드의 집에서 나는 소리이다. 놀라 아래층으로 내려가 인그리드가 괜찮은지 확인하러 집 문을 똑똑 두들긴다. 아무런 소리도 들리지 않는다. 다시 문을 두드리려 하던 찰나, 인그리드가 문을 열고 나타난다. 어딘가 이상하다. 하지만 괜찮다는 인그리드의 말에 줄스는 집으로 돌아간다. 그러나 그 다음날, 인그리드는 사라졌다. 관리자에게 인그리드가 어디로 갔냐고 물어봐도 급히 나갔다는 말뿐이다. 어딘가 이상하다. 줄스처럼 인그리드도 오갈 데 없는 사람인데 대체 어딜 갔다는 것인가. 석연치 않다. 인그리드가 사라진 사건 이후, 줄스는 바솔로뮤가 단순히 맨해튼의 부자들이 사는 곳이 아닌 것처럼 느껴진다. 누구나 살고 싶어 하던 꿈만 같은 바솔로뮤는 이제 없다. 바솔로뮤의 비밀을 줄스와 함께 끝까지 따라가 보길 바란다.\n",
      "\n",
      "요약:\n",
      "\n",
      "[디버그] chunk summary 응답: 뉴욕 맨해튼의 고급 아파트 바솔로뮤의 시터로 취직한 줄스는 엄청난 보수를 받는 대신 엄격한 규칙을 지켜야 한다. 어느 날 아래층 시터 인그리드가 사라지고, 줄스는 바솔로뮤의 비밀을 파헤치기 시작한다.\n",
      "\n",
      "[디버그] chunk summary 프롬프트 호출:\n",
      "다음 책 정보를 200자 이내로 요약해줘:\n",
      "병든 어머니와 미국 동해안의 휴양지에서 외롭게 지내던 잭 소여는, 우연히 만나게 된 스피디 파커라는 노인에게 놀라운 이야기를 듣는다. 바로 현재의 세상과 다른 또 하나의 세상, ‘테러토리’라는 곳에 대해서다. 그곳은 마법이 공존하는 곳으로서, 현세 사람들의 트위너가 또 다른 모습으로 살아가고 있었다. 잭의 어머니 역시 그곳에 트위너가 있었는데, 바로 여왕이었다. 게다가 잭의 어머니처럼 죽어가고 있었다. 스피디는 잭에게 두 개의 세계를 넘나들며 여왕을 구하는 것만이 잭의 어머니를 살릴 수 있는 방법이라고 말하는데…….\n",
      "\n",
      "요약:\n",
      "\n",
      "[디버그] chunk summary 응답: 잭 소여는 병든 어머니와 함께 미국 동해안의 휴양지에서 지내다가 스피디 파커라는 노인에게 '테러토리'라는 또 다른 세상에 대한 이야기를 듣게 된다. 테러토리는 마법이 공존하는 곳으로, 잭의 어머니는 그곳의 여왕이며 죽어가고 있다. 잭은 두 세계를 오가며 여왕을 구해야 어머니를 살릴 수 있다는 말을 듣고 모험을 떠난다.\n",
      "--------------------------------------------------\n",
      "[챗봇] 책 제목: 여덟 건의 완벽한 살인\n",
      "저자: 피터 스완슨 저/노진선 역 지음\n",
      "추천 이유: 추리소설 전문 서점을 운영하는 맬컴 커쇼에게 FBI 요원이 찾아와 자신이 쓴 범죄소설 속 살인 방법을 모방한 연쇄살인 사건이 일어났다고 말한다. 범인은 점차 커쇼와 주변 인물들을 위협하기 시작하고, 커쇼는 범인을 추적하며 과거의 비밀과 마주하게 된다. 메스처럼 예리한 문체로 유명한 피터 스완슨의 신작으로, 치밀한 구성과 서늘한 반전이 돋보이는 스릴러 소설이...\n",
      "\n",
      "책 제목: 락 에브리 도어\n",
      "저자: 라일리 세이거 저/오세영 역 지음\n",
      "추천 이유: 뉴욕 맨해튼의 고급 아파트 바솔로뮤의 시터로 취직한 줄스는 엄청난 보수를 받는 대신 엄격한 규칙을 지켜야 한다. 어느 날 아래층 시터 인그리드가 사라지고, 줄스는 바솔로뮤의 비밀을 파헤치기 시작한다.\n",
      "\n",
      "책 제목: 부적1\n",
      "저자: 스티븐 킹, 피터 스트라우브 지음\n",
      "추천 이유: 잭 소여는 병든 어머니와 함께 미국 동해안의 휴양지에서 지내다가 스피디 파커라는 노인에게 '테러토리'라는 또 다른 세상에 대한 이야기를 듣게 된다. 테러토리는 마법이 공존하는 곳으로, 잭의 어머니는 그곳의 여왕이며 죽어가고 있다. 잭은 두 세계를 오가며 여왕을 구해야 어머니를 살릴 수 있다는 말을 듣고 모험을 떠난다.\n",
      "--------------------------------------------------\n",
      "\n",
      "[디버그] 후속 질문 의도 분석 프롬프트 호출:\n",
      "\n",
      "다음 후속 질문: \"\"\n",
      "추천된 책 목록:\n",
      "제목: 여덟 건의 완벽한 살인, ISBN: 9791156759454, 내용 일부: 제목 : 여덟 건의 완벽한 살인 분류 : ['국내도서 > 소설/시/희곡 > 영미소설', '국내도서 > 소설/시/희곡 > 액션/스릴러소설', '국내도서 > 소설/시/희곡 > 세계의 문학 > 미국문학', '외국도서 > 소설/시/희곡 > 소설 > 문학', '외국도서 > 소설/시/희곡 > 소설 > 서스펜스', '외국도서 > 소설/시/희곡 > 소설 > 스릴러 > 서스펜스'] 저자 : 피터 스완슨 저/노진선 역 지음 저자소개 : 저 : 피터 스완슨 (Peter Swanson) 2016년을 뒤흔든 『죽여 마땅한 사람들』로 “메스처럼 예리한 문체로 냉정한 악의 본질을 탐구하는 작가 [퍼블리셔스 위클리]”, “무시무시한 미치광이에게 푹 빠져들게 하는 법을 아는 작가[더 가디언]” 라는 찬사를 받았다. “대담하고 극적인 반전을 갖춘 채 가차 없이 펼쳐지는 이야기[보스턴 글로브]”라는 평가를 받은 『아낌없이 뺏는 사랑』으로 ‘결코 독자를 실망시키지 않는 작가’로 확고히 자리 잡았다. 한국에서 세 번째로 출간된 작품 『312호에서는 303호 여자가 보인다』는 건물의 독특한 구조가 이야기에 중요한 역할을 하는 ‘아파트먼트 스릴러’로, 색다른 공간이 자아내는 긴장감과 서스펜스가 압도적이다. 역 : 노진선 숙명여대 영어영문학과를 졸업했으며, 뉴욕대학교에서 소설 창작 과정을 공부했다. 잡지사 기자 생활을 거쳐 전문번역가로 활동 중이다. 언어의 경계를 허무는 유려한 번역으로 독자들의 신뢰를 받고 있다. 조디 피코의 『작지만 위대한 일들』, 존 그린의 『거북이는 언제나 거기에 있어』, 피터 스완슨의 『죽여 마땅한 사람들』, 요 네스뵈의 『스노우맨』, 『레오파드』, 『네메시스』, 『아들』, 엘리자베스 길버트의 『먹고 기도하고 사랑하라』, 『결혼해도 괜찮아』, 캐서린 아이작의 『유 미 에브리싱』 외 『토스카나 달콤한 내 인생』, 『아빠가 결혼했다』, 『나의 외로움이 널 부를 때』, 『만 가지 슬픔』, 『새장 안에서도 새들은 노래한다』, 『금요일 밤의 뜨개질 클럽』, 『자기 보살핌』, 『동거의 기\n",
      "제목: 락 에브리 도어, ISBN: 9791167640222, 내용 일부: 제목 : 락 에브리 도어 분류 : ['국내도서 > 소설/시/희곡 > 영미소설', '국내도서 > 소설/시/희곡 > 액션/스릴러소설', '국내도서 > 소설/시/희곡 > 세계의 문학 > 미국문학'] 저자 : 라일리 세이거 저/오세영 역 지음 저자소개 : 저 : 라일리 세이거 (Riley Sager) 『락 에브리 도어(Lock Every Door)』는 라일리 세이거의 세 번째 스릴러 작품이다. 라일리 세이거는 뉴저지 프린스톤에 살고 있는 작가의 필명이다. 라일리의 첫 소설 『파이널 걸스(Final Girls)』는 24개국이 넘는 국가에서 출판되어 전 세계적으로 인기를 끈 베스트셀러이며, ITW 스릴러 어워드에서 베스트 하드커버 노벨상을 수상, 유니버셜 픽쳐스에 의해 장편 영화로 제작 중이다. 두 번째 소설인 『더 라스트 타임 아이 라이드(The Last Time I Lied)』는 뉴욕타임즈 베스트셀러에 이름을 올렸다. 역 : 오세영 고려대학교 국어국문학과를 졸업하고, 사람과 사람 사이를 이어주는 글의 힘을 믿으며 꾸준히 글을 쓰고 있다. 책소개 : 방문객 금지, 아파트 밖에서 밤을 보내는 것도 금지, 이곳의 주민들을 귀찮게 하는 것도 금지 바솔로뮤 아파트 시터의 규칙이다. 이 규칙만 지킨다면 나는 한 달에 사천 달러를 받게 된다. 충격적인 보수다. 석 달을 비어 있는 방에서 살아 줄 사람을 구하고 있다고 했으니, 계산해 보면 석 달 이 집에서 사는 보수로 만 이천 달러를 가지게 되는 셈이다. 가족도, 가진 것도, 직장도 없어 오갈 데 없는 나에게 어떻게 이런 행운이 생긴 것일까? 대체 누가 석 달 동안 살면서 아무런 대가도 없이 거금을 나에게 주는 걸까? 애초에 이 꿈만 같은 이야기를 믿어도 될까? 친구가 내 준 소파의 자리를 제외한 모든 것을 잃은 줄스 라슨. 그녀의 앞에 바솔로뮤로 들어가는 문이 보인다. 그녀는 말 그대로 뉴욕 맨해튼에서 모르는 사람이 없다는 그 유명한 건물, 바솔로뮤의 시터로 취직한다. 시터가 하는 일이라고는 그저 바솔로뮤에서 석 달만 살기. 너\n",
      "제목: 부적1, ISBN: 9791158886660, 내용 일부: 제목 : 부적1 분류 : ['국내도서 > 소설/시/희곡 > 영미소설', '국내도서 > 소설/시/희곡 > 판타지/환상문학 > 외국판타지/환상소설', '국내도서 > 소설/시/희곡 > 테마문학 > 영화소설', '국내도서 > 소설/시/희곡 > 세계의 문학 > 미국문학'] 저자 : 스티븐 킹, 피터 스트라우브 지음 저자소개 : 스티븐 킹 저자 : 스티븐 킹 STEPHEN KING 스티븐 킹은 1947년 메인 주 포틀랜드에서 태어났다. 어린 시절 아버지를 여의고 홀어머니를 따라 여기저기 이사 다니며 힘든 생활을 하면서도 형이 발행하던 동네 신문에 기사를 쓰면서 글쓰기에 흥미를 갖기 시작했다. 킹의 이름을 세상에 알린 작품은 1974년에 발표한 첫 장편소설 『캐리』였다. 원래 쓰레기통에 처박혔던 원고를 아내인 태비사가 설득하여 고쳐 쓴 이 작품으로 킹은 작가로서 경력을 쌓기 시작했고, 이후 30여 년간 500여 편의 작품을 발표하여 오늘날 세계에서 가장 유명한 작가가 되었다. 킹의 작품들은 지금까지 33개 언어로 번역되어 3억 부 이상이 판매되었을 만큼 전 세계 독자들로부터 뜨거운 사랑을 받고 있다. 이러한 대중적 인기와 더불어 최근에는 그의 문학성을 새롭게 평가하는 움직임도 일고 있어서, 2003년 킹은 미국의 가장 권위 있는 문학상인 전미 도서상에서 미국 문단에 탁월한 공로를 기여한 작가에게 수여하는 평생 공로상을 수상한 바 있다. 1996년에는 오헨리 상, 2011년에는 《LA타임스》 도서상, 2014년에는 에드거 최우수 장편소설상을 수상하며 문학성을 입증받기도 했다. 이 외에 브람 스토커 상을 15회나 수상했고, 영국 판타지 상과 호러 길드 상을 각 6회, 로커스 상 5회, 세계 판타지 상을 4회 수상했다. 그의 작품들은 영화로 제작되어서도 높은 평가를 얻었다. 그중 『캐리』, 『샤이닝』, 『살렘스 롯』, 『미저리』, 『돌로레스 클레이본』, 『쇼생크 탈출』, 『그린 마일』, 『미스트』, 『그것』 등이 명작으로 꼽힌다. 저자 : 피터 스트라우브 PETER STRAUB\n",
      "\n",
      "위 책 목록을 참고하여, 사용자의 후속 질문 의도를 분석해라.\n",
      "- 만약 사용자가 특정 책에 대해 더 자세한 정보를 원한다면, \"action\"을 \"상세\"로, \"ISBN\"에 해당 책의 ISBN을, \"query\"는 빈 문자열로 출력해라.\n",
      "- 만약 사용자가 특정 책과 유사한 책을 추천받고자 한다면, \"action\"을 \"유사\"로, \"ISBN\"에 해당 책의 ISBN을, \"query\"에 해당 책 전문을 요약한 내용을 출력해라.\n",
      "출력 형식은 반드시 JSON 형식으로, 예:\n",
      "{ \"action\": \"상세\", \"ISBN\": \"1234567890\", \"query\": \"\" }\n",
      "또는\n",
      "{ \"action\": \"유사\", \"ISBN\": \"1234567890\", \"query\": \"요약문\" }\n",
      "단, 불필요한 설명이나 추가 문구 없이 오직 JSON 형식만 출력해라.\n",
      "\n",
      "\n",
      "[디버그] 후속 질문 의도 분석 응답: { \"action\": \"상세\", \"ISBN\": \"9791156759454\", \"query\": \"\" }\n",
      "--------------------------------------------------\n",
      "[챗봇] 해당 ISBN의 책 정보를 찾을 수 없습니다.\n",
      "--------------------------------------------------\n",
      "\n",
      "[대화 저장 중...]\n",
      "대화 저장 완료\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\computer\\anaconda3\\envs\\Kill_the_RAG_env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3585: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "nest_asyncio.apply()\n",
    "\n",
    "\n",
    "def main():\n",
    "    previous_additional_question_embeddings.clear()\n",
    "    print(\"페르소나 선택:\")\n",
    "    print(\"1. 예술/문학\")\n",
    "    print(\"2. 과학/기술\")\n",
    "    print(\"3. 범용/일반\")\n",
    "    choice = input(\"원하는 페르소나 번호를 입력하세요 (1, 2, 3): \").strip()\n",
    "    if choice == \"1\":\n",
    "        pipeline = LiteratureRAGPipeline(\n",
    "            llm_clova, merged_retriever, dpr_qa_chain, documents\n",
    "        )\n",
    "    elif choice == \"2\":\n",
    "        pipeline = ScienceRAGPipeline(\n",
    "            llm_clova, merged_retriever, dpr_qa_chain, documents\n",
    "        )\n",
    "    elif choice == \"3\":\n",
    "        pipeline = GeneralRAGPipeline(\n",
    "            llm_clova, merged_retriever, dpr_qa_chain, documents\n",
    "        )\n",
    "    else:\n",
    "        print(\"잘못된 선택입니다. 기본 범용/일반 페르소나로 실행합니다.\")\n",
    "        pipeline = GeneralRAGPipeline(\n",
    "            llm_clova, merged_retriever, dpr_qa_chain, documents\n",
    "        )\n",
    "\n",
    "    asyncio.run(pipeline.interactive_multi_turn_qa())\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kill_the_RAG_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
